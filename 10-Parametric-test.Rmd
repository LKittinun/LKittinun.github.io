# Parametric test

Parametric test คือ การวิเคราะห์ทางสถิติที่เราทราบลักษณะการกระจายตัวของข้อมูลอย่างชัดเจน แต่มีข้อดีคือการเปรียบเทียบข้อมูลจะมีความแม่นยำสูง

## $t$-test {#sec-t-test}

คือ การคำนวณทางสถิติที่เปรียบเทียบค่าเฉลี่ย (Mean) และความผันผวนของการวัด (Standard Error; SE) ระหว่างสองกลุ่ม แบ่งเป็น

### One sample $t$-test {#one-t}

เป็นการเปรียบเทียบความแตกต่างของค่าเฉลี่ยระหว่างกลุ่มตัวอย่าง (Sample) กับประชากร (Population)

$$
t = \frac{\bar{x} - \mu_{0}}{SE} = \frac{\bar{x} - \mu_{0}}{s/\sqrt{n}}
$$

เพื่อให้เห็นภาพของความต่างในการทดสอบนี้ เราจะทำการสร้างกราฟเปรียบว่ากลุ่มตัวอย่างนั้น มีค่าเฉลี่ยต่างจากประชากร ที่ ค่าเฉลี่ย = 10 และ ค่าเฉลี่ย = 30 หรือไม่

```{r distribution}
set.seed(123)
norm_10_pop <- rnorm(1000, mean = 10, sd = 4) # สร้างประชากร mean = 10, sd = 4
norm_10_sample <- sample(norm_10_pop, 100) # สุ่มตัวอย่างมาจากประชากร 100 ราย
norm_30_pop <- rnorm(1000, mean = 30, sd = 4)
norm_30_sample <- sample(norm_30_pop, 100)
```

```{r one_t_plot, out.width="100%"}
norm_pop_df <- data.frame(Pop_10 = norm_10_pop, Pop_30 = norm_30_pop) |>
  pivot_longer(everything(), names_to = "Pop", values_to = "Values")  

norm_sample_df <- data.frame(Samp_10 = norm_10_sample, Samp_30 = norm_30_sample) |>    pivot_longer(everything(), names_to = "Samp", values_to = "Values")  

ggplot(norm_pop_df, aes(x = Values, fill = Pop)) +    
  geom_density(aes(y = after_stat(count)),color = "black", alpha = 0.5) + 
  geom_density(data = norm_sample_df, 
               aes(x  = Values, y = after_stat(count), fill = Samp), 
               color = "black", alpha = 0.7) + theme_bw()
```

จะเห็นว่าเมื่อดูลักษณะการกระจายตัวของข้อมูลแล้ว `Samp_10` ที่มี ค่าเฉลี่ย = 10 นั้น ไม่ต่างจากประชากรที่มี ค่าเฉลี่ย = 10 แต่ดูแตกต่างอย่างเห็นได้ชัดกับประชากรที่มี mean = 30 `t.test` จะช่วยตัดสินว่าค่าที่ได้นั้นแตกต่างกันจริงหรือไม่ โดยสมมติฐานที่ตั้งคือ

**Case 1**: ประชากรมีค่าเฉลี่ย = 10

-   $H_{0}$: ค่าเฉลี่ยของกลุ่มตัวอย่างนั้น ไม่ต่างจากค่าเฉลี่ยของประชากร = 10

-   $H_{a}$: ค่าเฉลี่ยของกลุ่มตัวอย่างนั้น ต่างจากค่าเฉลี่ยของประชากร = 10

```{r one_t_10}
t.test(norm_10_sample, mu = 10) # p > 0.05
```

**Case 2**: ประชากรมีค่าเฉลี่ย = 40

-   $H_{0}$: ค่าเฉลี่ยของกลุ่มตัวอย่างนั้น ไม่ต่างจากค่าเฉลี่ยของประชากร = 40

-   $H_{a}$: ค่าเฉลี่ยของกลุ่มตัวอย่างนั้น ต่างจากค่าเฉลี่ยของประชากร = 40

```{r one_t_30}
t.test(norm_10_sample, mu = 30) # p <= 0.05
```

จะเห็นว่าต่างจากประชากรที่ค่าเฉลี่ย = 30 อย่างมีนัยสำคัญ ($p$ = $2.2 \times 10^{-16}$ \< Critical point = 0.05)

พิจารณาที่มาของ $p$-value นั้นมีที่มาจากสูตรขั้นต้น

```{r self_formulate_t}
hypothesized_mean <- 30
mean_sample <- mean(norm_10_sample)
sd_sample <- sd(norm_10_sample)

t <- (mean_sample - hypothesized_mean)/(sd_sample/sqrt(length(norm_10_sample)))

t

2*pt(t, df = 99) # p-value
```

จะเห็นว่าค่า $t$ นั้นเท่ากับ ค่าที่ได้จาก `t.test` ขั้นต้น เมื่อสร้าง $t$-distribution ที่มี $H_{0}$ คือ ค่าเฉลี่ย = 0 แล้วจะพบว่าค่านี้มากกว่า Critical value

### Independent t-test {#ind-t}

เป็นการเปรียบเทียบค่าเฉลี่ยระหว่าง ตัวอย่างสองกลุ่มที่ไม่เกี่ยวเนื่องกัน

$$
t = \frac{\bar{x_{1}}-\bar{x_{2}}}{\sqrt{\frac{s^{2}_1}{n_{1}}+\frac{s^{2}_2}{n_{2}}}}
$$

$$
S_{p}^{2} = \frac{(n_{1}-1)s^{2}_{1}+(n_{2}-1)s^{2}_{2}}{{n_{1}} + n_{2} - 2}
$$

กลับไปดูภาพขั้นต้น ครั้งนี้จะเทียบระหว่างกลุ่มตัวอย่างสองกลุ่ม คือ `norm_10_sample` และ `norm_30_sample` ว่ามี ค่าเฉลี่ยที่แตกต่างกันอย่างมีนัยสำคัญหรือไม่

-   $H_{0}$: ค่าเฉลี่ยของ `norm_10_sample` และ `norm_30_sample` นั้นไม่แตกต่างกัน ($\bar{x_{1}} - \bar{x_{2}} = 0$)

-   $H_{a}$: ค่าเฉลี่ยของ `norm_10_sample` และ `norm_30_sample` นั้นแตกต่างกัน ($\bar{x_{1}} - \bar{x_{2}} \neq 0$)

```{r independent_t}
t.test(norm_10_sample, norm_30_sample, var.equal = TRUE)
```

สรุปได้ว่าค่าเฉลี่ยของกลุ่มตัวอย่างทั้งสองกลุ่มนั้นแตกต่างกันอย่างมีนัยสำคัญ

ปล. บางครั้งข้อมูลอาจจะมีความแปรปรวนไม่เท่ากัน ในที่นี้มักจะใช้ Welch's $t$-test โดย `t.test(…, var.equal = FALSE)` โดยสมการนี้จะทำการปรับความแปรปรวนให้ด้วย

### Paired t-test {#pair-t}

เป็นการเปรียบเทียบค่าเฉลี่ยระหว่างตัวอย่างสองกลุ่มที่เกี่ยวเนื่องกัน (ก่อน-หลัง แม่-ลูก เป็นต้น)

$$
t = \frac{\bar{x}_{d} -\mu_{0}}{{s_{d} / \sqrt{n}}}
$$

$$ S_{d} = \sqrt{\sum(x_{d}-\bar{x}_{d})/(n-1)}$$

```{r paired_t}
t.test(norm_10_sample, norm_30_sample, paired = TRUE)
```

จะเห็นว่ามีความแตกต่างในส่วนของ $DF$ (Degree of freedom) ซึ่งเกิดจากการจับคู่หาความต่าง 100 ครั้ง เนื่องจากค่าที่เปรียบเทียบนั้นอยู่ในตัวอย่างเดียวกัน (แม่ลูก คู่ที่ 1 แม่ลูกคู่ที่ 2 ... เป็นต้น) เมื่อเปรียบเทียบกับ Independent $t$-test เนื่องจากเป็นการหา mean ในกลุ่มของตัวเอง 2 ครั้ง และมาเทียบความต่างกัน

ดังนั้น การเลือก Paired vs Independent นั้นมีความสำคัญ ขึ้นอยู่กับโจทย์การศึกษาของท่านด้วย

------------------------------------------------------------------------

## Analysis of Variance (ANOVA) {#ANOVA}

คือ การคำนวณทางสถิติที่เปรียบเทียบค่าเฉลี่ยและความแปรปรวนระหว่างสองกลุ่มขึ้นไป โดยมีสมมติฐาน คือ

-   $H_{0}$: ค่าเฉลี่ยของทุกกลุ่มเท่ากัน ($\bar{x_{1}} = \bar{x_{2}} = \bar{x_{3}} = … = \bar{x_{n}}$)

-   $H_{a}$: ค่าเฉลี่ยของ**กลุ่มใดกลุ่มหนึ่ง**ต่างจากกลุ่มอื่น

การวิเคราะห์ ANOVA นั้นมีหลายแบบ

-   One-way ANOVA เป็นการหาความแตกต่างของ 1 ตัวแปร

-   Two-way ANOVA เป็นการหาความแตกต่างของ 2 ตัวแปร

-   MANOVA เป็นการหาความแตกต่างที่มากกว่า 2 ตัวแปร

-   Nested ANOVA เป็นการหาความแตกต่างที่ใน 1 ตัวแปรนั้น มีตัวแปรย่อยอีก

ณ ที่นี้จะกล่าวถึงแค่ one ANOVA ซึ่งมีความซับซ้อนน้อย และนิยมใช้มากที่สุด โดยหลักการโดยง่ายของ ANOVA คือ การเปรียบเทียบความต่างของ **ค่าเฉลี่ยทั้งกลุ่ม (Global mean)** เปรียบเทียบกับ **ผลรวมของค่าเฉลี่ยแต่ละกลุ่ม (Between group mean)**

การวิเคราะห์ทางสถิติของ ANOVA นั้นใช้ $F$-test ซึ่งเป็นการเปรียบเทียบระหว่าง ความแปรปรวนที่อธิบายได้ และความแปรปรวนที่อธิบายไม่ได้

$$F^{*} = \frac{\text{Explained variance}}{\text{Unexplained variance}} =  \frac{\text{Between group variance}}{\text{Within groups variance}}$$

-   Between group variance คือ ความแปรปรวนของค่าเฉลี่ยแต่ละกลุ่มกับค่าเฉลี่ยทั้งหมด

-   Within group variance คือ ความแปรปรวนของข้อมูลในกลุ่มนั้น ซึ่งไม่สามารถอธิบายได้ภายใต้สมมติฐานงานวิจัยนั้น

อธิบายโดยใช้ตัวอย่าง iris ในที่นี้เราจะเปรียบเทียบตวามต่างของ `Sepal.Width` ในแต่ละ `Species`

```{r anova, message = FALSE}
aov(Sepal.Width ~ Species, data = iris) |> summary()
```

อธิบายด้วยภาพ

```{r granova, message = FALSE}
library(granova)
granova.1w(iris$Sepal.Width, group = iris$Species)
```

-   รูปสามเหลี่ยม คือ ค่าเฉลี่ยของ `Petal.Width` ในดอกไม้แต่ละ `Species`

-   จุดสีดำ คือ ค่า `Petal.Width` ในดอกไม้แต่ละดอก

-   จุดสีเขียว คือ Global mean (Grand mean) คือ ค่าเฉลี่ย `Petal.Width` เมื่อรวมดอกไม้ทุก `Species`

จุดประสงค์ของ F-test คือการเปรียบเทียบอัตราส่วนระหว่าง ความแปรปรวนของค่าเฉลี่ยแต่ละกลุ่มกับค่าเฉลี่ยทั้งหมด (mean ของความต่างจุดเขียวกับสามเหลี่ยม) ใกล้กันกับความแปรปรวนของข้อมูลในกลุ่มนั้น (mean ของความต่างระหว่างจุดดำกับกับสามเหลี่ยม) หรือไม่ (ratio \~ 1) ซึ่งค่า $F$ นั้นจะถูกนำไปคิด $p$-value จาก $F$-distribution (หลักการเดียวกันกับ $t$-test)

**สังเกตว่า** ท่านไม่สามารถบอกได้ว่ากลุ่มไหนเป็นกลุ่มที่มีค่าเฉลี่ยที่แตกต่างจากทั้งกลุ่ม การที่จะทราบนั้นต้องทำ `t.test` เปรียบเทียบกันในแต่ละกลุ่ม $3\choose2$ = 3 ครั้ง การค้นหากลุ่มที่มีความต่างหลัง ANOVA นี้ เรียกว่า Post-hoc test

```{r posthoc_anova}
pairwise.t.test(iris$Sepal.Width, iris$Species)
```

$p$-value น้อยกว่า 0.05 ทุกกลุ่ม หมายความว่า ทุกกลุ่มมีค่าเฉลี่ยของ `Petal.Width` ที่แตกต่างกัน

## Correlation test

### Pearson correlation {#pearson}

เป็นการทดสอบความสัมพันธ์**เชิงเส้น**ของตัวแปรสองตัวแปร

$$
r_{xy} =\frac{cov(x,y)}{s(x) s(y)}
$$

$$
cov(x,y) = \frac{\sum^{n}_{i=1}(x_{i}-\bar{x})(y_{i}-\bar{y})}{n-1}
$$

$$
\therefore r_{xy} = \frac{\sum^{n}_{i=1}(x_{i}-\bar{x})(y_{i}-\bar{y})}{\sqrt{\sum^{n}_{i=1}(x_{i}-\bar{x})^{2}}\sqrt{\sum^{n}_{i=1}(y_{i}-\bar{y})^{2}}}
$$

```{r cor_iris}
ggplot(iris, aes(x = Sepal.Length, y = Petal.Length)) + 
  geom_point(aes(col = Species)) +
  geom_smooth(method = "lm", se = FALSE)

cor(iris$Sepal.Length, iris$Petal.Length)
```

การแปลผลของ Correlation ขึ้นอยู่กับ

-   ระดับของความสัมพันธ์ = 0-1 ยิ่งเข้าใกล้ 1 ยิ่งสัมพันธ์กันมาก

-   ทิศทางของความสัมพันธ์ = + ไปทิศทางเดียวกัน - ไปทิศทางตรงข้ามกัน

ท่านสามารถสร้างตาราง Correlation และ $p$-value ได้ด้วย package `corrplot`

```{r corrplot, message = FALSE}
library(corrplot)

iris_cor <- cor(iris[1:4])
iris_cor
iris_cor_p <- cor.mtest(iris[1:4])
iris_cor_p

corrplot(iris_cor, method = "shade",type = "upper",order = "AOE", 
         p.mat = iris_cor_p$p, insig = "p-value")
```

**ข้อควรระวัง** $p$-value ของ Correlation test นั้นอยู่ภายใต้สมมติฐาน ($t$-test/$F$-test)

-   $H_{0}$: ไม่มีความสัมพันธ์เชิงเส้นของทั้งสองตัวแปร ($r_{xy} = 0$)

-   $H_{0}$: มีความสัมพันธ์เชิงเส้นของทั้งสองตัวแปร ($r_{xy} \neq 0$)

ซึ่งถ้า $p$ \< 0.05 หมายความว่า ท่านมีความมั่นใจมากเพียงพอว่า ความสัมพันธ์เชิงเส้นของทั้งสองตัวแปรนั้น มีมากกว่าการวาดเส้นจากการสร้างจุดแบบสุ่ม ท่านยังคงต้องแปรผลร่วมกับค่า Correlation coefficient ต่อไป

เช่น

-   $r_{x,y}$ = 0.2, $p$ \< 0.05 มั่นใจว่ามีความสัมพันธ์เชิงเส้นของสองตัวแปร ความสัมพันธ์เป็นไปในทิศทางเดียวกัน แต่ความสัมพันธ์เชิงเส้นอยู่ในระดับน้อย

-   $r_{x,y}$ = 1, $p$ = 1 ความสัมพันธ์เชิงเส้นอยู่ในระดับดีเยี่ยม แต่ไม่มั่นใจว่ามีความสัมพันธ์กันจริงหรือไม่ เนื่องจากข้อมูลน้อย (เช่น มีข้อมูลเพียงสองจุด $r_{x,y}$ ย่อมเท่ากับ 1)

-   $r_{x,y}$ = 0.3, $p$ = 1 ความสัมพันธ์เชิงเส้นอยู่ในระดับน้อย แต่ไม่มั่นใจว่ามีความสัมพันธ์กันจริงหรือไม่ เนื่องจากข้อมูลน้อยเกินไป ควรเก็บข้อมูลเพิ่ม

-   $r_{x,y}$ = -1, $p$ \< 0.05 มั่นใจว่ามีความสัมพันธ์เชิงเส้นของสองตัวแปร ความสัมพันธ์เป็นไปในทิศทางตรงข้าม และความสัมพันธ์เชิงเส้นอยู่ในระดับดีเยี่ยม

นั่นหมายความว่า ยิ่งจำนวนตัวอย่างเพิ่มขึ้น **ความมั่นใจ**ยิ่งเพิ่มขึ้น **ไม่ใช่ความสัมพันธ์เพิ่มขึ้น**
