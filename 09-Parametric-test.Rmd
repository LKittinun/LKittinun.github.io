# Parametric test

Parametric test คือ การวิเคราะห์ทางสถิติที่เราทราบลักษณะการกระจายตัวของข้อมูลอย่างชัดเจน แต่มีข้อดีคือการเปรียบเทียบข้อมูลจะมีความแม่นยำสูง

## t-test {#sec-t-test}

คือ การคำนวณทางสถิติที่เปรียบเทียบค่าเฉลี่ย (mean) และความแปรปรวน (sd) ระหว่างสองกลุ่ม แบ่งเป็น

### One sample t-test

เป็นการเปรียบเทียบความแตกต่างของ mean ระหว่าง `sample` กับ `population`

$$
t = \frac{\bar{x} - \mu_{0}}{s/\sqrt{n}}
$$

เพื่อให้เห็นภาพของความต่างใน test นี้เราจะทำการสร้างกราฟเปรียบว่า sample นั้น มี mean ต่างจาก population ที่ mean = 10 และ mean = 30 หรือไม่

```{r distribution}
set.seed(123)
norm_10_pop <- rnorm(1000, mean = 10, sd = 4) # สร้างประชากร mean = 10, sd = 4
norm_10_sample <- sample(norm_10_pop, 100) # สุ่มตัวอย่างมาจากประชากร 100 ราย
norm_30_pop <- rnorm(1000, mean = 30, sd = 4)
norm_30_sample <- sample(norm_30_pop, 100)
```

```{r one_t_plot, out.width="100%"}
norm_pop_df <- data.frame(Pop_10 = norm_10_pop, Pop_30 = norm_30_pop) |>
  pivot_longer(everything(), names_to = "Pop", values_to = "Values")  

norm_sample_df <- data.frame(Samp_10 = norm_10_sample, Samp_30 = norm_30_sample) |>    pivot_longer(everything(), names_to = "Samp", values_to = "Values")  

ggplot(norm_pop_df, aes(x = Values, fill = Pop)) +    
  geom_density(aes(y = after_stat(count)),color = "black", alpha = 0.5) + 
  geom_density(data = norm_sample_df, 
               aes(x  = Values, y = after_stat(count), fill = Samp), 
               color = "black", alpha = 0.7) + theme_bw()
```

จะเห็นว่าเมื่อดูลักษณะการกระจายตัวของข้อมูลแล้ว `Samp_10` ที่มี mean = 10 นั้น ไม่ต่างจากประชากรที่มี mean = 10 แต่ดูแตกต่างอย่างเห็นได้ชัดกับประชากรที่มี mean = 30 `t.test` จะช่วยตัดสินว่าค่าที่ได้นั้นแตกต่างกันจริงหรือไม่ hypothesis ที่ตั้งคือ

**Case 1**: Population at mean = 10

-   $H_{0}$: mean ของ sample นั้น ไม่ต่างจาก mean ของ population ที่ mean = 10

-   $H_{a}$: mean ของ sample นั้น ต่างจาก mean ของ population ที่ mean = 10

```{r one_t_10}
t.test(norm_10_sample, mu = 10) # p > 0.05
```

**Case 2**: Population at mean = 40

-   $H_{0}$: mean ของ sample นั้น ไม่ต่างจาก mean ของ population ที่ mean = 40

-   $H_{a}$: mean ของ sample นั้น ต่างจาก mean ของ population ที่ mean = 40

```{r one_t_30}
t.test(norm_10_sample, mu = 30) # p <= 0.05
```

จะเห็นว่าต่างจาก population ที่ mean = 30 อย่างมีนัยสำคัญ (p = $2.2 \times 10^{-16}$ \< critical point (0.05) )

พิจารณาที่มาของ `p-value` นั้นมีที่มาจากสูตรขั้นต้น

```{r self_formulate_t}
hypothesized_mean <- 30
mean_sample <- mean(norm_10_sample)
sd_sample <- sd(norm_10_sample)

t <- (mean_sample - hypothesized_mean)/(sd_sample/sqrt(length(norm_10_sample)))

t

2*pt(t, df = 99) # p-value
```

จะเห็นว่าค่า `t` นั้นเท่ากับ ค่าที่ได้จาก function `t.test` ขั้นต้น เมื่อสร้าง `t-distribution` ที่มี $H_{0}$ คือ mean = 0 แล้วจะพบว่าค่านี้มากกว่า critical value

### Independent t-test

เป็นการเปรียบเทียบ mean ระหว่าง `sample` สองกลุ่มที่ไม่เกี่ยวเนื่องกัน

$$
t = \frac{\bar{x_{1}}-\bar{x_{2}}}{\sqrt{\frac{s^{2}_1}{n_{1}}+\frac{s^{2}_2}{n_{2}}}}
$$

$$
S_{p}^{2} = \frac{(n_{1}-1)s^{2}_{1}+(n_{2}-1)s^{2}_{2}}{{n_{1}} + n_{2} - 2}
$$

กลับไปดูภาพขั้นต้น ครั้งนี้จะเทียบระหว่าง sample สองกลุ่ม คือ `norm_10_sample` และ `norm_30_sample` ว่ามี mean ที่แตกต่างกันอย่างมีนัยสำคัญหรือไม่

-   $H_{0}$: mean ของ `norm_10_sample` และ `norm_30_sample` นั้นไม่แตกต่างกัน ($\text{mean difference} = 0$)

-   $H_{a}$: mean ของ `norm_10_sample` และ `norm_30_sample` นั้นแตกต่างกัน ($\text{mean difference} \neq 0$)

```{r independent_t}
t.test(norm_10_sample, norm_30_sample, var.equal = TRUE)
```

สรุปได้ว่า mean ของ `sample` ทั้งสองกลุ่มนั้นแตกต่างกันอย่างมีนัยสำคัญ

ปล. บางครั้งข้อมูลอาจจะมีความแปรปรวนไม่เท่ากัน ในที่นี้มักจะใช้ `Welch's t-test` โดย `t.test(…, var.equal = FALSE)` โดยสมการนี้จะทำการปรับความแปรปรวนให้ด้วย

### Paired t-test

เป็นการเปรียบเทียบ mean ระหว่าง `sample` สองกลุ่มที่เกี่ยวเนื่องกัน (ก่อน-หลัง แม่-ลูก เป็นต้น)

$$
t = \frac{\bar{x}_{d} -\mu_{0}}{{s_{d} / \sqrt{n}}}
$$

$$ s_{d} = \sqrt{\sum(x_{d}-\bar{x}_{d})/(n-1)}$$

```{r paired_t}
t.test(norm_10_sample, norm_30_sample, paired = TRUE)
```

จะเห็นว่ามีความแตกต่างในส่วนของ $DF$ (degree of freedom) ซึ่งเกิดจากการจับคู่หาความต่าง 100 ครั้ง เนื่องจากค่าที่เปรียบเทียบนั้นอยู่ในตัวอย่างเดียวกัน (แม่ลูก คู่ที่ 1 แม่ลูกคู่ที่ 2 ... เป็นต้น) เมื่อเปรียบเทียบกับ `independent t-test` เนื่องจากเป็นการหา mean ในกลุ่มของตัวเอง 2 ครั้ง และมาเทียบความต่างกัน

ดังนั้น การเลือก `paired vs independent` นั้นมีความสำคัญ ขึ้นอยู่กับโจทย์การศึกษาของท่านด้วย

---


## Analysis of Variance (ANOVA)

คือ การคำนวณทางสถิติที่เปรียบเทียบค่าเฉลี่ย (mean) และความแปรปรวน (sd) ระหว่างสองกลุ่มขึ้นไป โดยมีสมมติฐาน คือ

-   $H_{0}$: ค่าเฉลี่ยของทุกกลุ่มเท่ากัน ($\mu_{1} = \mu_{2} = \mu_{3} = … = \mu_{k}$)

-   $H_{a}$: ค่าเฉลี่ยของ**กลุ่มใดกลุ่มหนึ่ง**ต่างจากกลุ่มอื่น

การวิเคราะห์ ANOVA นั้นมีหลายแบบ

-   `one-way ANOVA` เป็นการหาความแตกต่างของ 1 ตัวแปร

-   `two-way ANOVA` เป็นการหาความแตกต่างของ 2 ตัวแปร

-   `MANOVA` เป็นการหาความแตกต่างที่มากกว่า 2 ตัวแปร

-   `nested ANOVA` เป็นการหาความแตกต่างที่ใน 1 ตัวแปรนั้น มีตัวแปรย่อยอีก

ณ ที่นี้จะกล่าวถึงแค่ `one-way ANOVA` ซึ่งมีความซับซ้อนน้อย โดยหลักการโดยง่ายของ ANOVA คือ การเปรียบเทียบความต่างของ **ค่าเฉลี่ยทั้งกลุ่ม (global mean)** เปรียบเทียบกับ **ผลรวมของค่าเฉลี่ยแต่ละกลุ่ม (between group mean)**

การวิเคราะห์ทางสถิติของ ANOVA นั้นใช้ **F-test** ซึ่งเป็นการเปรียบเทียบระหว่าง ความแปรปรวนที่อธิบายได้ และความแปรปรวนที่อธิบายไม่ได้

$$F^{*} = \frac{\text{Explained variance}}{\text{Unexplained variance}} =  \frac{\text{Between group variance}}{\text{Within groups variance}}$$

-   Between group variance คือ ความแปรปรวนของค่าเฉลี่ยแต่ละกลุ่มกับค่าเฉลี่ยทั้งหมด

-   Within group variance คือ ความแปรปรวนของข้อมูลในกลุ่มนั้น ซึ่งไม่สามารถอธิบายได้ภายใต้สมมติฐานงานวิจัยนั้น

อธิบายโดยใช้ตัวอย่าง iris ในที่นี้เราจะเปรียบเทียบตวามต่างของ `Sepal.Width` ในแต่ละ `Species`

```{r anova, message = FALSE}
aov(Sepal.Width ~ Species, data = iris) |> summary()
```

อธิบายด้วยภาพ

```{r granova, message = FALSE}
library(granova)
granova.1w(iris$Sepal.Width, group = iris$Species)
```

-   รูปสามเหลี่ยม คือ mean ของ `Petal.Width` ในดอกไม้แต่ละ `Species`

-   จุดสีดำ คือ ค่า `Petal.Width` ในดอกไม้แต่ละดอก

-   จุดสีเขียว คือ global mean (grand mean) คือ ค่าเฉลี่ย `Petal.Width` เมื่อรวมดอกไม้ทุก `Species`

จุดประสงค์ของ F-test คือการเปรียบเทียบอัตราส่วนระหว่าง ความแปรปรวนของค่าเฉลี่ยแต่ละกลุ่มกับค่าเฉลี่ยทั้งหมด (mean ของความต่างจุดเขียวกับสามเหลี่ยม) ใกล้กันกับความแปรปรวนของข้อมูลในกลุ่มนั้น (mean ของความต่างระหว่างจุดดำกับกับสามเหลี่ยม) หรือไม่ (ratio \~ 1) ซึ่งค่า $F$ นั้นจะถูกนำไปคิด `p-value` จาก `F-distribution` (หลักการเดียวกันกับ t-test)

**สังเกตว่า** ท่านไม่สามารถบอกได้ว่ากลุ่มไหนเป็นกลุ่มที่มีค่าเฉลี่ยที่แตกต่างจากทั้งกลุ่ม การที่จะทราบนั้นต้องทำ `t.test` เปรียบเทียบกันในแต่ละกลุ่ม $3\choose2$ = 3 ครั้ง การค้นหากลุ่มที่มีความต่างหลัง ANOVA นี้ เรียกว่า post-hoc test

```{r posthoc_anova}
pairwise.t.test(iris$Sepal.Width, iris$Species)
```

`p-value` น้อยกว่า 0.05 ทุกกลุ่ม หมายความว่า ทุกกลุ่มมีค่าเฉลี่ยของ `Petal.Width` ที่แตกต่างกัน
