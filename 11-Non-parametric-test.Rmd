# Non-parametric test

คือ การวิเคราะห์ทางสถิติที่เรา**ไม่**ทราบลักษณะการกระจายตัวของข้อมูลอย่างชัดเจน ข้อดีคือมีความยืดหยุ่นกว่า แต่มีความแม่นยำน้อยกว่า

## Proportion test

คือ การทดสอบทางสถิติเพื่อทำการเปรียบเทียบอัตราส่วนของจำนวน โดยจะใช้กับข้อมูลประเภทจำนวนนับของตัวแปรจัดประเภท (Nominal variable) เช่น จำนวนคน จำนวนเซลล์ เป็นต้น

**ข้อสังเกต** การทดลองที่มีการทำ Technical replicate แล้วหาค่าเฉลี่ยนั้น ตัวข้อมูลยังเป็น **จำนวนนับ** การจะหาความต่างค่าเฉลี่ยโดยใช้ `t.test` นั้น จำนวน Sample ควรจะมากพอตาม Central limit theorem นอกเหนือจากนั้นควรใช้ Proportional test หรือ ควรใช้ Generalized linear model ประเภทอื่นมากกว่า

### Chi-square test

คือ การทดสอบความต่างของอัตราส่วนโดยใช้การประมาณการของ ค่าที่คาดหวัง (Expected value) และ ค่าที่สังเกตได้จริง (Observed value)

$$
\chi^{2} = \sum_{i=1}^{n}\frac{(O-E)^{2}}{E}
$$

#### Chi-square goodness of fit {#chisq-f}

เป็นการเปรียบเทียบว่า Observed value นั้นมาจากประชากรทางทฤษฎีหรือไม่ โดย Expected value นั้นคำนวนจาก

$$
E_{i} = CDF_{i}(Y_{u})-CDF_{i}(Y_{l})
$$

ยกตัวอย่างการทอดลูกเต๋า ซึ่งมีโอกาสการเกิดทุกหน้า = $1/6$

-   $H_{0}$ การกระจายตัวของการทอดลูกเต๋านี้เท่ากับการกระจายทางทฤษฎี

-   $H_{a}$ การกระจายตัวของการทอดลูกเต๋านี้**ไม่**เท่ากับการกระจายทางทฤษฎี

```{r dice}
set.seed(123)
dice <- sample(6, 1000, replace = TRUE) # โยนลูกเต๋า 1000 ครั้ง
chisq_dice <- chisq.test(table(dice))
chisq_dice

data.frame(O = chisq_dice$observed, E.Freq = chisq_dice$expected)
```

จะเห็นว่าความแตกต่างระหว่าง Observed และ Expected นั้น อยู่ในพิสัยของของ $H_{0}$

แต่ถ้าลูกเต๋านั้นเป็นลูกเต๋าถ่วงน้ำหนัก

```{r weight_dice}
weight_dice <- sample(6,1000, replace = TRUE, prob = c(3,2,1,1,1,1)/9)
chisq_weight_norm <- chisq.test(table(weight_dice))
chisq_weight_norm
data.frame(O = chisq_weight_norm$observed, E.freq = chisq_weight_norm$expected)
```

เมื่อวิเคราะห์ Chi-square ตามการกระจายตัวของลูกเต๋าทั่วไป จะแตกต่างอย่างมีนัยสำคัญ

```{r weight_dice_weight}
chisq_weight_weight <- chisq.test(table(weight_dice), p = c(3,2,1,1,1,1)/9)
chisq_weight_weight
data.frame(O = chisq_weight_weight$observed, E.freq = chisq_weight_weight$expected)
```

แต่ถ้าวิเคราะห์เทียบกับการกระจายตัวเดียวกับลูกเต๋าถ่วงน้ำหนัก จะไม่แตกต่างกัน

#### Chi-square test of independence

เป็นการเปรียบเทียบข้อมูลจำนวนสองกลุ่มขึ้นไปว่า มีความสัมพันธ์ที่ทำให้การกระจายตัวของข้อมูลเปลี่ยนไปจากปกติหรือไม่

$H_{0}$: ข้อมูลทั้ง 2+ กลุ่มนั้น**ไม่**มีความสัมพันธ์ต่อกัน

$H_{a}$: ข้อมูลทั้ง 2+ กลุ่มนั้นมีความสัมพันธ์ต่อกัน

โดยการวิเคราะห์นั้นจะใช้กับข้อมูลความถี่แบบ $n \times n$ โดย Expected event นั้นคิดจาก

| Group/Success | Con1  | Con2  | Total         |
|---------------|-------|-------|---------------|
| **Group 1**   | A     | B     | A + B         |
| **Group 2**   | C     | D     | C + D         |
| **Total**     | A + C | B + D | A + B + C + D |

$$
E_{i,j} = P(G_{i,j}) \times P(Con_{i,j}) \times \text{total counts} 
$$ $$
E = \frac{\text{Row total} \times \text{Column total}}{\text{Total sample size}}
$$

อย่างเช่น Expected event สำหรับช่อง $A$ คือ $$
\frac{(A + B) \times (A + C)}{(A + B + C + D)^{2}}(A+B+C+D)
$$

```{r lung_chisq, echo = FALSE, message = FALSE}
library(survival)

lung_ob <- lung |> 
  mutate(sex = case_match(sex, 1 ~ "Male", 2~"Female")) |> 
  mutate(status = case_match(status, 1 ~ "Alive", 2~"Dead")) |> 
  select(sex,status) |> table()
```

ยกตัวอย่างว่าอยากทราบว่าเพศมีผลต่ออัตราการตายในมะเร็งปอดหรือไม่

```{r chisq_lung}
lung_ob

lung_chisq <- chisq.test(lung_ob, correct = FALSE)
lung_chisq
```

$p$ \< 0.05 หมายความว่าเพศมีผลต่ออัตราการตายอย่างมีนัยสำคัญ

ลองคำนวณเองตามสูตรขั้นต้น

```{r chisq_lung_manual}
lung_ex <- apply(expand.grid(rowSums(lung_ob), colSums(lung_ob)),1, prod) |> 
  matrix(nrow=2)/sum(lung_ob) # สร้าง expected table

lung_ex

chi_value <- sum((lung_ob - lung_ex)^2/lung_ex)
chi_value # chi-squared

pchisq(chi_value, df = lung_chisq$parameter, lower.tail = FALSE) # p-value
```

### Fisher's exact test {#fisher}

คือการทดสอบว่าข้อมูลนั้นมีความสัมพันธ์หรือไม่ โดยการเทียบกับความสัมพันธ์แบบสุ่ม การทดสอบนี้จะมีความแม่นยำกว่า Chi-square เนื่องจากเป็นการคำนวณความน่าจะเป็นโดยตรง

$$
p = \frac{{A+B \choose A}{C+D \choose C}}{{n \choose A+C}} = \frac{{A+B \choose B}{C+D \choose D}}{{n \choose B+D}}
$$

พิจารณาสูตร จุดประสงค์คือ การคำนวณความน่าจะเป็นของการหยิบสุ่มแบบไม่คืนให้ได้ตาม Condition ที่ต้องการนั่นเอง

```{r fisher_lung}
fisher.test(lung_ob, alternative = "two.sided")
```

$p$ \< 0.05 หมายความว่าเพศมีผลต่ออัตราการตายอย่างมีนัยสำคัญ สังเกตว่า $p$ จะมากกว่า Chi-square เนื่องจากการทดสอบนี้มีความ Conservative กว่า

ลองคำนวณเองตามสูตรขั้นต้น

```{r fish_lung_man}
alive_dead <- colSums(lung_ob)
alive_dead # total alive and dead
male_female <- rowSums(lung_ob)
male_female # total male and female
fisher_p <- (choose(alive_dead[1], lung_ob[1]-1)*choose(alive_dead[2], lung_ob[3])/
               (choose(sum(lung_ob), male_female[1])))

unname(fisher_p)*2 # remove name

## or
2*(phyper(lung_ob[1]-1,alive_dead[1], 
       alive_dead[2], male_female[1],lower.tail=FALSE))
```

ปล. การใช้ `lung_ob[1] - 1` นั้นมีที่มาจากว่า เมื่อใช้ `lower.tail = TRUE` จะคำนวณโอกาสที่ ได้ $P[X > x]$ ซึ่งเราต้องการ $P[X \geq x]$ จึงต้อง ลบ Condition ที่ต้องการออกด้วย

------------------------------------------------------------------------

## Rank test

เป็นการหาความต่างของ**ลำดับ** แทนที่จะหาความต่างของ Mean/Variance ในภาวะที่ไม่ทราบการกระจายตัวของข้อมูลที่ชัดเจน

### Test for normality

กลับมาที่ตัวอย่าง `iris` ดูการกระจายของข้อมูล

```{r iris_hist, fig.path="figure/"}
  ggplot(long_df, aes(x = cm, fill = Metrics)) + geom_histogram() +
  facet_grid(Metrics~Species, scales = "free") +
  theme_bw()
```

พิจารณาแล้ว `Petal.Width` ไม่น่าจะใช่ Normal distribution จะทำการทดสอบต่อโดย `shapiro.test()` ซึ่งเป็นการทดสอบการกระจายตัวของข้อมูลว่าหลุดออกจาก Normal distribution หรือไม่

```{r shapiro}
long_df |> 
  group_by(Metrics, Species) |> 
  summarise(normality = round(shapiro.test(cm)$p.value, 4))
```

จะเห็นว่า `Petal.Width` มี $p$ \< 0.05 พอสมควร (ไม่เป็น Normal distribution) จึงสมควรใช้ Non-parametric test

### Wilcoxon's rank sum test (Mann-Whitney U test) {#wilcox-rs}

คือ การคำนวณว่ากลุ่มตัวอย่าง 2 กลุ่มนั้นมาจากประชากรกลุ่มเดียวกันหรือไม่ จากการพิจารณาผลรวมของ**ลำดับข้อมูล**ทั้งสองกลุ่ม

ลักษณะการใช้คล้าย [Independent t-test](#ind-t) สำหรับ Non-normal distribution

$$
W_{j} = n_{1}n_{2} + \frac{n_{j}(n_{j}+1)}{2} - R_{n}
$$

$$
W = min(W_{1}, W_{2})
$$

```{r wilcox_rs}
iris_pw <- df |> 
  select(Petal.Width, Species) |> 
  filter(Species != "virginica" )

iris_wx <- wilcox.test(Petal.Width~Species, data = iris_pw)

iris_wx
iris_wx$p.value
```

ลองคำนวณเอง หลักการคือ

-   จัดอันดับของข้อมูลโดยเรียงจาก น้อยไปมาก และให้อันดับเป็นตัวเลข (อันดับที่เท่ากัน ให้เป็นค่าเฉลี่ยของลำดับนั้น เช่น อันดับ 2, 3, 4 ที่มีค่าเท่ากัน ให้อันดับเป็น (2+3+4)/3 = 5 ทุกตัว)

-   คำนวณค่า $W$ โดยแยกกลุ่ม 1 และ กลุ่ม 2 และเลือกค่า $W$ ที่น้อยที่สุด

```{r wilcox_rs_manual}
iris_pw_rank <- iris_pw |> 
  arrange(`Petal.Width`) |> 
  mutate(Rank = rank(`Petal.Width`, ties.method = "average")) # rank all values

setosa <- split(iris_pw_rank, iris_pw$Species)$setosa
versicolor <- split(iris_pw_rank, iris_pw$Species)$versicolor

all_combn <- nrow(setosa)*nrow(versicolor)
all_combn
setosa_rank_sum <- all_combn + (nrow(setosa)*(nrow(setosa)+1))/2 - sum(setosa$Rank)
setosa_rank_sum
versicolor_rank_sum <- all_combn + (nrow(versicolor)*(nrow(versicolor)+1))/2 - sum(versicolor$Rank)
versicolor_rank_sum

W <- min(setosa_rank_sum,versicolor_rank_sum)
W

## Normal approximation
mW <- all_combn/2
sdW <- sqrt(all_combn*(nrow(setosa)+nrow(versicolor)+1)/12)
z = (W-mW)/sdW
pval <- 2*pnorm(-abs(z)) 
pval # not exactly equal due to tie adjustment in wilcox.test()
```

**Note:** เมื่อจำนวนตัวอย่าง \>50 ค่า $W$ จะเข้าสู่ Normal distribution ซึ่งสามารถเปลี่ยนเป็นค่า $Z$ ได้ ส่งผลให้การคำนวณ $p$-value จะแม่นยำขึ้น

$$
Z = \frac{W-m_{w}}{s_{w}}
$$

$$
m_{w} = \frac{n_{1}n_{2}}{2} = \text{mean of W}
$$

$$
s_{w} = \sqrt{\frac{n_{1}n_{2}(n_{1}+n_{2}+1)}{12}}
$$

### Wilcoxon's signed-rank test {#wilcox-sign}

คือ การคำนวณว่ากลุ่มตัวอย่าง 2 กลุ่มนั้นมาจากประชากรกลุ่มเดียวกันหรือไม่ จากการคำนวณ**ลำดับข้อมูล**ของทั้งสองกลุ่ม

ลักษณะการใช้คล้าย [Paired t-test](#pair-t) สำหรับ Non-normal distribution

$$
V = \sum_{i=1}^{N_{r}}[sgn(x_{2,i} - x_{1,i}) \cdot R_{i}]
$$

$$
sgn(x) =\begin{cases} -1 \quad \text{if} \, x < 1,  \\0 \quad \ \ \  \text{if} \, x = 0,\\1 \quad \ \ \  \text{if} \, x > 0\end{cases}
$$

$$
V = min(V_{-}, V_{+})
$$

สมมติการวัด Wound healing assay (วัดการเคลื่อนที่ของเซลล์) ก่อนและหลัง Treat ยา

```{r cell_migration, echo = FALSE, out.width= "60%", fig.align ="center"}
knitr::include_graphics("Picture/cell_migration.jpg")
```

```{r wilcox_sign}
set.seed(123)

treat <- data.frame(sample = 1:20,
  Before = runif(20, min = 400, max = 500),
           After = detectnorm::rnonnorm(20, mean = 400, sd = 30, skew = 10, kurt = 5)$dat)

head(treat, 10)

wilcox.test(treat$Before, treat$After, paired = TRUE, exact = TRUE)
```

ลองคำนวณเอง หลักการคือ

-   คำนวณความต่างของก่อนและหลัง (หรือคู่เทียบ)

-   จัดอันดับของข้อมูลโดยเรียงจาก น้อยไปมาก และให้อันดับเป็นตัวเลข (อันดับที่เท่ากัน ให้เป็นค่าเฉลี่ยของลำดับนั้น เช่น อันดับ 2, 3, 4 เท่ากัน ให้อันดับเป็น (2+3+4)/3 = 5 ทุกตัวแปร)

-   คำนวณค่า $V$ โดยแยกเครื่องหมาย `+` และ `-` และเลือกค่า $V$ ที่น้อยที่สุด

```{r wilcox_sign_manual}
treat_rank <- treat |> mutate(Diff = Before-After) |> 
                mutate(Absdiff = abs(Diff)) |> 
                mutate(Rank = rank(Absdiff, ties.method = "average")) 
treat_rank

sign_rank <- treat_rank |> group_by(sign(Diff)) |> 
              summarize(rank_sum = sum(Rank))

V <- min(sign_rank$rank_sum)
V

pval <- psignrank(V, 20,20)*2
pval
```

### Kruskal-Wallis test

คือ การเปรียบเทียบค่าเฉลี่ยของ**ลำดับ**ว่ามาจากประชากรเดียวกันหรือไม่ ลักษณะการใช้เช่นเดียวกับ [ANOVA](#ANOVA)

$$
H = (N-1)\frac{\sum^{g}_{i=1}n_{i}(\bar{r_{i}}-\bar{r})^{2}}{\sum^{g}_{i=1}\sum^{n_{i}}_{j=1}(r_{ij}-\bar{r})^{2}}
$$

```{r iris_kruskal}
iris_pw_all <- df |> 
               select(Petal.Width, Species) # 3 groups

iris_kw <- kruskal.test(Petal.Width ~ Species, data = iris_pw_all)
iris_kw$p.value
```

ลองคำนวณเอง หลักการการจัดอันดับเหมือน [Wilcoxon's rank sum test](#wilcox-rs)

```{r iris_kruskal_manual}
iris_pw_all_ranked <- iris_pw_all |> arrange(`Petal.Width`) |> 
                        mutate(Rank = rank(`Petal.Width`, ties.method = "average"))
iris_pw_all_ranked
average_rank <- mean(iris_pw_all_ranked$Rank) # also = (nrow(iris_pw_all_ranked)+1)/2
average_rank

between_group_var <- iris_pw_all_ranked |>
                  group_by(Species) |> 
                   summarise(rank_var = ((mean(Rank) - average_rank)^2)*n())
between_group_var
within_group_var <- iris_pw_all_ranked |> 
                    mutate(rank_var = (Rank-average_rank)^2)
within_group_var
H <- ((nrow(iris_pw_all_ranked)-1))*sum(between_group_var$rank_var)/sum(within_group_var$rank_var)
H

pval <- pchisq(H, 2, lower.tail = FALSE)
pval
```

## Correlation test

### Spearman's correlation

เป็นการทดสอบความสัมพันธ์ในทิศทางของตัวแปรสองตัวแปรว่าเป็นไปในทางเดียวกันหรือไม่ (Monotonic relationship)

$$ \rho_{xy} =\frac{cov(x,y)}{s(x) s(y)} $$

$$
\rho_{xy} = \frac{\sum^{n}_{i=1}(x_{i}-\bar{x})(y_{i}-\bar{y})}{\sqrt{\sum^{n}_{i=1}(x_{i}-\bar{x})^{2}}\sqrt{\sum^{n}_{i=1}(y_{i}-\bar{y})^{2}}}
$$

โดย $x, y$ คือ ลำดับของข้อมูล (ไม่ใช่ตัวข้อมูลเอง) ส่งผลให้การทดสอบนี้ เป็นการทดสอบการเพิ่มขึ้นของลำดับ ไม่ใช่การเพิ่มขึ้นของข้อมูล ดังนั้น จึงไม่ใช่การทดสอบความสัมพันธ์เป็นเชิงเส้นเหมือน [Pearson's correlation](#pearson) แต่เป็นการทดสอบเพียงว่าข้อมูลไปในทิศทางเดียวันหรือไม่

```{r poly_cor, fig.path="figure/"}
poly_data <- data.frame(x = seq(-10, 10, length.out = 100)) |> 
  mutate(y = x^9+x+10+rnorm(100, mean = 0, sd =3))

ggplot(poly_data, aes(x=x,y=y)) + geom_point() + 
  geom_smooth(method = "lm", se = FALSE) +
  theme_bw()

cor(poly_data$x, poly_data$y, method = "pearson") # not quite linear
cor(poly_data$x, poly_data$y, method = "spearman") # monotonic
```

การทดสอบใน `R` ใช้ลักษณะ code เดียวกันกับ [Pearson's correlation](#pearson) แต่เปลี่ยน Argument เป็น `method = "pearson"` และข้อควรระวังก็คิดเหมือนกัน
