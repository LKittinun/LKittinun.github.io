[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"เอกสารนี้จัดทำขึ้นเพื่อจุดประสงค์ขึ้นเพื่อแนะนำการใช้ R เบื้องต้น สำหรับนักวิทยาศาสตร์ที่มีความสนใจในการใช้ R ในการวิเคราะห์ข้อมูล ซึ่งผู้ใช้งานจำเป็นจะต้องมีความรู้เรื่อง basic R ต่างๆ เล็กน้อย เพื่อที่จะได้ใช้งานได้อย่างไม่ติดขัดOnline version: https://tmrc.psu.ac.th/RNAseq/_book/index.html","code":""},{"path":"index.html","id":"r-installation","chapter":"Preface","heading":"R installation","text":"","code":""},{"path":"index.html","id":"r-console","chapter":"Preface","heading":"R console","text":"ผู้ที่ต้องการใช้ R สามารถดาวน์โหลดโปรแกรม ได้ที่นี่ https://cran.r-project.org/bin/windows/base/ โดยตัว R console จะมีหน้าตาดังภาพ","code":""},{"path":"index.html","id":"rstudio","chapter":"Preface","heading":"Rstudio","text":"อย่างไรก็ตาม การใช้งาน R ด้วยโปรแกรมนี้จะใช้งานค่อนข้างยาก โดยส่วนใหญผู้ใช้การจะต้องดาวน์โหลด IDE (integrated development environment) มาอำนวยความสะดวกในการเขียนคำสั่ง ซึ่ง IDE ที่ได้รับความนิยมมากที่สุด คือ Rstudio สามารถดาวน์โหลดได้ที่ https://posit.co/download/rstudio-desktop/นี่คือหน้าต่าง default ของ Rstudio โดยส่วนประกอบหลักคือText editor มุมซ้ายบน คือ ที่ๆ เราจะเขียน script ไว้เพื่อ runEnvironment มุมขวาบน คือ ส่วนที่เก็บข้อมูล variable ต่างๆ ที่เรา assignR console มุมซ้ายล่าง คือ ส่วนที่ R ทำงานจริงๆ ซึ่งก็คือ ตัว R console ที่เราโหลดมาตอนแรกนั่นเองส่วน Output ที่จะมีไว้แสดงที่อยู่ของไฟล์ รูปภาพที่ render ออกมา และ อื่นๆ ตามที่เราจะปรับแต่งเราสามารถเขียนไว้ script ไว้ที่ text editor และกด run คำสั่งแต่ละบรรทัดได้โดยการกด Ctrl + Enterยินดีด้วย! เท่านี้ท่านก็สามารถเริ่มใช้งาน R ได้แล้ว","code":""},{"path":"basic-r.html","id":"basic-r","chapter":"1 Basic R","heading":"1 Basic R","text":"","code":""},{"path":"basic-r.html","id":"basic-operation","chapter":"1 Basic R","heading":"1.1 Basic operation","text":"ท่านสามารถใช้ R ในการคำนวณต่างๆ ได้ เช่น บวก ลบ คูณ หาร ยกกำลัง เป็นต้น","code":"\n3+2## [1] 5\n3-2## [1] 1\n3*2## [1] 6\n3/2## [1] 1.5\n3^2## [1] 9\nlog(3)## [1] 1.098612\nsqrt(3)## [1] 1.732051\n3==3 # ตรวจสอบว่าข้อมูลเหมือนกันหรือไม่## [1] TRUE"},{"path":"basic-r.html","id":"variable","chapter":"1 Basic R","heading":"1.2 Variable","text":"","code":""},{"path":"basic-r.html","id":"variable-assignment","chapter":"1 Basic R","heading":"1.2.1 Variable assignment","text":"R สามารถเก็บข้อมูลต่างๆ ไว้ในตัวแปรได้ เพื่อที่สามารถนำมาใช้ในภายหลัง โดยการเก็บตัวแปรนั้นจะใช้เครื่องหมาย <-","code":"\nx <- 2\nx## [1] 2\ny <- 3\ny## [1] 3\nx+y # ท่านสามารถนำตัวแปรมาทำ operation ได้ตามปกติ## [1] 5\nx*y## [1] 6\nx <- 5 # การลงข้อมูลในตัวแปรเดิมจะเป็นการลบตัวแปรเก่า\nx## [1] 5\nhelloworld <- (x+y)^(x-y) # สามารถตั้งชื่ออะไรก็ได้ตราบใดที่ไม่เว้นวรรค\nhelloworld## [1] 64"},{"path":"basic-r.html","id":"type-of-variable","chapter":"1 Basic R","heading":"1.2.2 Type of variable","text":"R นั้นสามารถรองรับตัวแปรต่างๆ ได้หลากหลาย ซึ่งเป็นได้ทั้ง ตัวเลข หรือตัวอักษร หรือแม้กระทั่งเก็บหลายข้อมูลภายในตัวแปรเดียวได้ลักษณะตัวแปรต่างๆ ใน R มีดังนี้ในบางครั้ง class ที่ R ทำการเดามาให้ตั้งแต่แรกอาจจะไม่ใช่ลักษณะตัวแปรที่ท่านต้องการ ท่านสามารถใช้ คำสั่ง .*() ในการเปลี่ยน class ของตัวแปรนั้นได้","code":"\nx <- \"Hello world\" # ตัวอักษร\nx## [1] \"Hello world\"\ny <- c(1,2,3,4) # เก็บหลายตัวข้อมูลในตัวแปรเดียว\ny## [1] 1 2 3 4\nz <- list(c(1,2,3), 4, c(\"hello world\", \"I love R\"))  # เก็บข้อมูลในรูปแบบ list\nz## [[1]]\n## [1] 1 2 3\n## \n## [[2]]\n## [1] 4\n## \n## [[3]]\n## [1] \"hello world\" \"I love R\"\nclass(x) # ท่านสามารถเช็คชนิดของตัวแปรได้โดยใช้ function class()## [1] \"character\"\nx <- c(1,2,3,4,5)\nclass(x) # ไม่ต้องการให้คิดเป็นตัวเลข เช่น ตัวแปรที่จริงแล้วอาจจะเป็น กลุ่ม1 กลุ่ม2## [1] \"numeric\"\nx <- as.factor(x)\nclass(x) # เปลี่ยนเป็น factor## [1] \"factor\"\nx_list <- list(\"A\"= c(1,2,3,4,5), \"B\" = c(\"a\",\"b\",\"c\",\"d\",\"e\"))\nx_list## $A\n## [1] 1 2 3 4 5\n## \n## $B\n## [1] \"a\" \"b\" \"c\" \"d\" \"e\"\nas.data.frame(x_list) # เปลี่ยนเป็น dataframe"},{"path":"basic-r.html","id":"matrix-and-dataframe","chapter":"1 Basic R","heading":"1.3 Matrix and Dataframe","text":"เนื่องจาก R นั้นเป็นโปรแกรมที่ส่วนมากใช้ในการวิเคราะห์ทางสถิติ ซึ่งเกี่ยวข้อมูลส่วนใหญ่จะถูกเก็บในรูปของตาราง R จึงมีตัวแปรที่เก็บข้อมูลในรูปของตารางโดยเฉพาะ เรียกว่า matrix และ dataframe ซึ่งท่านจะใช้เป็นหลักในการวิเคราะห์ข้อมูลใน Rโดยตารางนั้นจะประกอบด้วยสองส่วนหลักๆ คล้าย excel spreadsheet ได้แก่Column (คอลัมน์): คือ ข้อมูลในแนวตั้ง ซึ่งแถวบนสุดจะเป็นชื่อ column นั้นๆRow (แถว): คือ ข้อมูลในแนวนอนโดย matrix นั้น สามารถเก็บ variable ในรูปแบบเดียวกันได้เท่านั้น แต่ dataframe สามารถเก็บข้อมูลต่างชนิดร่วมกันได้ โดยมีข้อแม้ว่า column เดียวกัน จะต้องเป็นข้อมูลชุดเดียวกัน","code":"\nmat <- matrix(c(1,2,3,4), nrow=2)\nmat##      [,1] [,2]\n## [1,]    1    3\n## [2,]    2    4\nclass(mat)## [1] \"matrix\" \"array\"\ndf <- data.frame(x=c(3,4),y=c(2,5),z=c(4,7))\ndf\nclass(df)## [1] \"data.frame\""},{"path":"basic-r.html","id":"subset","chapter":"1 Basic R","heading":"1.4 Subset","text":"ท่านสามารถดึงข้อมูลแค่บางส่วนออกมาจาก vector, list, matrix หรือ dataframe ได้ เรียกว่าการ subsetในส่วนของ matrix และ dataframe นั้น ท่านสามารถ subset ตามตำแหน่งได้ โดยการระบุ row และ column ตามลำดับในส่วนของ dataframe นั้น ท่านสามารถ subset ได้โดยใช้ชื่อของ column อีกด้วย","code":"\nx <- c(\"a\",\"b\",\"c\",\"d\")\nx[3] # subset โดยระบุตำแหน่ง## [1] \"c\"\nx[1:3] # subset หลายตำแหน่ง## [1] \"a\" \"b\" \"c\"\nx[c(1,3)] # subset หลากหลายตำแหน่งแบบจำเพาะ## [1] \"a\" \"c\"\ny <- list(c(1,2,3), c(\"a\",\"b\",\"c\"))\ny[1] # subset list ตามตำแหน่ง (จะได้ list ย่อยออกมา)## [[1]]\n## [1] 1 2 3\ny[[1]] # ดึงข้อมูลที่อยู่ใน list ออกมา## [1] 1 2 3\nmat##      [,1] [,2]\n## [1,]    1    3\n## [2,]    2    4\nmat[1,2] # 1st row, 2nd column## [1] 3\ndf\ndf[1,3] # 1st row, 3rd column## [1] 4\ndf[\"x\"] # subset เป็น column ย่อย\ndf[[\"x\"]] # subset ข้อมูลที่อยู่ใน column นั้น## [1] 3 4\ndf[[2, \"x\"]] # ระบุแถวด้วย## [1] 4\ndf$x # เหมือนกัน df[[\"x\"]]## [1] 3 4"},{"path":"r-function.html","id":"r-function","chapter":"2 R function","heading":"2 R function","text":"function (ฟังก์ชัน) คือ ชุดของคำสั่งที่จะสั่งการให้ R ทำงานตามจุดประสงค์ที่ท่านตั้งไว้ โดยตัว function นั้น จะประกอบไปด้วยfunction ที่มีมาพร้อมกับ R ตั้งแต่ต้น (base R function)function ที่ผู้นิพนธ์ท่านอื่นเขียนไว้ และรวบรวมมาเป็น ชุดของ function เรียกว่า packagefunction ที่ท่านเขียนขึ้นมาเอง","code":""},{"path":"r-function.html","id":"anatomy-of-function","chapter":"2 R function","heading":"2.1 Anatomy of function","text":"function นั้นประกอบด้วย 4 ส่วน คือ 1. Function name (ชื่อฟังก์ชัน) 2. Argument (รายละเอียดของฟังก์ชัน) 3. Function body (รายละเอียดของฟังก์ชัน) 4. Return (ผลลัพธ์ของฟังก์ชัน)ยกตัวอย่างฟังก์ชันหา ค่าเฉลี่ยของข้อมูลจะเห็นว่า function นี่รับข้อมูล 2 ตัวแปร คือ x และ y ซึ่งท่านจะต้องแทนค่าที่ท่านต้องการลงไปใน function หลังจากนั้น function จะทำการประมวลผลและส่งผลลัพธ์กลับมาในผู้เริ่มต้น ส่วนใหญ่ท่านมักจะไม่ใช้ function ที่เขียนขึ้นมาเองมากนัก เนื่องจาก basic operation ส่วนใหญ่จะมีผู้นิพนธ์ขึ้นมาให้แล้ว","code":"\nfind_mean <- function(x, y){\n  (x + y)/2\n}\n\nfind_mean(2, 3)## [1] 2.5\nfind_mean(3, 5)## [1] 4"},{"path":"r-function.html","id":"base-r-function","chapter":"2 R function","heading":"2.2 Base R function","text":"Base R function คือ function ที่ติดกับ R มาตั้งแต่แรก ซึ่งท่านสามารถเรียกใช้ได้เลยโดยไม่ต้องทำการเรียก package ขึ้นมาก่อนในส่วนของการ manipulate dataframe นั้น คำสั่งต่างๆ ที่น่ารู้มีดังนี้สามารถดู base R function ทั้งหมดได้ที่ https://stat.ethz.ch/R-manual/R-devel/library/base/html/00Index.htmlถ้าท่านต้องการดูว่า function นั้นใช้งานอย่างไร ให้ใส่เครื่องหมาย ? หน้า function นั้น เช่น ?mean() ?colSums()","code":"\nmax(c(1,2,4,5,5,68)) # find max value## [1] 68\nmin(c(1,4,5,6,-20)) # find min value## [1] -20\nmean(c(1,2,3,4)) # find mean## [1] 2.5\nmedian(c(1,2,5,3,4)) # find median## [1] 3\nunique(c(1,1,1,1,2,2,4,5,5,6,7,8)) # display only unique values## [1] 1 2 4 5 6 7 8\ndf <- data.frame(x = c(3,3,6,7,8,9),y = c(2,5,8,1,2,3),z = c(4,7,9,4,7,8))\ndf\nhead(df, 5) # ดู 5 แถวแรก\ntail(df , 5) # ดู 5 แถวล่าง\nrowMeans(df) # หาค่า mean แต่ละแถว## [1] 3.000000 5.000000 7.666667 4.000000 5.666667 6.666667\ncolMeans(df) # หาค่า mean แต่ละ columns##   x   y   z \n## 6.0 3.5 6.5\nrownames(df) # ชื่อแถว## [1] \"1\" \"2\" \"3\" \"4\" \"5\" \"6\"\ncolnames(df) # ชื่อ column## [1] \"x\" \"y\" \"z\""},{"path":"what-is-tidyverse.html","id":"what-is-tidyverse","chapter":"3 What is tidyverse","heading":"3 What is tidyverse","text":"Tidyverse เป็น package ซึ่งนิพนธ์โดย Haley Wickham และคณะ โดย function ส่วนใหญ่ใน tidyverse นั้นเกี่ยวข้องกับการปรับแต่งข้อมูลจาก dataframe ซึ่งจะอำนวยความสะดวกให้ท่านสามารถทำงานได้มากขึ้นกว่าการใช้ base R ข้อเสียของ tidyverse นั้น อาจจะทำให้ run ช้ากว่า และมีปรับแต่งให้ตรงกับการใช้งานจำเพาะได้ยากกว่า แต่สำหรับผู้ที่ไม่ใช่ R hardcore นั้น tidyverse ถือว่าเป็น package ที่อำนวยความสะดวกได้อย่างดีเยี่ยมการจะใช้งาน package ใดๆ นั้น เริ่มจากท่านจะต้องติดตั้ง package นั้นลงบนเครื่องของท่านก่อน โดยคำสั่ง install.packages() โดยการโดย tidyverse นั้นจะเป็น package ใหญ่ และจะแบ่งเป็นหลาย package ย่อยๆ ได้อีก โดยท่านสามารถเรียกใช้ ทั้งหมดได้ หรือ เรียกใช้แค่ package ย่อย","code":"\ninstall.packages(\"tidyverse\") \nlibrary(tidyverse) "},{"path":"importing-data.html","id":"importing-data","chapter":"4 Importing data","heading":"4 Importing data","text":"","code":""},{"path":"importing-data.html","id":"importing-data-with-readr","chapter":"4 Importing data","heading":"4.1 Importing data with readr","text":"ก่อนที่ท่านจะทำการวิเคราะห์ข้อมูลได้นั้น ท่านจำเป็นที่จะต้องนำข้อมูลเข้ามาใน R ให้ได้ก่อน ซึ่ง tidyverse ได้มี package สำหรับการนำข้อมูลจากสกุลไฟล์ที่เป็นที่นิยมส่วนใหญ่เข้าสู่ R ได้เกือบทั้งหมด โดยใช้ function read_*()ไฟล์ที่ได้อ่านเข้ามานี้ คือ gene expression ของ DNA microarray ในชิ้นเนื้อผู้ป่วยมะเร็งปากมดลูก ซึ่งจะถูกนำไปใช้ต่อใน ตัวอย่างท้ายบท","code":"\nlibrary(readr) # ต้อง run ทุกครั้งที่จะใช้งาน\n\nGSE63514 <- read_csv(\"Resource/GSE63514_norm.csv\")\n\nhead(GSE63514, 10) \nGSE63514_meta <- read_csv(\"Resource/GSE63514_meta.csv\")\n\nhead(GSE63514_meta, 10)"},{"path":"importing-data.html","id":"other-packages","chapter":"4 Importing data","heading":"4.2 Other packages","text":"ท่านสามารถเขียนข้อมูลจาก R ลงไปในไฟล์ที่ท่านต้องการด้วย write_()* อีกด้วย อย่างไรก็ตาม แม้ว่า readr นั้นจะสามารถอ่านและเขียนไฟล์ได้ครอบคลุมเป็นอย่างมาก ในบางสกุลไฟล์นั้น อาจจะต้องใช้การอ่านจาก package อื่น","code":""},{"path":"data-wrangling.html","id":"data-wrangling","chapter":"5 Data wrangling","heading":"5 Data wrangling","text":"","code":""},{"path":"data-wrangling.html","id":"data-manipulation-with-dplyr","chapter":"5 Data wrangling","heading":"5.1 Data manipulation with dplyr","text":"dplyr คือ package ย่อยของ tidyverse ซึ่งทำหน้าที่จัดการ dataframe ที่ท่านนำเข้าไปใน R ให้เป็นในรูปแบบที่ท่านต้องการ","code":"\nlibrary(dplyr) "},{"path":"data-wrangling.html","id":"basic-dataframe-manipulation","chapter":"5 Data wrangling","heading":"5.1.1 Basic dataframe manipulation","text":"ในกรณีนี้จะใช้ข้อมูลตัวอย่าง iris เพื่อสาธิตการใช้ dplyr โดย iris เป็นข้อมูลของความยาวกลีบของพันธุ์ดอกไม้ต่างๆรูปจาก: https://www.datacamp.com/tutorial/machine-learning--rfunction หลักๆ ของ dplyr จะเกี่ยวข้องกับ data manipulation เป็นส่วนใหญ่ ในที่นี้จะแนะนำที่จำเป็นต้องใช้ในบทอื่นglimpse() มีไว้ดูภาพรวมข้อมูลselect() เลือก column ที่ต้องการโดยใช้ตำแหน่งหรือชื่อ column ก็ได้filter() กรองแถว (row) ที่ต้องการ โดยต้องระบุ ว่าต้องการข้อมูล ที่ column ไหน และต้องการกรองค่าที่เท่าไรสังเกตว่าจะเห็นเครื่องหมาย |> ซึ่งใน R ท่านจะเรียกว่า “pipe operator” เป็นสิ่งที่เป็นเอกลักษณ์ใน R ซึ่งส่งผลให้สามารถ run operation ได้ต่อๆ กัน เพื่อให้อ่านได้ง่ายบรรทัดสุดท้าย สำหรับ dataframe จะไม่สามารถดึงมาทั้ง column ได้ ซึ่งจะต้องใช้ข้อมูลอีกแบบ (tibble) แต่จะไม่กล่าวถึง ณ ที่นี่Note: การ subset โดย dplyr นั้นสามารถทำใน dataframe/tibble เท่านั้น ไม่สามารถทำใน matrix ได้ (ต้องใช้วิธีของ base R)ในส่วนการเรียงข้อมูลนั้นจะใช้ function arrange()mutate() เป็นคำสั่งที่ใช้ในการสร้างคอลัมน์ใหม่ให้เป็นในแบบที่ต้องการได้ท่านสามารถจัดกลุ่มตัวแปรได้โดยใช้ group_by() โดยมักจะใช้คู่กับ summarize() ซึ่งเป็นคำสั่งที่ใช้ในการสรุปข้อมูลทั้งหมดตามที่ต้องการrename() สามารถใช้ในการเปลี่ยนชื่อคอลัมน์ ระวังว่าชื่อที่ต้องการจะอยู่ด้านซ้ายของเครื่องหมาย = ซึ่งไม่เหมือนคำสั่งอื่น","code":"\ndf <- iris # โหลด dataframe ตัวอย่างที่ติดมากับ base R\nhead(df, 5)\nglimpse(df)## Rows: 150\n## Columns: 5\n## $ Sepal.Length <dbl> 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.8, 4.8, 4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5.…\n## $ Sepal.Width  <dbl> 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3.0, 3.0, 4.0, 4.4, 3.9, 3.5, 3.8, 3.…\n## $ Petal.Length <dbl> 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.6, 1.4, 1.1, 1.2, 1.5, 1.3, 1.4, 1.7, 1.…\n## $ Petal.Width  <dbl> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.4, 0.4, 0.3, 0.3, 0.…\n## $ Species      <fct> setosa, setosa, setosa, setosa, setosa, setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\ndf |> select(Species) |> head(5) # เลือก column \"Species\"\ndf |> select(2) |> head(5) # เลือก column ที่ 2\ndf |> select(1:2) |> head(5) # เลือก 2 column\ndf |> select(contains(\"Length\")) |> head(5) # เลือก column ที่มีคำว่า \"Length\"\n# เลือกแถวที่ Species == virginica\ndf |>  filter(Species == \"virginica\") |>  head(5)\n# เลือกแถวที่ Species = setosa, Sepal.Length = 5.4\ndf |>  \n  filter(Species == \"setosa\" & Sepal.Length == 5.4) |>  head(5)\n# เลือกแถวที่ Sepal.Length = 5.1 หรือ 4.9\ndf |>  filter(Sepal.Length == 5.1 | Sepal.Length == 4.9) |>  head(10)\n# เลือกแถวที่ Species = setosa คอลัมน์ Sepal.Length\ndf |> \n  filter(Species == \"setosa\") |> \n  select(Sepal.Length) |> head(5)\n# เหมือนกับข้างบน แต่ไม่ใช้ pipe operator จะทำความเข้าใจได้ยากกว่า\nselect(filter(df, Species == \"setosa\"), Sepal.Length) |>  head(5)\n# ใช้แค่ base R solution จะไม่สามารถดึงออกมาเป็น dataframe ได้\ndf[df[\"Species\"] == \"setosa\", \"Sepal.Length\"]##  [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2 5.2\n## [30] 4.7 4.8 5.4 5.2 5.5 4.9 5.0 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0\ndf |> \n  arrange(Sepal.Length) |> head(5) # เรียง Sepal.Length จากน้อยไปมาก\ndf |> \n  arrange(desc(Sepal.Length)) |>  head(5) # เรียง Sepal.Length จากมากไปน้อย\ndf |> \n  mutate(Sepal_mm = Sepal.Length*100) # มิลลิเมตร\ndf |> \n  mutate(Sepal.Length = log10(Sepal.Length)) # สามารถแทนที่ column เดิมได้ด้วย\ndf |>  \n  group_by(Species) |>  # จัดกลุ่มตาม Species\n  summarize(Sepal.Length = sum(Sepal.Length), Sepal.Width = mean(Sepal.Width)) # รวมความยาวทั้งหมด และเฉลี่ยความกว้าง\ndf |> \n  rename(\"Sepal_length\" = \"Sepal.Length\", \"Sepal_width\" = \"Sepal.Width\") "},{"path":"data-wrangling.html","id":"joining-data","chapter":"5 Data wrangling","heading":"5.1.2 Joining data","text":"หลายครั้งที่การจัดการกับข้อมูลนั้นมีที่มาจากหลายส่วน โดยคอลัมน์หลักร่วมเพียงไม่กี่คอลัมน์ ผู้วิเคราะห์สามารถรวมตารางจากหลายแห่งเข้าด้วยกันได้โดยการใช้คำสั่ง x_join เพื่อความสะดวกในการวิเคราะห์","code":""},{"path":"data-wrangling.html","id":"mutating-join","chapter":"5 Data wrangling","heading":"5.1.2.1 Mutating join","text":"Mutating join คือการรวมตารางสองตารางเข้าด้วยกันภายใต้เงื่อนไขต่างๆ ในคอลัมน์หลักที่กำหนดต่อไปจะใช้ตารางดังต่อไปนี้ในการแสดงตัวอย่างInner join รวมบรรทัดที่มีตัวแปรที่มีร่วมกันทั้งสองตารางOuter join/Full join รวมทุกบรรทัดLeft join รวมบรรทัดจากตาราง y ที่มีตัวแปรในตาราง x และคงบรรทัดในตาราง x ทั้งหมดRight join รวมบรรทัดจากตาราง x ที่มีตัวแปรในตาราง y และคงบรรทัดในตาราง y ทั้งหมด","code":"\ninner_join(score_df, grade_df, by = \"Name\")\nfull_join(score_df, grade_df, by = \"Name\")\nleft_join(score_df, grade_df, by = \"Name\")\nright_join(score_df, grade_df, by = \"Name\")"},{"path":"data-wrangling.html","id":"filtering-join","chapter":"5 Data wrangling","heading":"5.1.2.2 Filtering join","text":"Filtering join คือการกรองบรรทัดในตาราง xโดยเงื่อนไขจากตาราง ysemi join กรองบรรทัดในตาราง x ที่มีตัวแปรในตาราง yanti join กรองบรรทัดในตาราง x ที่ไม่มีตัวแปรในตาราง y","code":"\nsemi_join(score_df, grade_df, by = \"Name\")\nanti_join(score_df, grade_df, by = \"Name\")"},{"path":"data-wrangling.html","id":"reshape","chapter":"5 Data wrangling","heading":"5.2 Reshaping data with tidyr","text":"","code":""},{"path":"data-wrangling.html","id":"data-structure","chapter":"5 Data wrangling","heading":"5.2.1 Data structure","text":"โดยปกติแล้วรูปแบบลักษณะของการบันทึกข้อมูลนั้นจะมีอยู่ 2 ลักษณะWide form เป็นลักษณะที่ง่ายต่อการบันทึก วิเคราะห์และอ่านผลเบื้องต้น โดยมีรูปแบบคือ ในแต่ละแถวนั้น จะมีข้อมูลหลักที่ไม่ซ้ำกัน (มักจะเป็นข้อมูลระบุตัวตน)Long form เป็นลักษณะที่ง่ายต่อการ visualize โดยมีรูปแบบคือ สามารถมีข้อมูลหลักที่ซ้ำกันได้ลองทำการดูที่ข้อมูล iris อีกครั้งจะเห็นว่า ข้อมูลในแต่ละแถวนั้น คือ ดอกไม้ 1 ดอก จำนวนคอลัมน์จะมากกว่าข้อมูลแบบ long form","code":"\nhead(df, 10)\ndf_id <- df |> \n  mutate(flower_id = row_number(), \n         .before = everything()) # สร้าง unique id ดอกไม้แต่ละดอก\n\nhead(df_id)"},{"path":"data-wrangling.html","id":"wide-to-long","chapter":"5 Data wrangling","heading":"5.2.2 Wide to long","text":"ท่านสามารถเปลี่ยนข้อมูลจาก wide form เป็น long form ได้โดย package tidyr โดยใช้ function pivot_longer()ซึ่งจะทำให้สามารถวิเคราะห์ข้อมูลได้สะดวกขึ้น ยกตัวอย่างถ้าเราต้องการสรุปข้อมูลชุดนี้ถ้าลองทำในข้อมูล wide formจะเห็นว่าค่อนข้าง intensive และผิดพลาดง่ายปล. อย่างไรก็ตาม dplyr ในสมัยนี้มีการพัฒนาไปมาก การวิเคราะห์ ใน wide form ก็สามารถทำได้โดยง่าย ขึ้นอยู่กับว่าถนัดแบบใดมากกว่าอีก ประเด็นสำคัญ ของข้อมูลประเภท long form นั้นคือ สามารทำ visualization ที่ซับซ้อนได้ดีกว่า wide form เป็นอย่างมาก ดังตัวอย่าง Boxplot1, Boxplot2","code":"\nlong_df <- df_id |> \n    pivot_longer(cols = !c(flower_id, Species), \n                 names_to = \"Metrics\", values_to = \"cm\") #ไม่รวมคอลัมน์ Species\n\nhead(long_df,10)\nsummary_df <- long_df |> \n  group_by(Species, Metrics) |>\n  summarize(`Median (cm)` = median(cm),`Mean (cm)` = mean(cm), `sd (cm)` = sd(cm))\n\nsummary_df\ndf |> \n  group_by(Species) |> \n  summarize(mean_Petal_L = mean(Petal.Length), \n            median_Petal_L = median(Petal.Length), \n            sd_Petal_L = sd(Petal.Length),\n            mean_Petal_W = mean(Petal.Width), \n            median_Petal_W = median(Petal.Width), \n            sd_Petal_W = sd(Petal.Width),\n            mean_Setal_L = mean(Sepal.Length), \n            median_Setal_L = median(Sepal.Length), \n            sd_Setal_L = sd(Sepal.Length),\n            mean_Setal_W = mean(Sepal.Width), \n            median_Setal_W = median(Sepal.Width), \n            sd_Setal_W = sd(Sepal.Width),\n            )\ndf |> \n  group_by(Species) |>    \n  dplyr::summarize(across(everything(), list(median = median, mean = mean, sd = sd)))"},{"path":"data-wrangling.html","id":"long-to-wide","chapter":"5 Data wrangling","heading":"5.2.3 Long to wide","text":"ท่านสามารถเปลี่ยนกลับเป็น wide form ได้เช่นกันหรือท่านอยากจะเปลี่ยนข้อมูลที่สรุปแล้วให้เป็น wide form ก็เป็นได้","code":"\nwide_df <- long_df |> \n    pivot_wider(names_from = \"Metrics\", values_from = \"cm\")\n\nhead(wide_df, 10)\nsummary_df |> \n  pivot_wider(names_from = \"Metrics\", \n              values_from = c(\"Median (cm)\" ,\"Mean (cm)\", \"sd (cm)\"))"},{"path":"data-visualization.html","id":"data-visualization","chapter":"6 Data visualization","heading":"6 Data visualization","text":"","code":""},{"path":"data-visualization.html","id":"ggplot2","chapter":"6 Data visualization","heading":"6.1 General visualization with ggplot2","text":"ggplot2 คือ package ย่อยอีกตัวของ tidyverse ซึ่งใช้สำหรับการพล็อตกราฟ","code":""},{"path":"data-visualization.html","id":"simple-anatomy-of-ggplot","chapter":"6 Data visualization","heading":"6.1.1 (Simple) Anatomy of ggplot","text":"aes คือ aesthetic ซึ่งหมายถึงการ map ข้อมูลของท่านเข้ากับตำแหน่งของกราฟ\nx = แกน x, y = แกน y\ncol = สี, fill = สีพื้นหลัง\nx = แกน x, y = แกน ycol = สี, fill = สีพื้นหลังgeom_*() คือ การกำหนดว่าท่านต้องการที่จะ plot กราฟอะไรtheme_*() คือ การกำหนด theme ของกราฟ เพื่อความสวยงาม เช่น theme_bw(), theme_classic()การสร้างภาพที่สมบูรณ์นั้นมีส่วนจำเป็นที่ประกอบด้วย aes และ geom ตรงส่วนอื่นเป็นส่วนเสริมที่จะช่วยให้ภาพมีความสวยงามขึ้นสังเกตว่าจะยังไม่มีกราฟใดๆ ปรากฏ ท่านจำเป็นต้องใช้ function geom เพื่อทำการสร้างภาพนั้นขึ้น","code":"ggplot(data = your_data, aes(x = x, y = y, col = col, fill = fill)) +\n  geom_*() +\n  theme_*() +\n  ...\nlibrary(ggplot2) \ndf\nggplot(df, aes(x = Sepal.Width, y = Sepal.Length))"},{"path":"data-visualization.html","id":"scatter-plot","chapter":"6 Data visualization","heading":"6.1.2 Scatter plot","text":"สังเกตการ mapping ของ aes()","code":"\nggplot(df, aes(x = Sepal.Width, y = Sepal.Length, col = Species)) + geom_point()"},{"path":"data-visualization.html","id":"straight-line","chapter":"6 Data visualization","heading":"6.1.3 Straight line","text":"ท่านสามารถเพิ่มเส้นที่ท่านต้องการได้โดย geom_hline (แนวตั้ง), geom_vline (แนวนอน), geom_abline (แนวเฉียง)สังเกตว่าท่านสามารถปรับค่าจำพวก สี ลักษณะเส้นต่างๆ ได้ โดย parameter นั้น ต้องอยู่นอก aes มิเช่นนั้น function จะพยายามไปดึงข้อมูลจากกราฟมาที่ถูกต้อง ท่านต้องนำ col ไปอยู่นอก aes จึงจะได้สีที่ท่านต้องการ","code":"\nggplot(df, aes(x = Sepal.Width, y = Sepal.Length, col = Species)) + \n  geom_point() + \n  geom_hline(yintercept = 6, linetype = \"dashed\", col = \"red\", linewidth = 1) + \n  geom_vline(xintercept = 2.7, linetype = \"dotted\", col = \"blue\", linewidth = 1.25) + \n  geom_abline(intercept = 2, slope = 1, linetype = \"dotdash\", col = \"black\", linewidth = 1.5)\nggplot(df, aes(x = Sepal.Width, y = Sepal.Length, col = \"darkviolet\")) + # ผิด\n  geom_point() + \n  geom_hline(yintercept = 6, linetype = \"dashed\", col = \"red\", linewidth = 1) + \n  geom_vline(xintercept = 2.7, linetype = \"dotted\", col = \"blue\", linewidth = 1.25) + \n  geom_abline(intercept = 2, slope = 1, linetype = \"dotdash\", col = \"black\", linewidth = 1.5)\nggplot(df, aes(x = Sepal.Width, y = Sepal.Length)) + # ผิด\n  geom_point(col = \"darkviolet\") + \n  geom_hline(yintercept = 6, linetype = \"dashed\", col = \"red\", linewidth = 1) + \n  geom_vline(xintercept = 2.7, linetype = \"dotted\", col = \"blue\", linewidth = 1.25) + \n  geom_abline(intercept = 2, slope = 1, linetype = \"dotdash\", col = \"black\", linewidth = 1.5)"},{"path":"data-visualization.html","id":"bar-chart","chapter":"6 Data visualization","heading":"6.1.4 Bar chart","text":"geom_bar() ใช้สำหรับนับจำนวนของ column นั้น ไม่มีค่า yส่วน geom_col() จะรับค่า y ด้วย โดยข้อมูล x ที่ซ้ำกันจะถูกนำมารวมกันสังเกตว่าค่าที่ได้เกิดจากการรวมกันของข้อมูลทั้งคอลัมน์ (สังเกตที่เส้นสีดำเป็นเส้นต่อๆ กัน ไม่ใช่เส้นเดียว) ซึ่งมักไม่เป็นที่ต้องการในการแสดง โดยมักเกิดจากความผิดพลาดมากกว่า (โดยเฉพาะถ้าไม่ได้ใส่ col = black) และส่วนใหญ่มักจะใช้ในการแสดงค่าเฉลี่ยมากกว่าผลรวม ในการนี้ ควรใช้คำสั่ง dplyr::summarize() ในการสรุปข้อมูลก่อนจะเห็นว่ากราฟแสดงค่าเฉลี่ยซึ่งตรงตามความต้องการทั่วไปมากกว่า (สังเกตแกน y)","code":"\nggplot(df, aes(x = Species, fill = Species)) + # fill ไว้สำหรับแบ่งสีใน barchart\n  geom_bar(col = \"black\", width = 0.5) # ความกว้าง 50% \nggplot(df, aes(x = Species, y = Sepal.Width, fill = Species)) + \n  geom_col(col = \"black\", width = 0.5) \ndf |> \n  group_by(Species) |> \n  summarize(across(everything(), mean)) |> \n  ggplot(aes(x = Species, y = Sepal.Width, fill = Species)) + \n  geom_col(col = \"black\", width = 0.5) "},{"path":"data-visualization.html","id":"multi_boxplot","chapter":"6 Data visualization","heading":"6.1.5 Box plot","text":"ทำการสร้าง box plotถ้าท่านต้องการสร้าง plot ที่แสดงหลาย metrics ท่านจะต้องเปลี่ยนข้อมูลเป็น long form เสียก่อน","code":"\nggplot(df, aes(x = Species, y = Sepal.Width, fill = Species)) +\n  geom_boxplot(width = 0.5) \nhead(long_df, 10)\nlong_df |> \n    ggplot(aes(x = Species, y = cm, fill = Metrics)) +\n    geom_boxplot() "},{"path":"data-visualization.html","id":"histogram","chapter":"6 Data visualization","heading":"6.1.6 Histogram","text":"ในการทำงานสถิตินั้น โดยส่วนใหญ่จะต้องทำการตรวจสอบการกระจายของข้อมูลก่อนวิเคราะห์ทางสถิติ ซึ่งสามารถทำได้โดยใช้ geom_histogram()หรือ geom_density()ทั้งนี้ ท่านสามารถพล็อตหลายกราฟเข้าด้วยกันได้ ด้วยการ + ตามหลังไปเรื่อยๆ เพียงแต่ต้องระวังเรื่อง scale ที่ต้องเป็นระดับเดียวกัน","code":"\nggplot(df, aes(x = Sepal.Width)) + \n  geom_histogram(fill = \"skyblue\", binwidth = 0.1)  # binwidth = ความกว้างของแต่ละช่วงข้อมุล\nggplot(df, aes(x = Sepal.Width)) + \n  geom_density(fill = \"violet\", alpha = 0.5)\nggplot(df, aes(x = Sepal.Width)) +\n  geom_histogram(aes(y = after_stat(density)), binwidth = 0.1, fill = \"skyblue\") + # ปรับเป็นความถี่\n  geom_density(fill = \"violet\", alpha = 0.5) +\n  theme_bw() # ลบภาพพื้นหลังสีเทาออก"},{"path":"data-visualization.html","id":"fitting-a-statistical-model","chapter":"6 Data visualization","heading":"6.1.7 Fitting a statistical model","text":"ท่านสามารถที่พล็อต statistical model ได้โดยใช้ geom_smooth() ยกตัวอย่าง เช่น ถ้าอยากดูความสัมพันธ์ของ Sepal.Length และ Petal.Length","code":"\nggplot(df, aes(x = Sepal.Length, y = Petal.Length, color = Species)) + # สีตาม Species\n  geom_point(color = \"black\") +\n  geom_smooth(method = \"loess\") + # fit a LOESS model\n  theme_bw()\nggplot(df, aes(x = Sepal.Length, y = Petal.Length, color = Species)) + # สีตาม Species\n  geom_point(color = \"black\") +\n  geom_smooth(method = \"lm\") + # fit a linear model\n  theme_bw()"},{"path":"data-visualization.html","id":"faceting","chapter":"6 Data visualization","heading":"6.1.8 Faceting","text":"ในบางครั้งท่านอาจจะต้องการที่จะพล็อตกราฟแยกกันเป็นส่วนๆ มากกว่ารวมกันในกราฟเดียว ท่านสามารถแบ่ง partition ของการพล็อตแต่ละกลุ่มได้โดยใช้ facetทั้งหมดที่แสดงนี้ เป็นเพียงกราฟพื้นฐานเท่านั้น ยังมีการปรับแต่งอื่นๆ ได้อีกมาก สามารถศึกษาเพิ่มเติมได้ที่:Function reference: https://ggplot2.tidyverse.org/reference/Function reference: https://ggplot2.tidyverse.org/reference/Plot gallery: https://r-graph-gallery.com/Plot gallery: https://r-graph-gallery.com/","code":"\nggplot(df, aes(x = Sepal.Length, y = Petal.Length, color = Species)) + # สีตาม Species\n  geom_point(color = \"black\") +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(~Species) + # แบ่งเป็นหลายกลุ่ม\n  theme_bw()\nggplot(df, aes(x = Sepal.Length,  fill = Species)) + # สีตาม Species\n  geom_histogram(binwidth = 0.1) +\n  facet_wrap(~Species, scales = \"free_x\", nrow = 2) + # ทำให้แกน x ไม่ fix ค่า\n  theme_bw()"},{"path":"GSE63514.html","id":"GSE63514","chapter":"7 Case study: Microarray visualization","heading":"7 Case study: Microarray visualization","text":"ต่อไปนี้จะเป็นตัวอย่างในการใช้ R ในการวิเคราะห์ข้อมูล molecular data เบื้องต้น โดยใช้ข้อมูลจาก GEO dataset GSE63514 ซึ่งเป็น gene expression microarray","code":""},{"path":"GSE63514.html","id":"import-files","chapter":"7 Case study: Microarray visualization","heading":"7.1 Import files","text":"ไฟล์แรกที่อ่านเข้ามาคือ GSE63514_norm.csv ซึ่งเป็นไฟล์ microarray expression ของชิ้นเนื้อปากมดลูก ประกอบด้วย ตัวอย่าง Normal , CIN1 , CIN2 , CIN3 , Cancer ในที่นี้เราจะทำการวิเคราะห์ 20,000 gene แรกส่วนที่สองคือ metadata (ข้อมูลระบุตัวตน) ของข้อมูลนี้ส่วนที่สามคือไฟล์ annotation ของ probe","code":"\nlibrary(tidyverse) \n\nGSE63514 <- read_csv(\"Resource/GSE63514_norm.csv\") \nGSE63514_20000 <- read_csv(\"Resource/GSE63514_norm.csv\") |> head(2000)\nnames(GSE63514_20000)##   [1] \"probe\"                                  \"GSM1551311_Normal-01_U133_Plus2.CEL.gz\"\n##   [3] \"GSM1551312_Normal-02_U133_Plus2.CEL.gz\" \"GSM1551313_Normal-03_U133_Plus2.CEL.gz\"\n##   [5] \"GSM1551314_Normal-04_U133_Plus2.CEL.gz\" \"GSM1551315_Normal-05_U133_Plus2.CEL.gz\"\n##   [7] \"GSM1551316_Normal-06_U133_Plus2.CEL.gz\" \"GSM1551317_Normal-07_U133_Plus2.CEL.gz\"\n##   [9] \"GSM1551318_Normal-08_U133_Plus2.CEL.gz\" \"GSM1551319_Normal-09_U133_Plus2.CEL.gz\"\n##  [11] \"GSM1551320_Normal-10_U133_Plus2.CEL.gz\" \"GSM1551321_Normal-11_U133_Plus2.CEL.gz\"\n##  [13] \"GSM1551322_Normal-12_U133_Plus2.CEL.gz\" \"GSM1551323_Normal-13_U133_Plus2.CEL.gz\"\n##  [15] \"GSM1551324_Normal-14_U133_Plus2.CEL.gz\" \"GSM1551325_Normal-15_U133_Plus2.CEL.gz\"\n##  [17] \"GSM1551326_Normal-16_U133_Plus2.CEL.gz\" \"GSM1551327_Normal-17_U133_Plus2.CEL.gz\"\n##  [19] \"GSM1551328_Normal-18_U133_Plus2.CEL.gz\" \"GSM1551329_Normal-19_U133_Plus2.CEL.gz\"\n##  [21] \"GSM1551330_Normal-20_U133_Plus2.CEL.gz\" \"GSM1551331_Normal-21_U133_Plus2.CEL.gz\"\n##  [23] \"GSM1551332_Normal-22_U133_Plus2.CEL.gz\" \"GSM1551333_Normal-23_U133_Plus2.CEL.gz\"\n##  [25] \"GSM1551334_Normal-24_U133_Plus2.CEL.gz\" \"GSM1551335_CIN1-01_U133_Plus2.CEL.gz\"  \n##  [27] \"GSM1551336_CIN1-02_U133_Plus2.CEL.gz\"   \"GSM1551337_CIN1-03_U133_Plus2.CEL.gz\"  \n##  [29] \"GSM1551338_CIN1-04_U133_Plus2.CEL.gz\"   \"GSM1551339_CIN1-05_U133_Plus2.CEL.gz\"  \n##  [31] \"GSM1551340_CIN1-06_U133_Plus2.CEL.gz\"   \"GSM1551341_CIN1-07_U133_Plus2.CEL.gz\"  \n##  [33] \"GSM1551342_CIN1-08_U133_Plus2.CEL.gz\"   \"GSM1551343_CIN1-09_U133_Plus2.CEL.gz\"  \n##  [35] \"GSM1551344_CIN1-10_U133_Plus2.CEL.gz\"   \"GSM1551345_CIN1-11_U133_Plus2.CEL.gz\"  \n##  [37] \"GSM1551346_CIN1-12_U133_Plus2.CEL.gz\"   \"GSM1551347_CIN1-13_U133_Plus2.CEL.gz\"  \n##  [39] \"GSM1551348_CIN1-14_U133_Plus2.CEL.gz\"   \"GSM1551349_CIN2-01_U133_Plus2.CEL.gz\"  \n##  [41] \"GSM1551350_CIN2-02_U133_Plus2.CEL.gz\"   \"GSM1551351_CIN2-03_U133_Plus2.CEL.gz\"  \n##  [43] \"GSM1551352_CIN2-04_U133_Plus2.CEL.gz\"   \"GSM1551353_CIN2-05_U133_Plus2.CEL.gz\"  \n##  [45] \"GSM1551354_CIN2-06_U133_Plus2.CEL.gz\"   \"GSM1551355_CIN2-07_U133_Plus2.CEL.gz\"  \n##  [47] \"GSM1551356_CIN2-08_U133_Plus2.CEL.gz\"   \"GSM1551357_CIN2-09_U133_Plus2.CEL.gz\"  \n##  [49] \"GSM1551358_CIN2-10_U133_Plus2.CEL.gz\"   \"GSM1551359_CIN2-11_U133_Plus2.CEL.gz\"  \n##  [51] \"GSM1551360_CIN2-12_U133_Plus2.CEL.gz\"   \"GSM1551361_CIN2-13_U133_Plus2.CEL.gz\"  \n##  [53] \"GSM1551362_CIN2-14_U133_Plus2.CEL.gz\"   \"GSM1551363_CIN2-15_U133_Plus2.CEL.gz\"  \n##  [55] \"GSM1551364_CIN2-16_U133_Plus2.CEL.gz\"   \"GSM1551365_CIN2-17_U133_Plus2.CEL.gz\"  \n##  [57] \"GSM1551366_CIN2-18_U133_Plus2.CEL.gz\"   \"GSM1551367_CIN2-19_U133_Plus2.CEL.gz\"  \n##  [59] \"GSM1551368_CIN2-20_U133_Plus2.CEL.gz\"   \"GSM1551369_CIN2-21_U133_Plus2.CEL.gz\"  \n##  [61] \"GSM1551370_CIN2-22_U133_Plus2.CEL.gz\"   \"GSM1551371_CIN3-01_U133_Plus2.CEL.gz\"  \n##  [63] \"GSM1551372_CIN3-02_U133_Plus2.CEL.gz\"   \"GSM1551373_CIN3-03_U133_Plus2.CEL.gz\"  \n##  [65] \"GSM1551374_CIN3-04_U133_Plus2.CEL.gz\"   \"GSM1551375_CIN3-05_U133_Plus2.CEL.gz\"  \n##  [67] \"GSM1551376_CIN3-06_U133_Plus2.CEL.gz\"   \"GSM1551377_CIN3-07_U133_Plus2.CEL.gz\"  \n##  [69] \"GSM1551378_CIN3-08_U133_Plus2.CEL.gz\"   \"GSM1551379_CIN3-09_U133_Plus2.CEL.gz\"  \n##  [71] \"GSM1551380_CIN3-10_U133_Plus2.CEL.gz\"   \"GSM1551381_CIN3-11_U133_Plus2.CEL.gz\"  \n##  [73] \"GSM1551382_CIN3-12_U133_Plus2.CEL.gz\"   \"GSM1551383_CIN3-13_U133_Plus2.CEL.gz\"  \n##  [75] \"GSM1551384_CIN3-14_U133_Plus2.CEL.gz\"   \"GSM1551385_CIN3-15_U133_Plus2.CEL.gz\"  \n##  [77] \"GSM1551386_CIN3-16_U133_Plus2.CEL.gz\"   \"GSM1551387_CIN3-17_U133_Plus2.CEL.gz\"  \n##  [79] \"GSM1551388_CIN3-18_U133_Plus2.CEL.gz\"   \"GSM1551389_CIN3-19_U133_Plus2.CEL.gz\"  \n##  [81] \"GSM1551390_CIN3-20_U133_Plus2.CEL.gz\"   \"GSM1551391_CIN3-21_U133_Plus2.CEL.gz\"  \n##  [83] \"GSM1551392_CIN3-22_U133_Plus2.CEL.gz\"   \"GSM1551393_CIN3-23_U133_Plus2.CEL.gz\"  \n##  [85] \"GSM1551394_CIN3-24_U133_Plus2.CEL.gz\"   \"GSM1551395_CIN3-25_U133_Plus2.CEL.gz\"  \n##  [87] \"GSM1551396_CIN3-26_U133_Plus2.CEL.gz\"   \"GSM1551397_CIN3-27_U133_Plus2.CEL.gz\"  \n##  [89] \"GSM1551398_CIN3-28_U133_Plus2.CEL.gz\"   \"GSM1551399_CIN3-29_U133_Plus2.CEL.gz\"  \n##  [91] \"GSM1551400_CIN3-30_U133_Plus2.CEL.gz\"   \"GSM1551401_CIN3-31_U133_Plus2.CEL.gz\"  \n##  [93] \"GSM1551402_CIN3-32_U133_Plus2.CEL.gz\"   \"GSM1551403_CIN3-33_U133_Plus2.CEL.gz\"  \n##  [95] \"GSM1551404_CIN3-34_U133_Plus2.CEL.gz\"   \"GSM1551405_CIN3-35_U133_Plus2.CEL.gz\"  \n##  [97] \"GSM1551406_CIN3-36_U133_Plus2.CEL.gz\"   \"GSM1551407_CIN3-37_U133_Plus2.CEL.gz\"  \n##  [99] \"GSM1551408_CIN3-38_U133_Plus2.CEL.gz\"   \"GSM1551409_CIN3-39_U133_Plus2.CEL.gz\"  \n## [101] \"GSM1551410_CIN3-40_U133_Plus2.CEL.gz\"   \"GSM1551411_Cancer-01_U133_Plus2.CEL.gz\"\n## [103] \"GSM1551412_Cancer-02_U133_Plus2.CEL.gz\" \"GSM1551413_Cancer-03_U133_Plus2.CEL.gz\"\n## [105] \"GSM1551414_Cancer-04_U133_Plus2.CEL.gz\" \"GSM1551415_Cancer-05_U133_Plus2.CEL.gz\"\n## [107] \"GSM1551416_Cancer-06_U133_Plus2.CEL.gz\" \"GSM1551417_Cancer-07_U133_Plus2.CEL.gz\"\n## [109] \"GSM1551418_Cancer-08_U133_Plus2.CEL.gz\" \"GSM1551419_Cancer-09_U133_Plus2.CEL.gz\"\n## [111] \"GSM1551420_Cancer-10_U133_Plus2.CEL.gz\" \"GSM1551421_Cancer-11_U133_Plus2.CEL.gz\"\n## [113] \"GSM1551422_Cancer-12_U133_Plus2.CEL.gz\" \"GSM1551423_Cancer-13_U133_Plus2.CEL.gz\"\n## [115] \"GSM1551424_Cancer-14_U133_Plus2.CEL.gz\" \"GSM1551425_Cancer-15_U133_Plus2.CEL.gz\"\n## [117] \"GSM1551426_Cancer-16_U133_Plus2.CEL.gz\" \"GSM1551427_Cancer-17_U133_Plus2.CEL.gz\"\n## [119] \"GSM1551428_Cancer-18_U133_Plus2.CEL.gz\" \"GSM1551429_Cancer-19_U133_Plus2.CEL.gz\"\n## [121] \"GSM1551430_Cancer-20_U133_Plus2.CEL.gz\" \"GSM1551431_Cancer-21_U133_Plus2.CEL.gz\"\n## [123] \"GSM1551432_Cancer-22_U133_Plus2.CEL.gz\" \"GSM1551433_Cancer-23_U133_Plus2.CEL.gz\"\n## [125] \"GSM1551434_Cancer-24_U133_Plus2.CEL.gz\" \"GSM1551435_Cancer-25_U133_Plus2.CEL.gz\"\n## [127] \"GSM1551436_Cancer-26_U133_Plus2.CEL.gz\" \"GSM1551437_Cancer-27_U133_Plus2.CEL.gz\"\n## [129] \"GSM1551438_Cancer-28_U133_Plus2.CEL.gz\"\nhead(GSE63514_meta, 10)\nhgu133plus2_genenames <- read_csv(\"Resource/hgu133plus2_genenames.csv\") |> \n  select(-1) # remove row number\nhead(hgu133plus2_genenames, 10)"},{"path":"GSE63514.html","id":"cleaning-data","chapter":"7 Case study: Microarray visualization","heading":"7.2 Cleaning data","text":"สมมติว่าในตัวอย่างนี้ จะทำการวิเคราะห์แค่ระหว่าง Normal, CIN1, และ Cancer เท่านั้น จึงจำเป็นที่จะต้องกรองข้อมูลที่ไม่ต้องการออกไปเสียก่อนเมื่อดูในตัวแปร exps_nc จะพบว่า probe นั้นเป็นชื่อเฉพาะของตัวเครื่อง ไม่ใช้ชื่อสากล ในที่นี้จะทำการเปลี่ยน probe ให้เป็นชื่อ gene นั้นๆ แต่ว่าชื่อ list รายชื่อนั้นเป็นชื่อทั้งหมดของ probe สังเกตได้จากจำนวนแถวที่ไม่เท่ากันในที่นี้ การใช้คำสั่ง *_join() จะทำให้สามารถรวมแค่แถวที่ต้องการได้","code":"\nexprs_nc <- GSE63514_20000 |> select(probe, contains(c(\"Normal\", \"CIN1\", \"Cancer\")))\nmeta_nc <- GSE63514_meta |> \n  filter(grepl(\"Normal|CIN1|Cancer\", title)) |> \n  select(title, `characteristics_ch1.1`, `dissection:ch1`)\nnames(exprs_nc) <- c(\"prob\", meta_nc$title) # เปลี่ยนชื่อให้อ่านง่าย\n\nhead(exprs_nc, 10)\nhead(meta_nc, 10)\nnrow(exprs_nc)## [1] 2000\nnrow(hgu133plus2_genenames)## [1] 54675\ngene_nc <- exprs_nc |> \n            left_join(hgu133plus2_genenames, by = c(\"prob\"=\"PROBEID\")) |> \n            relocate(c(\"SYMBOL\", \"ENTREZID\", \"GENENAME\"), .after = \"prob\")"},{"path":"GSE63514.html","id":"top10_boxplot","chapter":"7 Case study: Microarray visualization","heading":"7.3 Visualization","text":"ต่อไป เราจะทำการแสดงผล gene expression 10 ตัวที่มีการแสดงออกมากที่สุดในทั้ง experiment นี้ขั้นแรก เราจะทำการรวม intensity ทั้งหมดใน 1 gene ผ่าน function rowSums() และเรียง total_intensity จากมากไปน้อย หลังจากนั้นเลือก top10 intensity ออกมาโดยใช้ function head()จะเห็นว่าข้อมูลของเรา อยู่ในลักษณะ wide form ในการสร้าง boxplot นั้น ข้อมูลจำเป็นต้องอยู่ในลักษณะ long form เราจะใช้ function pivot_longer()ท่านอาจจะอยากเพิ่มเส้นค่าเฉลี่ยเพื่อดูว่า global mean intensity เป็นเท่าไรตัวกลุ่ม RPL ดูน่าสนใน เนื่องจาก intensity ใน cancer ต่ำกว่า global mean แต่จะมีนัยสำคัญหรือไม่ต้องใช้การวิเคราะห์ทางสถิติเพิ่มเติมทีหลังต่อไป เราอยากที่จะแบ่งว่า tissue ที่เป็น whole section กับ laser captured มีการแสดงออกที่แตกต่างกันอย่างไร เราจะใช้ facet_wrap() เข้ามาช่วยพล็อตอัตราส่วนจำนวนของ laser capture vs whole sectionเห็นว่าผลที่ได้ประหลาด เนื่องจาก laser capturedและ laser-captured เป็นตัวแปรซ้ำ ต้องแก้ไขเสียก่อนเมื่อข้อมูลที่ได้ถูกต้อง จะเห็นว่า มีเฉพาะกลุ่ม cancer เท่านั้น ที่มีการตัดแบบ whole sectionหลังจากนั้นเราจะทำการพล็อต intensity ในแต่ละ gene","code":"\ngene_symbol_mat <- gene_nc |> \n  select(-prob, -ENTREZID, -GENENAME) |> \n  mutate(total_intensity = \n           rowSums(select(gene_nc, -prob, -ENTREZID, -GENENAME, -SYMBOL)),\n         .before = \"Normal-01\") |> \n  arrange(desc(total_intensity)) \n\ntop10_intensity <- head(gene_symbol_mat,10)\ntop10_intensity\ntop10_long <- top10_intensity |> \n              select(-total_intensity) |> \n              pivot_longer(-SYMBOL, names_to = \"Case\", values_to = \"Intensity\") |> \n              separate(Case, into = c(\"Group\", \"Number\"), sep = \"-\", remove = FALSE)\nggplot(top10_long, aes(x = SYMBOL, y = Intensity, fill = Group)) + \n  geom_boxplot() +\n  theme_bw() +\n  theme(axis.text.x = \n          element_text(angle = 45, vjust = 1, hjust=1)) # หมุนแกน x เพื่อความสวยงาม\nglobal_mean_intensity <- mean(top10_long$Intensity)\nglobal_mean_intensity## [1] 12.99896\nggplot(top10_long, aes(x = SYMBOL, y = Intensity, fill = Group)) + \n  geom_boxplot() +\n  geom_hline(yintercept = global_mean_intensity, linetype = \"dashed\", color = \"darkviolet\", linewidth = 1) +\n  theme_bw() +\n  theme(axis.text.x = \n          element_text(angle = 45, vjust = 1, hjust=1))\ntop10_long_dissec <- top10_long |> \n                      left_join(select(meta_nc, title, `dissection:ch1`), \n                                by = c(\"Case\" = \"title\"))\ntop10_long_dissec\nggplot(top10_long_dissec, aes(x = `dissection:ch1`, fill = Group)) + \n  geom_bar(col = \"black\", width = 0.5, position = \"dodge\") + \n  theme_bw()\ntop10_long_dissec <- top10_long_dissec |> \n                      mutate(`dissection:ch1` = gsub(\"-\", \" \", `dissection:ch1`))\n\nggplot(top10_long_dissec, aes(x = `dissection:ch1`, fill = Group)) + \n  geom_bar(col = \"black\", width = 0.5, position = \"dodge\") + \n  theme_bw()\nggplot(top10_long_dissec, aes(x = SYMBOL, y = Intensity, fill = Group)) + \n  geom_boxplot() +\n  facet_wrap(~`dissection:ch1`) +\n  theme_bw() +\n  theme(axis.text.x = \n          element_text(angle = 45, vjust = 1, hjust=1))"},{"path":"hypothesis-testing.html","id":"hypothesis-testing","chapter":"8 Hypothesis testing","heading":"8 Hypothesis testing","text":"","code":""},{"path":"hypothesis-testing.html","id":"principle","chapter":"8 Hypothesis testing","heading":"8.1 Principle","text":"การทดสอบสมมติฐาน คือ การใช้วิธีทางสถิติในตอบคำถามสมมติฐานที่ต้องการ โดยมีขั้นตอน คือ","code":""},{"path":"hypothesis-testing.html","id":"สรางสมมตฐาน-construct-the-hypothesis","chapter":"8 Hypothesis testing","heading":"8.1.1 สร้างสมมติฐาน (Construct the hypothesis)","text":"สมมติฐานว่าง (Null hypothesis; \\(H_{0}\\)) คือสมมติฐานที่ต้องการทดสอบ ซึ่งเปรียบเทียบได้กับสิ่งที่ทุกคนมีความเชื่อกันอยู่แล้ว (default belief) หรือไม่ทราบแน่ชัดว่าเป็นอย่างไร ซึ่งจะเป็นแนวปฏิเสธไว้ก่อน คือ ไม่มีความแตกต่างกันสมมติฐานทางเลือก (Alternative hypothesis; \\(H_{}\\)) คือสมมติฐานที่คาดหวังว่าจะเป็นการค้นพบใหม่","code":""},{"path":"hypothesis-testing.html","id":"ทำการวเคราะหคาทางสถต-construct-the-test-statistics","chapter":"8 Hypothesis testing","heading":"8.1.2 ทำการวิเคราะห์ค่าทางสถิติ (Construct the test statistics)","text":"โดยเครื่องมือจะมีหลายรูปแบบตามลักษณะของข้อมูล เช่น t-test, Chi-square เป็นต้น ซึ่งผลลัพธ์จากการหาค่าทางสถิติจะเป็นไปตามการทดสอบนั้นๆ เช่น t-test: \\(t\\), Chi-square: \\(X^{2}\\), F-test: \\(F\\) เป็นต้น","code":""},{"path":"hypothesis-testing.html","id":"หา-p-value","chapter":"8 Hypothesis testing","heading":"8.1.3 หา p-value","text":"คือ โอกาสที่สามารถสังเกตค่าทางสถิติที่มากกว่าค่าการวิเคราะห์ทางสถิติที่โดยไม่ได้อยู่ภายใต้ \\(H_{0}\\) โดยทางปฏิบัติแล้วคือ การสร้างแบบจำลองข้อมูลภายใต้ \\(H_{0}\\) ขึ้นมาแล้วแล้วดูว่า ที่ค่าสถิตินั้น มีโอกาสไม่เกิดเท่าไรยกตัวอย่าง เมื่อวิเคราะห์ \\(t\\)-test จะทำการสร้าง t-distribution ขึ้นมา (ตัวอย่างของการวิเคราะห์ อยู่บทถัดไป ) ภายใต้ \\(H_{0}\\) ว่า mean = 10ที่ -0.7345 < \\(t\\) < 0.7345 (พื้นที่ใต้กราฟสีขาว) หมายถึงโอกาสที่ค่านั้นเกิดจากความบังเอิญภายใต้ \\(H_{0}\\) ที่ยังเป็นจริง คิดเป็น AUC ได้ที่ \\(t\\) < -0.7345 หรือ \\(t\\) > 0.7345 (พื้นที่ใต้กราฟสีฟ้า) หมายถึงโอกาสที่ค่านั้นไม่ได้เกิดจากความบังเอิญภายใต้ \\(H_{0}\\) ที่ยังเป็นจริง (extreme value) คิดเป็น AUC ได้โดย AUC_blue = p-value = พื้นที่ใต้กราฟสีฟ้า = ~46.4%","code":"\nlibrary(tidyverse)\nt_dist <- dt(seq(-5,5,0.01), df = 99) # t-distribution มี mean = 0 sd = 1\n\ntval <- 0.7345 # t-value วิธีคำนวณอยู่ในบท t-test\n\ndensity_df <- data.frame(x = seq(-5,5,0.01), y = t_dist) |>\n  mutate(area = ifelse(between(x,-tval,tval), TRUE,FALSE))\n\nggplot(density_df, aes(x,y)) + \n  geom_area(fill = \"skyblue\", color = \"black\") +\n  geom_area(data = filter(density_df, area), fill = \"white\", color = \"black\") +\n  geom_vline(xintercept = c(-tval,tval), linetype = \"dashed\") +\n  theme_bw()\ndensity_df |> \n  filter(area) |> \n  summarize(AUC_white = sum(y)) |> pull()## [1] 53.59248\ndensity_df |> \n  filter(!area) |> \n  summarize(AUC_blue = sum(y)) |> pull()## [1] 46.40728\np <- 2*pt(0.7345, 99, lower.tail = FALSE) \np # p-value## [1] 0.4643803"},{"path":"hypothesis-testing.html","id":"เปรยบเทยบ-p-value-กบ-คาวกฤต-critical-value-ทยอมรบได","chapter":"8 Hypothesis testing","heading":"8.1.4 เปรียบเทียบ p-value กับ ค่าวิกฤติ (critical value) ที่ยอมรับได้","text":"จุดนี้จะเป็นการตัดว่า ท่านสามารถยอมรับความบังเอิญนี้ที่กี่ % โดยทั่วไปมักใช้ที่น้อยกว่า 5% (0.05) หรือ 1% (0.01) ซึ่งแบ่งเป็นLeft-tailed คือ โอกาสที่ critical value \\(\\leq H_{0}\\)Left-tailed คือ โอกาสที่ critical value \\(\\leq H_{0}\\)Right-tailed คือ โอกาสที่ critical value \\(\\geq H_{0}\\)Right-tailed คือ โอกาสที่ critical value \\(\\geq H_{0}\\)Two-tailed คือ โอกาสที่ critical value \\(\\neq H_{0}\\) นิยมใช้วิเคราะห์มากที่สุดTwo-tailed คือ โอกาสที่ critical value \\(\\neq H_{0}\\) นิยมใช้วิเคราะห์มากที่สุดจะเห็นว่า โอกาสที่ความแตกต่างนั้นไม่ได้เกิดจากความบังเอิญภายใต้ \\(H_{0}\\) นั้นอยู่ที่ 46% ซึ่งมากกว่า 5% ที่ต้องการ จึงไม่สามารถ reject null hypothesis ได้ เรียกอีกแบบหนึ่งว่า ไม่ได้แตกต่างอย่างมีนัยสำคัญ (จนสามารถ reject \\(H_{0}\\) ได้)ตรงส่วนพื้นที่ระหว่าง critical value (ระหว่างเส้นประสีแดง) คือ พิสัยของความแตกต่างที่สามารถรับได้ ซึ่งจะถูกนำไปใช้ในการคำนวณค่าความเชื่อมั่น (confidence interval) ต่อไป","code":"\ncrit <- qt(1-0.05/2, df = 99) # ตัดที่ <= p 0.05, two-tailed\n\ndensity_df <- density_df |> \n  mutate(crits = ifelse(between(x,-crit,crit), TRUE,FALSE))\n\nggplot(density_df, aes(x,y)) + \n  geom_area(fill = \"darkred\", color = \"black\") +\n  geom_area(data = filter(density_df, crits), fill = \"skyblue\", color = \"black\") + \n  geom_area(data = filter(density_df, area), fill = \"white\", color = \"black\") +\n  geom_vline(xintercept = c(-tval,tval), linetype = \"dashed\") +\n  geom_vline(xintercept = c(-crit,crit), linetype = \"dashed\", color = \"red\") +\n  theme_bw()"},{"path":"hypothesis-testing.html","id":"power","chapter":"8 Hypothesis testing","heading":"Power","text":"คือ โอกาสการเกิดผลบวกจริง (True positive) ของ \\(H_{}\\) = 1 - powerพิจารณาการคำนวณทางสถิติ t-test ภายใต้สมมติฐาน \\(H_{0}\\): \\(\\mu = 12\\) และ \\(H_{}\\): \\(\\mu > 12\\) ที่ \\(S = 1.7\\)จากการคำนวณ สามารถสรุปได้ว่าสามารถปฏิเสธ \\(H_{0}\\) นั่นคือ ข้อมูลของกลุ่มตัวอย่างนี้มีค่าเฉลี่ยมากกว่าจาก 12 อย่างมีนัยสำคัญ แต่ว่า \\(H_{}\\) นั้น มีโอกาสเป็นจริงหรือไม่นั้น เมื่อพิจารณาของกระจายตัวของข้อมูล t-distribution แล้วจากกราฟ เส้นประสีแดงคือการกระจายตัวของข้อมูล \\(H_{0}\\): \\(\\mu = 12\\) ส่วนเส้นประสีฟ้าคือ \\(H_{}\\): \\(\\mu = 12 + \\frac{1.379}{4}\\times2.156 = 12.743\\) พื้นที่สีแดงคือ critical value = \\(\\alpha\\) ที่ 0.05ดังนั้น พื้นที่สีฟ้าคือ พื้นที่ของกลุ่มตัวอย่างจาก \\(H_{}\\): \\(\\mu = 12.743\\) ซึ่งแท้จริงแล้ว สามารถอยู่ในกลุ่ม \\(H_{0}\\): \\(\\mu = 12\\) ได้เช่นกัน ซึ่งก็คือโอกาสการเกิดผลบวกลวง (False positive) = Type-II error นั้นเองส่วนตรงที่เป็นเส้นแนวเฉียงสีฟ้า คือพื้นที่ๆ ไม่มีทางมาจาก \\(H_{0}\\) ได้ ซึ่งก็คือ ความสามารถในการแยกแยะกลุ่มตัวอย่างที่เป็นความจริง เรียกว่า ผลบวกที่แท้จริง (True positive) = Power = 1 - Type-II error ดังนั้น ถ้าท่านเพิ่มค่า \\(\\alpha\\) สูงสุดที่รับได้ โอกาสการเกิด False positive ก็จะเพิ่มขึ้น แต่โอกาสการเกิด False negative ก็จะต่ำลง (= Power สูงขึ้น)อย่างไรก็ตาม ในด้านงานวิจัยนั้น ส่วนใหญ่จะให้ความสำคัญกับ False positive มากกว่า เนื่องจากผลบวกลวงอาจจะส่งผลให้ตัดสินใจเปลี่ยนแปลงการรักษาเดิมที่เป็นมาตรฐาน ซึ่งอาจเกิดผลเสียแก่ผู้ป่วยได้ ดังนั้น จึงไม่ค่อยมีการปรับเพิ่ม \\(\\alpha\\) แต่จะเลือกเพิ่ม Power จากการเพิ่ม Sample size มากกว่า โดยจำนวนตัวอย่างที่มากขึ้น ส่งผลให้ความแปรปรวนในการวัด (Standard error) ลดลง ส่งผลให้การกระจายตัวของข้อมูลนั้นแคบลงด้วยจากกราฟ เส้นประสีแดงคือการกระจายตัวของข้อมูล \\(H_{0}\\): \\(\\mu = 12\\) ส่วนเส้นประสีฟ้าคือ \\(H_{}\\): \\(\\mu = 12 + \\frac{1.654}{19}\\times3.356 = 12.29\\) พื้นที่สีแดงคือ critical value = \\(\\alpha\\) ที่ 0.05 จะเห็นว่าการกระจายตัวของข้อมูลทั้งสองกลุ่มนั้นแคบกว่า (สังเกตตัวเลขแกน x) จึงมีส่วนที่พื้นที่ร่วมกันที่น้อยกว่าด้วยเมื่อพล็อตกราฟความสัมพันธ์ระหว่าง ขนาดตัวอย่าง, \\(\\alpha\\), power จะได้ดังรูปNote: ทั้งหมดนี้เป็นการคำนวณตัวอย่างของ t-test เท่านั้น การกระจายตัวแบบอื่นจะมีวิธีคำนวณ Power ที่ต่างกันไป อย่างไรก็ตามหลักการพื้นฐานจะคล้ายกัน","code":"\nset.seed(123)\nmean_5_sample <- rnorm(5, mean = 13, sd = 1.7)\nsd(mean_5_sample) #sd## [1] 1.378737\nt_test_5 <- t.test(mean_5_sample, mu = 12, alternative = \"greater\")\nt_test_5## \n##  One Sample t-test\n## \n## data:  mean_5_sample\n## t = 2.1555, df = 4, p-value = 0.04869\n## alternative hypothesis: true mean is greater than 12\n## 95 percent confidence interval:\n##  12.01459      Inf\n## sample estimates:\n## mean of x \n##  13.32907\nlibrary(pwrss)\npower.t.test(ncp = t_test_5$statistic, df = 4, alpha = 0.05,\n             alternative = \"greater\", plot = TRUE, verbose = FALSE)\npower.t.test(ncp = t_test_5$statistic, df = 4, alpha = 0.1,\n             alternative = \"greater\", plot = TRUE, verbose = FALSE)\nset.seed(123)\nmean_20_sample <- rnorm(20, mean = 13, sd = 1.7)\nsd(mean_20_sample) # sd## [1] 1.653531\nsd(mean_20_sample)/sqrt(length(mean_20_sample)) # standard error## [1] 0.3697408\nt_test_20 <- t.test(mean_20_sample, mu = 12, alternative = \"greater\")\nt_test_20## \n##  One Sample t-test\n## \n## data:  mean_20_sample\n## t = 3.3558, df = 19, p-value = 0.00166\n## alternative hypothesis: true mean is greater than 12\n## 95 percent confidence interval:\n##  12.60143      Inf\n## sample estimates:\n## mean of x \n##  13.24076\npower.t.test(ncp = t_test_20$statistic, df = 19, alpha = 0.05,\n             alternative = \"greater\", plot = TRUE, verbose = FALSE) \nmean_diff <- 1 # ความต่างคงที่ 1\nn <- 3:50\nalphas <- c(0.5, 0.2, 0.1,0.05,0.01,0.001)\n\npower_df <- expand_grid(n = n, alphas = alphas) |> \n  mutate(power = stats::power.t.test(n = n, delta = mean_diff, sig.level = alphas, sd = 1)$power) |> \n  mutate(alpha = as.factor(alphas)) |> \n  mutate(alpha = fct_reorder(alpha, desc(alphas)))\n\n\nggplot(power_df, aes(x = n, y = power, col = alpha, linetype = alpha)) + \n  geom_line(linewidth = 1.25) + theme_bw() +\n  labs(y = \"Power (1-beta)\", x = \"Sample size\")"},{"path":"hypothesis-testing.html","id":"trade-off-ของ-p-value-threshold","chapter":"8 Hypothesis testing","heading":"Trade-off ของ p-value threshold","text":"การตั้งค่าวิกฤตินั้นมี trade-ระหว่าง false positive และ false negative ที่ต้องพิจารณาType error = false positive = \\(\\alpha\\) = critical valueType error = false positive = \\(\\alpha\\) = critical valueType II error = false negative = \\(\\beta\\) = 1 - powerType II error = false negative = \\(\\beta\\) = 1 - power\\(\\therefore\\) power = true negative","code":""},{"path":"parametric-test.html","id":"parametric-test","chapter":"9 Parametric test","heading":"9 Parametric test","text":"Parametric test คือ การวิเคราะห์ทางสถิติที่เราทราบลักษณะการกระจายตัวของข้อมูลอย่างชัดเจน แต่มีข้อดีคือการเปรียบเทียบข้อมูลจะมีความแม่นยำสูง","code":""},{"path":"parametric-test.html","id":"sec-t-test","chapter":"9 Parametric test","heading":"9.1 t-test","text":"คือ การคำนวณทางสถิติที่เปรียบเทียบค่าเฉลี่ย (mean) และความแปรปรวน (sd) ระหว่างสองกลุ่ม แบ่งเป็น","code":""},{"path":"parametric-test.html","id":"one-t","chapter":"9 Parametric test","heading":"9.1.1 One sample t-test","text":"เป็นการเปรียบเทียบความแตกต่างของ mean ระหว่าง sample กับ population\\[\nt = \\frac{\\bar{x} - \\mu_{0}}{SE} = \\frac{\\bar{x} - \\mu_{0}}{s/\\sqrt{n}}\n\\]เพื่อให้เห็นภาพของความต่างใน test นี้เราจะทำการสร้างกราฟเปรียบว่า sample นั้น มี mean ต่างจาก population ที่ mean = 10 และ mean = 30 หรือไม่จะเห็นว่าเมื่อดูลักษณะการกระจายตัวของข้อมูลแล้ว Samp_10 ที่มี mean = 10 นั้น ไม่ต่างจากประชากรที่มี mean = 10 แต่ดูแตกต่างอย่างเห็นได้ชัดกับประชากรที่มี mean = 30 t.test จะช่วยตัดสินว่าค่าที่ได้นั้นแตกต่างกันจริงหรือไม่ hypothesis ที่ตั้งคือCase 1: Population mean = 10\\(H_{0}\\): mean ของ sample นั้น ไม่ต่างจาก mean ของ population ที่ mean = 10\\(H_{0}\\): mean ของ sample นั้น ไม่ต่างจาก mean ของ population ที่ mean = 10\\(H_{}\\): mean ของ sample นั้น ต่างจาก mean ของ population ที่ mean = 10\\(H_{}\\): mean ของ sample นั้น ต่างจาก mean ของ population ที่ mean = 10Case 2: Population mean = 40\\(H_{0}\\): mean ของ sample นั้น ไม่ต่างจาก mean ของ population ที่ mean = 40\\(H_{0}\\): mean ของ sample นั้น ไม่ต่างจาก mean ของ population ที่ mean = 40\\(H_{}\\): mean ของ sample นั้น ต่างจาก mean ของ population ที่ mean = 40\\(H_{}\\): mean ของ sample นั้น ต่างจาก mean ของ population ที่ mean = 40จะเห็นว่าต่างจาก population ที่ mean = 30 อย่างมีนัยสำคัญ (p = \\(2.2 \\times 10^{-16}\\) < critical point (0.05) )พิจารณาที่มาของ p-value นั้นมีที่มาจากสูตรขั้นต้นจะเห็นว่าค่า t นั้นเท่ากับ ค่าที่ได้จาก function t.test ขั้นต้น เมื่อสร้าง t-distribution ที่มี \\(H_{0}\\) คือ mean = 0 แล้วจะพบว่าค่านี้มากกว่า critical value","code":"\nset.seed(123)\nnorm_10_pop <- rnorm(1000, mean = 10, sd = 4) # สร้างประชากร mean = 10, sd = 4\nnorm_10_sample <- sample(norm_10_pop, 100) # สุ่มตัวอย่างมาจากประชากร 100 ราย\nnorm_30_pop <- rnorm(1000, mean = 30, sd = 4)\nnorm_30_sample <- sample(norm_30_pop, 100)\nnorm_pop_df <- data.frame(Pop_10 = norm_10_pop, Pop_30 = norm_30_pop) |>\n  pivot_longer(everything(), names_to = \"Pop\", values_to = \"Values\")  \n\nnorm_sample_df <- data.frame(Samp_10 = norm_10_sample, Samp_30 = norm_30_sample) |>    pivot_longer(everything(), names_to = \"Samp\", values_to = \"Values\")  \n\nggplot(norm_pop_df, aes(x = Values, fill = Pop)) +    \n  geom_density(aes(y = after_stat(count)),color = \"black\", alpha = 0.5) + \n  geom_density(data = norm_sample_df, \n               aes(x  = Values, y = after_stat(count), fill = Samp), \n               color = \"black\", alpha = 0.7) + theme_bw()\nt.test(norm_10_sample, mu = 10) # p > 0.05## \n##  One Sample t-test\n## \n## data:  norm_10_sample\n## t = 0.73547, df = 99, p-value = 0.4638\n## alternative hypothesis: true mean is not equal to 10\n## 95 percent confidence interval:\n##   9.533936 11.015052\n## sample estimates:\n## mean of x \n##  10.27449\nt.test(norm_10_sample, mu = 30) # p <= 0.05## \n##  One Sample t-test\n## \n## data:  norm_10_sample\n## t = -52.852, df = 99, p-value < 2.2e-16\n## alternative hypothesis: true mean is not equal to 30\n## 95 percent confidence interval:\n##   9.533936 11.015052\n## sample estimates:\n## mean of x \n##  10.27449\nhypothesized_mean <- 30\nmean_sample <- mean(norm_10_sample)\nsd_sample <- sd(norm_10_sample)\n\nt <- (mean_sample - hypothesized_mean)/(sd_sample/sqrt(length(norm_10_sample)))\n\nt## [1] -52.85159\n2*pt(t, df = 99) # p-value## [1] 2.306252e-74"},{"path":"parametric-test.html","id":"ind-t","chapter":"9 Parametric test","heading":"9.1.2 Independent t-test","text":"เป็นการเปรียบเทียบ mean ระหว่าง sample สองกลุ่มที่ไม่เกี่ยวเนื่องกัน\\[\nt = \\frac{\\bar{x_{1}}-\\bar{x_{2}}}{\\sqrt{\\frac{s^{2}_1}{n_{1}}+\\frac{s^{2}_2}{n_{2}}}}\n\\]\\[\nS_{p}^{2} = \\frac{(n_{1}-1)s^{2}_{1}+(n_{2}-1)s^{2}_{2}}{{n_{1}} + n_{2} - 2}\n\\]กลับไปดูภาพขั้นต้น ครั้งนี้จะเทียบระหว่าง sample สองกลุ่ม คือ norm_10_sample และ norm_30_sample ว่ามี mean ที่แตกต่างกันอย่างมีนัยสำคัญหรือไม่\\(H_{0}\\): mean ของ norm_10_sample และ norm_30_sample นั้นไม่แตกต่างกัน (\\(\\text{mean difference} = 0\\))\\(H_{0}\\): mean ของ norm_10_sample และ norm_30_sample นั้นไม่แตกต่างกัน (\\(\\text{mean difference} = 0\\))\\(H_{}\\): mean ของ norm_10_sample และ norm_30_sample นั้นแตกต่างกัน (\\(\\text{mean difference} \\neq 0\\))\\(H_{}\\): mean ของ norm_10_sample และ norm_30_sample นั้นแตกต่างกัน (\\(\\text{mean difference} \\neq 0\\))สรุปได้ว่า mean ของ sample ทั้งสองกลุ่มนั้นแตกต่างกันอย่างมีนัยสำคัญปล. บางครั้งข้อมูลอาจจะมีความแปรปรวนไม่เท่ากัน ในที่นี้มักจะใช้ Welch's t-test โดย t.test(…, var.equal = FALSE) โดยสมการนี้จะทำการปรับความแปรปรวนให้ด้วย","code":"\nt.test(norm_10_sample, norm_30_sample, var.equal = TRUE)## \n##  Two Sample t-test\n## \n## data:  norm_10_sample and norm_30_sample\n## t = -38.469, df = 198, p-value < 2.2e-16\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -20.93623 -18.89440\n## sample estimates:\n## mean of x mean of y \n##  10.27449  30.18981"},{"path":"parametric-test.html","id":"pair-t","chapter":"9 Parametric test","heading":"9.1.3 Paired t-test","text":"เป็นการเปรียบเทียบ mean ระหว่าง sample สองกลุ่มที่เกี่ยวเนื่องกัน (ก่อน-หลัง แม่-ลูก เป็นต้น)\\[\nt = \\frac{\\bar{x}_{d} -\\mu_{0}}{{s_{d} / \\sqrt{n}}}\n\\]\\[ s_{d} = \\sqrt{\\sum(x_{d}-\\bar{x}_{d})/(n-1)}\\]จะเห็นว่ามีความแตกต่างในส่วนของ \\(DF\\) (degree freedom) ซึ่งเกิดจากการจับคู่หาความต่าง 100 ครั้ง เนื่องจากค่าที่เปรียบเทียบนั้นอยู่ในตัวอย่างเดียวกัน (แม่ลูก คู่ที่ 1 แม่ลูกคู่ที่ 2 … เป็นต้น) เมื่อเปรียบเทียบกับ independent t-test เนื่องจากเป็นการหา mean ในกลุ่มของตัวเอง 2 ครั้ง และมาเทียบความต่างกันดังนั้น การเลือก paired vs independent นั้นมีความสำคัญ ขึ้นอยู่กับโจทย์การศึกษาของท่านด้วย","code":"\nt.test(norm_10_sample, norm_30_sample, paired = TRUE)## \n##  Paired t-test\n## \n## data:  norm_10_sample and norm_30_sample\n## t = -37.802, df = 99, p-value < 2.2e-16\n## alternative hypothesis: true mean difference is not equal to 0\n## 95 percent confidence interval:\n##  -20.96067 -18.86996\n## sample estimates:\n## mean difference \n##       -19.91532"},{"path":"parametric-test.html","id":"ANOVA","chapter":"9 Parametric test","heading":"9.2 Analysis of Variance (ANOVA)","text":"คือ การคำนวณทางสถิติที่เปรียบเทียบค่าเฉลี่ย (mean) และความแปรปรวน (sd) ระหว่างสองกลุ่มขึ้นไป โดยมีสมมติฐาน คือ\\(H_{0}\\): ค่าเฉลี่ยของทุกกลุ่มเท่ากัน (\\(\\mu_{1} = \\mu_{2} = \\mu_{3} = … = \\mu_{k}\\))\\(H_{0}\\): ค่าเฉลี่ยของทุกกลุ่มเท่ากัน (\\(\\mu_{1} = \\mu_{2} = \\mu_{3} = … = \\mu_{k}\\))\\(H_{}\\): ค่าเฉลี่ยของกลุ่มใดกลุ่มหนึ่งต่างจากกลุ่มอื่น\\(H_{}\\): ค่าเฉลี่ยของกลุ่มใดกลุ่มหนึ่งต่างจากกลุ่มอื่นการวิเคราะห์ ANOVA นั้นมีหลายแบบone-way ANOVA เป็นการหาความแตกต่างของ 1 ตัวแปรone-way ANOVA เป็นการหาความแตกต่างของ 1 ตัวแปรtwo-way ANOVA เป็นการหาความแตกต่างของ 2 ตัวแปรtwo-way ANOVA เป็นการหาความแตกต่างของ 2 ตัวแปรMANOVA เป็นการหาความแตกต่างที่มากกว่า 2 ตัวแปรMANOVA เป็นการหาความแตกต่างที่มากกว่า 2 ตัวแปรnested ANOVA เป็นการหาความแตกต่างที่ใน 1 ตัวแปรนั้น มีตัวแปรย่อยอีกnested ANOVA เป็นการหาความแตกต่างที่ใน 1 ตัวแปรนั้น มีตัวแปรย่อยอีกณ ที่นี้จะกล่าวถึงแค่ one-way ANOVA ซึ่งมีความซับซ้อนน้อย โดยหลักการโดยง่ายของ ANOVA คือ การเปรียบเทียบความต่างของ ค่าเฉลี่ยทั้งกลุ่ม (global mean) เปรียบเทียบกับ ผลรวมของค่าเฉลี่ยแต่ละกลุ่ม (group mean)การวิเคราะห์ทางสถิติของ ANOVA นั้นใช้ F-test ซึ่งเป็นการเปรียบเทียบระหว่าง ความแปรปรวนที่อธิบายได้ และความแปรปรวนที่อธิบายไม่ได้\\[F^{*} = \\frac{\\text{Explained variance}}{\\text{Unexplained variance}} =  \\frac{\\text{group variance}}{\\text{Within groups variance}}\\]group variance คือ ความแปรปรวนของค่าเฉลี่ยแต่ละกลุ่มกับค่าเฉลี่ยทั้งหมดBetween group variance คือ ความแปรปรวนของค่าเฉลี่ยแต่ละกลุ่มกับค่าเฉลี่ยทั้งหมดWithin group variance คือ ความแปรปรวนของข้อมูลในกลุ่มนั้น ซึ่งไม่สามารถอธิบายได้ภายใต้สมมติฐานงานวิจัยนั้นWithin group variance คือ ความแปรปรวนของข้อมูลในกลุ่มนั้น ซึ่งไม่สามารถอธิบายได้ภายใต้สมมติฐานงานวิจัยนั้นอธิบายโดยใช้ตัวอย่าง iris ในที่นี้เราจะเปรียบเทียบตวามต่างของ Sepal.Width ในแต่ละ Speciesอธิบายด้วยภาพรูปสามเหลี่ยม คือ mean ของ Petal.Width ในดอกไม้แต่ละ Speciesรูปสามเหลี่ยม คือ mean ของ Petal.Width ในดอกไม้แต่ละ Speciesจุดสีดำ คือ ค่า Petal.Width ในดอกไม้แต่ละดอกจุดสีดำ คือ ค่า Petal.Width ในดอกไม้แต่ละดอกจุดสีเขียว คือ global mean (grand mean) คือ ค่าเฉลี่ย Petal.Width เมื่อรวมดอกไม้ทุก Speciesจุดสีเขียว คือ global mean (grand mean) คือ ค่าเฉลี่ย Petal.Width เมื่อรวมดอกไม้ทุก Speciesจุดประสงค์ของ F-test คือการเปรียบเทียบอัตราส่วนระหว่าง ความแปรปรวนของค่าเฉลี่ยแต่ละกลุ่มกับค่าเฉลี่ยทั้งหมด (mean ของความต่างจุดเขียวกับสามเหลี่ยม) ใกล้กันกับความแปรปรวนของข้อมูลในกลุ่มนั้น (mean ของความต่างระหว่างจุดดำกับกับสามเหลี่ยม) หรือไม่ (ratio ~ 1) ซึ่งค่า \\(F\\) นั้นจะถูกนำไปคิด p-value จาก F-distribution (หลักการเดียวกันกับ t-test)สังเกตว่า ท่านไม่สามารถบอกได้ว่ากลุ่มไหนเป็นกลุ่มที่มีค่าเฉลี่ยที่แตกต่างจากทั้งกลุ่ม การที่จะทราบนั้นต้องทำ t.test เปรียบเทียบกันในแต่ละกลุ่ม \\(3\\choose2\\) = 3 ครั้ง การค้นหากลุ่มที่มีความต่างหลัง ANOVA นี้ เรียกว่า post-hoc testp-value น้อยกว่า 0.05 ทุกกลุ่ม หมายความว่า ทุกกลุ่มมีค่าเฉลี่ยของ Petal.Width ที่แตกต่างกัน","code":"\naov(Sepal.Width ~ Species, data = iris) |> summary()##              Df Sum Sq Mean Sq F value Pr(>F)    \n## Species       2  11.35   5.672   49.16 <2e-16 ***\n## Residuals   147  16.96   0.115                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nlibrary(granova)\ngranova.1w(iris$Sepal.Width, group = iris$Species)## $grandsum\n##     Grandmean        df.bet       df.with        MS.bet       MS.with        F.stat        F.prob SS.bet/SS.tot \n##          3.06          2.00        147.00          5.67          0.12         49.16          0.00          0.40 \n## \n## $stats\n##            Size Contrast Coef Wt'd Mean Mean Trim'd Mean Var. St. Dev.\n## versicolor   50         -0.29      2.77 2.77        2.80 0.10     0.31\n## virginica    50         -0.08      2.97 2.97        2.96 0.10     0.32\n## setosa       50          0.37      3.43 3.43        3.41 0.14     0.38\npairwise.t.test(iris$Sepal.Width, iris$Species)## \n##  Pairwise comparisons using t tests with pooled SD \n## \n## data:  iris$Sepal.Width and iris$Species \n## \n##            setosa  versicolor\n## versicolor < 2e-16 -         \n## virginica  9.1e-10 0.0031    \n## \n## P value adjustment method: holm"},{"path":"parametric-test.html","id":"correlation-test","chapter":"9 Parametric test","heading":"9.3 Correlation test","text":"","code":""},{"path":"parametric-test.html","id":"pearson","chapter":"9 Parametric test","heading":"9.3.1 Pearson correlation","text":"เป็นการทดสอบความสัมพันธ์เชิงเส้นของตัวแปรสองตัวแปร\\[\nr_{xy} =\\frac{cov(x,y)}{s(x) s(y)}\n\\]\\[\nr_{xy} = \\frac{\\sum^{n}_{=1}(x_{}-\\bar{x})(y_{}-\\bar{y})}{\\sqrt{\\sum^{n}_{=1}(x_{}-\\bar{x})^{2}}\\sqrt{\\sum^{n}_{=1}(y_{}-\\bar{y})^{2}}}\n\\]การแปลผลของ correlation ขึ้นอยู่กับระดับของความสัมพันธ์ = 0-1 ยิ่งเข้าใกล้ 1 ยิ่งสัมพันธ์กันมากระดับของความสัมพันธ์ = 0-1 ยิ่งเข้าใกล้ 1 ยิ่งสัมพันธ์กันมากทิศทางของความสัมพันธ์ = + ไปทิศทางเดียวกัน - ไปทิศทางตรงข้ามกันทิศทางของความสัมพันธ์ = + ไปทิศทางเดียวกัน - ไปทิศทางตรงข้ามกันท่านสามารถสร้างตาราง correlation และ p-value ได้ด้วย package corrplotข้อควรระวัง p-value ของ correlation test นั้นอยู่ภายใต้สมมติฐาน (\\(t\\)-test/\\(F\\)-test)\\(H_{0}\\): ไม่มีความสัมพันธ์เชิงเส้นของทั้งสองตัวแปร (\\(r_{xy} = 0\\))\\(H_{0}\\): ไม่มีความสัมพันธ์เชิงเส้นของทั้งสองตัวแปร (\\(r_{xy} = 0\\))\\(H_{0}\\): มีความสัมพันธ์เชิงเส้นของทั้งสองตัวแปร (\\(r_{xy} \\neq 0\\))\\(H_{0}\\): มีความสัมพันธ์เชิงเส้นของทั้งสองตัวแปร (\\(r_{xy} \\neq 0\\))ซึ่งถ้า \\(p\\) < 0.05 หมายความว่า ท่านมีความมั่นใจมากเพียงพอว่า ความสัมพันธ์เชิงเส้นของทั้งสองตัวแปรนั้น มีมากกว่าการวาดเส้นจากการสร้างจุดแบบสุ่ม ท่านยังคงต้องแปรผลร่วมกับค่า correlation coefficient ต่อไปเช่น\\(r_{x,y}\\) = 0.2, \\(p\\) < 0.05 มั่นใจว่ามีความสัมพันธ์เชิงเส้นของสองตัวแปร ความสัมพันธ์เป็นไปในทิศทางเดียวกัน แต่ความสัมพันธ์เชิงเส้นอยู่ในระดับน้อย\\(r_{x,y}\\) = 0.2, \\(p\\) < 0.05 มั่นใจว่ามีความสัมพันธ์เชิงเส้นของสองตัวแปร ความสัมพันธ์เป็นไปในทิศทางเดียวกัน แต่ความสัมพันธ์เชิงเส้นอยู่ในระดับน้อย\\(r_{x,y}\\) = 1, \\(p\\) = 1 ความสัมพันธ์เชิงเส้นอยู่ในระดับดีเยี่ยม แต่ไม่มั่นใจว่ามีความสัมพันธ์กันจริงหรือไม่ เนื่องจากข้อมูลน้อย (เช่น มีข้อมูลเพียงสองจุด \\(r_{x,y}\\) ย่อมเท่ากับ 1)\\(r_{x,y}\\) = 1, \\(p\\) = 1 ความสัมพันธ์เชิงเส้นอยู่ในระดับดีเยี่ยม แต่ไม่มั่นใจว่ามีความสัมพันธ์กันจริงหรือไม่ เนื่องจากข้อมูลน้อย (เช่น มีข้อมูลเพียงสองจุด \\(r_{x,y}\\) ย่อมเท่ากับ 1)\\(r_{x,y}\\) = 0.3, \\(p\\) = 1 ความสัมพันธ์เชิงเส้นอยู่ในระดับน้อย แต่ไม่มั่นใจว่ามีความสัมพันธ์กันจริงหรือไม่ เนื่องจากข้อมูลน้อยเกินไป ควรเก็บข้อมูลเพิ่ม\\(r_{x,y}\\) = 0.3, \\(p\\) = 1 ความสัมพันธ์เชิงเส้นอยู่ในระดับน้อย แต่ไม่มั่นใจว่ามีความสัมพันธ์กันจริงหรือไม่ เนื่องจากข้อมูลน้อยเกินไป ควรเก็บข้อมูลเพิ่ม\\(r_{x,y}\\) = -1, \\(p\\) < 0.05 มั่นใจว่ามีความสัมพันธ์เชิงเส้นของสองตัวแปร ความสัมพันธ์เป็นไปในทิศทางตรงข้าม และความสัมพันธ์เชิงเส้นอยู่ในระดับดีเยี่ยม\\(r_{x,y}\\) = -1, \\(p\\) < 0.05 มั่นใจว่ามีความสัมพันธ์เชิงเส้นของสองตัวแปร ความสัมพันธ์เป็นไปในทิศทางตรงข้าม และความสัมพันธ์เชิงเส้นอยู่ในระดับดีเยี่ยมนั่นหมายความว่า ยิ่งจำนวนตัวอย่างเพิ่มขึ้น ความมั่นใจยิ่งเพิ่มขึ้น ไม่ใช่ความสัมพันธ์เพิ่มขึ้น","code":"\nggplot(iris, aes(x = Sepal.Length, y = Petal.Length)) + \n  geom_point(aes(col = Species)) +\n  geom_smooth(method = \"lm\", se = FALSE)\ncor(iris$Sepal.Length, iris$Petal.Length)## [1] 0.8717538\nlibrary(corrplot)\n\niris_cor <- cor(iris[1:4])\niris_cor##              Sepal.Length Sepal.Width Petal.Length Petal.Width\n## Sepal.Length    1.0000000  -0.1175698    0.8717538   0.8179411\n## Sepal.Width    -0.1175698   1.0000000   -0.4284401  -0.3661259\n## Petal.Length    0.8717538  -0.4284401    1.0000000   0.9628654\n## Petal.Width     0.8179411  -0.3661259    0.9628654   1.0000000\niris_cor_p <- cor.mtest(iris[1:4])\niris_cor_p## $p\n##              Sepal.Length  Sepal.Width Petal.Length  Petal.Width\n## Sepal.Length 0.000000e+00 1.518983e-01 1.038667e-47 2.325498e-37\n## Sepal.Width  1.518983e-01 0.000000e+00 4.513314e-08 4.073229e-06\n## Petal.Length 1.038667e-47 4.513314e-08 0.000000e+00 4.675004e-86\n## Petal.Width  2.325498e-37 4.073229e-06 4.675004e-86 0.000000e+00\n## \n## $lowCI\n##              Sepal.Length Sepal.Width Petal.Length Petal.Width\n## Sepal.Length    1.0000000  -0.2726932    0.8270363   0.7568971\n## Sepal.Width    -0.2726932   1.0000000   -0.5508771  -0.4972130\n## Petal.Length    0.8270363  -0.5508771    1.0000000   0.9490525\n## Petal.Width     0.7568971  -0.4972130    0.9490525   1.0000000\n## \n## $uppCI\n##              Sepal.Length Sepal.Width Petal.Length Petal.Width\n## Sepal.Length   1.00000000  0.04351158    0.9055080   0.8648361\n## Sepal.Width    0.04351158  1.00000000   -0.2879499  -0.2186966\n## Petal.Length   0.90550805 -0.28794993    1.0000000   0.9729853\n## Petal.Width    0.86483606 -0.21869663    0.9729853   1.0000000\ncorrplot(iris_cor, method = \"shade\",type = \"upper\",order = \"AOE\", \n         p.mat = iris_cor_p$p, insig = \"p-value\")"},{"path":"non-parametric-test.html","id":"non-parametric-test","chapter":"10 Non-parametric test","heading":"10 Non-parametric test","text":"Non-parametric test คือ การวิเคราะห์ทางสถิติที่เราไม่ทราบลักษณะการกระจายตัวของข้อมูลอย่างชัดเจน ข้อดีคือมีความยืดหยุ่นกว่า แต่มีความแม่นยำน้อยกว่า","code":""},{"path":"non-parametric-test.html","id":"proportion-test","chapter":"10 Non-parametric test","heading":"10.1 Proportion test","text":"คือ การทดสอบทางสถิติเพื่อทำการเปรียบเทียบอัตราส่วนของจำนวน โดยจะใช้กับข้อมูลประเภทจำนวนนับของตัวแปรจัดประเภท (Nominal variable) เช่น จำนวนคน จำนวนเซลล์ เป็นต้นข้อสังเกต การทดลองที่มีการทำ technical replicate แล้วหาค่าเฉลี่ยนั้น ตัวข้อมูลยังเป็น จำนวนนับ การจะหาความต่างค่าเฉลี่ยโดยใช้ t.test นั้น จำนวน sample ควรจะมากพอตาม Central limit theorem นอกเหนือจากนั้นควรใช้ proportional test หรือ ควรใช้ generalized linear model ประเภทอื่นมากกว่า","code":""},{"path":"non-parametric-test.html","id":"chi-square-test","chapter":"10 Non-parametric test","heading":"10.1.1 Chi-square test","text":"คือ การทดสอบความต่างของอัตราส่วนโดยใช้การประมาณการของ ค่าที่คาดหวัง (expected value) และ ค่าที่สังเกตได้จริง (observed value)\\[\n\\chi^{2} = \\sum_{=1}^{n}\\frac{(O-E)^{2}}{E}\n\\]","code":""},{"path":"non-parametric-test.html","id":"chi-square-goodness-of-fit","chapter":"10 Non-parametric test","heading":"10.1.1.1 Chi-square goodness of fit","text":"เป็นการเปรียบเทียบว่า observed value นั้นมาจากประชากรทางทฤษฎีหรือไม่ โดย expected value นั้นคำนวนจาก\\[\nE_{} = CDF_{}(Y_{u})-CDF_{}(Y_{l})\n\\]ยกตัวอย่างการทอดลูกเต๋า ซึ่งมีโอกาสการเกิดทุกหน้า = \\(1/6\\)\\(H_{0}\\) การกระจายตัวของการทอดลูกเต๋านี้เท่ากับการกระจายทางทฤษฎี\\(H_{0}\\) การกระจายตัวของการทอดลูกเต๋านี้เท่ากับการกระจายทางทฤษฎี\\(H_{}\\) การกระจายตัวของการทอดลูกเต๋านี้ไม่เท่ากับการกระจายทางทฤษฎี\\(H_{}\\) การกระจายตัวของการทอดลูกเต๋านี้ไม่เท่ากับการกระจายทางทฤษฎีจะเห็นว่าความแตกต่างระหว่าง observed และ expected นั้น อยู่ในพิสัยของของ \\(H_{0}\\)แต่ถ้าลูกเต๋านั้นเป็นลูกเต๋าถ่วงน้ำหนักเมื่อวิเคราะห์ chi-square ตามการกระจายตัวของลูกเต๋าทั่วไป จะแตกต่างอย่างมีนัยสำคัญแต่ถ้าวิเคราะห์เทียบกับการกระจายตัวเดียวกับลูกเต๋าถ่วงน้ำหนัก จะไม่แตกต่างกัน","code":"\nset.seed(123)\ndice <- sample(6, 1000, replace = TRUE) # โยนลูกเต๋า 1000 ครั้ง\nchisq_dice <- chisq.test(table(dice))\nchisq_dice## \n##  Chi-squared test for given probabilities\n## \n## data:  table(dice)\n## X-squared = 1.436, df = 5, p-value = 0.9203\ndata.frame(O = chisq_dice$observed, E.Freq = chisq_dice$expected)\nweight_dice <- sample(6,1000, replace = TRUE, prob = c(3,2,1,1,1,1)/9)\nchisq_weight_norm <- chisq.test(table(weight_dice))\nchisq_weight_norm## \n##  Chi-squared test for given probabilities\n## \n## data:  table(weight_dice)\n## X-squared = 248.55, df = 5, p-value < 2.2e-16\ndata.frame(O = chisq_weight_norm$observed, E.freq = chisq_weight_norm$expected)\nchisq_weight_weight <- chisq.test(table(weight_dice), p = c(3,2,1,1,1,1)/9)\nchisq_weight_weight## \n##  Chi-squared test for given probabilities\n## \n## data:  table(weight_dice)\n## X-squared = 2.9135, df = 5, p-value = 0.7133\ndata.frame(O = chisq_weight_weight$observed, E.freq = chisq_weight_weight$expected)"},{"path":"non-parametric-test.html","id":"chi-square-test-of-independence","chapter":"10 Non-parametric test","heading":"10.1.1.2 Chi-square test of independence","text":"เป็นการเปรียบเทียบข้อมูลจำนวนสองกลุ่มขึ้นไปว่า มีความสัมพันธ์ที่ทำให้การกระจายตัวของข้อมูลเปลี่ยนไปจากปกติหรือไม่\\(H_{0}\\): ข้อมูลทั้ง 2+ กลุ่มนั้นไม่มีความสัมพันธ์ต่อกัน\\(H_{}\\): ข้อมูลทั้ง 2+ กลุ่มนั้นมีความสัมพันธ์ต่อกันโดยการวิเคราะห์นั้นจะใช้กับข้อมูลความถี่แบบ \\(n \\times n\\) โดย expected event นั้นคิดจาก\\[\nE_{,j} = P(G_{,j}) \\times P(Con_{,j}) \\times \\text{total counts}\n\\] \\[\nE = \\frac{\\text{Row total} \\times \\text{Column total}}{\\text{Total sample size}}\n\\]อย่างเช่น expected event สำหรับช่อง \\(\\) คือ \\[\n\\frac{(+ B) \\times (+ C)}{(+ B + C + D)^{2}}(+B+C+D)\n\\]ยกตัวอย่างว่าอยากทราบว่าเพศมีผลต่ออัตราการตายในมะเร็งปอดหรือไม่p < 0.05 หมายความว่าเพศมีผลต่ออัตราการตายอย่างมีนัยสำคัญลองคำนวณเองตามสูตรขั้นต้น","code":"\nlung_ob##         status\n## sex      Alive Dead\n##   Female    37   53\n##   Male      26  112\nlung_chisq <- chisq.test(lung_ob, correct = FALSE)\nlung_chisq## \n##  Pearson's Chi-squared test\n## \n## data:  lung_ob\n## X-squared = 13.511, df = 1, p-value = 0.0002371\nlung_ex <- apply(expand.grid(rowSums(lung_ob), colSums(lung_ob)),1, prod) |> \n  matrix(nrow=2)/sum(lung_ob) # สร้าง expected table\n\nlung_ex##          [,1]     [,2]\n## [1,] 24.86842 65.13158\n## [2,] 38.13158 99.86842\nchi_value <- sum((lung_ob - lung_ex)^2/lung_ex)\nchi_value # chi-squared## [1] 13.51117\npchisq(chi_value, df = lung_chisq$parameter, lower.tail = FALSE) # p-value## [1] 0.000237147"},{"path":"non-parametric-test.html","id":"fisher","chapter":"10 Non-parametric test","heading":"10.1.2 Fisher’s exact test","text":"คือการทดสอบว่าข้อมูลนั้นมีความสัมพันธ์หรือไม่ โดยการเทียบกับความสัมพันธ์แบบสุ่ม การทดสอบนี้จะมีความแม่นยำกว่า chi-square เนื่องจากเป็นการคำนวณความน่าจะเป็นโดยตรง\\[\np = \\frac{{+B \\choose }{C+D \\choose C}}{{n \\choose +C}} = \\frac{{+B \\choose B}{C+D \\choose D}}{{n \\choose B+D}}\n\\]พิจารณาสูตร จุดประสงค์คือ การคำนวณความน่าจะเป็นของการหยิบสุ่มแบบไม่คืนให้ได้ตาม condition ที่ต้องการนั่นเองp < 0.05 หมายความว่าเพศมีผลต่ออัตราการตายอย่างมีนัยสำคัญ สังเกตว่า p จะมากกว่า chi-square เนื่องจากการทดสอบนี้มีความ conservative กว่าลองคำนวณเองตามสูตรขั้นต้นปล. การใช้ lung_ob[1] - 1 นั้นมีที่มาจากว่า เมื่อใช้ lower.tail = TRUE จะคำนวณโอกาสที่ ได้ \\(P[X > x]\\) ซึ่งเราต้องการ \\(P[X \\geq x]\\) จึงต้อง ลบ condition ที่ต้องการออกด้วย","code":"\nfisher.test(lung_ob, alternative = \"two.sided\")## \n##  Fisher's Exact Test for Count Data\n## \n## data:  lung_ob\n## p-value = 0.0004349\n## alternative hypothesis: true odds ratio is not equal to 1\n## 95 percent confidence interval:\n##  1.583762 5.727861\n## sample estimates:\n## odds ratio \n##   2.991585\nalive_dead <- colSums(lung_ob)\nalive_dead # total alive and dead## Alive  Dead \n##    63   165\nmale_female <- rowSums(lung_ob)\nmale_female # total male and female## Female   Male \n##     90    138\nfisher_p <- (choose(alive_dead[1], lung_ob[1]-1)*choose(alive_dead[2], lung_ob[3])/\n               (choose(sum(lung_ob), male_female[1])))\n\nunname(fisher_p)*2 # remove name## [1] 0.0004388966\n## or\n2*(phyper(lung_ob[1]-1,alive_dead[1], \n       alive_dead[2], male_female[1],lower.tail=FALSE))## [1] 0.0004635661"},{"path":"non-parametric-test.html","id":"rank-test","chapter":"10 Non-parametric test","heading":"10.2 Rank test","text":"เป็นการหาความต่างของลำดับ แทนที่จะหาความต่างของ mean/variance ในภาวะที่ไม่ทราบการกระจายตัวของข้อมูลที่ชัดเจน","code":""},{"path":"non-parametric-test.html","id":"test-for-normality","chapter":"10 Non-parametric test","heading":"10.2.1 Test for normality","text":"กลับมาที่ตัวอย่าง iris ดูการกระจายของข้อมูลพิจารณาแล้ว Petal.Width ไม่น่าจะใช่ normal distribution จะทำการทดสอบต่อโดย shapiro.test() ซึ่งเป็นการทดสอบการกระจายตัวของข้อมูลว่าหลุดออกจาก normal distribution หรือไม่จะเห็นว่า Petal.Width มี p < 0.05 พอสมควร (ไม่เป็น normal distribution) จึงสมควรใช้ non-parametric test","code":"\n  ggplot(long_df, aes(x = cm, fill = Metrics)) + geom_histogram() +\n  facet_grid(Metrics~Species, scales = \"free\") +\n  theme_bw()\nlong_df |> \n  group_by(Metrics, Species) |> \n  summarise(normality = round(shapiro.test(cm)$p.value, 4))"},{"path":"non-parametric-test.html","id":"wilcox-rs","chapter":"10 Non-parametric test","heading":"10.2.2 Wilcoxon’s rank sum test (Mann-Whitney U test)","text":"คือ การคำนวณว่ากลุ่มตัวอย่าง 2 กลุ่มนั้นมาจากประชากรกลุ่มเดียวกันหรือไม่ จากการพิจารณาผลรวมของลำดับข้อมูลทั้งสองกลุ่มลักษณะการใช้คล้าย independent t-test สำหรับ non-normal distribution\\[\nW_{j} = n_{1}n_{2} + \\frac{n_{j}(n_{j}+1)}{2} - R_{n}\n\\]\\[\nW = min(W_{1}, W_{2})\n\\]ลองคำนวณเอง หลักการคือจัดอันดับของข้อมูลโดยเรียงจาก น้อยไปมาก และให้อันดับเป็นตัวเลข (อันดับที่เท่ากัน ให้เป็นค่าเฉลี่ยของลำดับนั้น เช่น อันดับ 2, 3, 4 ที่มีค่าเท่ากัน ให้อันดับเป็น (2+3+4)/3 = 5 ทุกตัว)จัดอันดับของข้อมูลโดยเรียงจาก น้อยไปมาก และให้อันดับเป็นตัวเลข (อันดับที่เท่ากัน ให้เป็นค่าเฉลี่ยของลำดับนั้น เช่น อันดับ 2, 3, 4 ที่มีค่าเท่ากัน ให้อันดับเป็น (2+3+4)/3 = 5 ทุกตัว)คำนวณค่า \\(W\\) โดยแยกกลุ่ม 1 และ กลุ่ม 2 และเลือกค่า \\(W\\) ที่น้อยที่สุดคำนวณค่า \\(W\\) โดยแยกกลุ่ม 1 และ กลุ่ม 2 และเลือกค่า \\(W\\) ที่น้อยที่สุดปล. เมื่อจำนวนตัวอย่าง >50 ค่า \\(W\\) จะเข้าสู่ normal distribution ซึ่งสามารถเปลี่ยนเป็นค่า \\(Z\\) ได้ ส่งผลให้การคำนวณ p-value จะแม่นยำขึ้น\\[\nZ = \\frac{W-m_{w}}{s_{w}}\n\\]\\[\nm_{w} = \\frac{n_{1}n_{2}}{2} = \\text{mean W}\n\\]\\[\ns_{w} = \\sqrt{\\frac{n_{1}n_{2}(n_{1}+n_{2}+1)}{12}}\n\\]","code":"\niris_pw <- df |> \n  select(Petal.Width, Species) |> \n  filter(Species != \"virginica\" )\n\niris_wx <- wilcox.test(Petal.Width~Species, data = iris_pw)\n\niris_wx## \n##  Wilcoxon rank sum test with continuity correction\n## \n## data:  Petal.Width by Species\n## W = 0, p-value < 2.2e-16\n## alternative hypothesis: true location shift is not equal to 0\niris_wx$p.value## [1] 2.284669e-18\niris_pw_rank <- iris_pw |> \n  arrange(`Petal.Width`) |> \n  mutate(Rank = rank(`Petal.Width`, ties.method = \"average\")) # rank all values\n\nsetosa <- split(iris_pw_rank, iris_pw$Species)$setosa\nversicolor <- split(iris_pw_rank, iris_pw$Species)$versicolor\n\nall_combn <- nrow(setosa)*nrow(versicolor)\nall_combn## [1] 2500\nsetosa_rank_sum <- all_combn + (nrow(setosa)*(nrow(setosa)+1))/2 - sum(setosa$Rank)\nsetosa_rank_sum## [1] 2500\nversicolor_rank_sum <- all_combn + (nrow(versicolor)*(nrow(versicolor)+1))/2 - sum(versicolor$Rank)\nversicolor_rank_sum## [1] 0\nW <- min(setosa_rank_sum,versicolor_rank_sum)\nW## [1] 0\n## Normal approximation\nmW <- all_combn/2\nsdW <- sqrt(all_combn*(nrow(setosa)+nrow(versicolor)+1)/12)\nz = (W-mW)/sdW\npval <- 2*pnorm(-abs(z)) \npval # not exactly equal due to tie adjustment in wilcox.test()## [1] 6.856641e-18"},{"path":"non-parametric-test.html","id":"wilcox-sign","chapter":"10 Non-parametric test","heading":"10.2.3 Wilcoxon’s signed-rank test","text":"คือ การคำนวณว่ากลุ่มตัวอย่าง 2 กลุ่มนั้นมาจากประชากรกลุ่มเดียวกันหรือไม่ จากการคำนวณลำดับข้อมูลของทั้งสองกลุ่มลักษณะการใช้คล้าย paired t-test สำหรับ non-normal distribution\\[\nV = \\sum_{=1}^{N_{r}}[sgn(x_{2,} - x_{1,}) \\cdot R_{}]\n\\]\\[\nsgn(x) =\\begin{cases} -1 \\quad \\text{} \\, x < 1,  \\\\0 \\quad \\ \\ \\  \\text{} \\, x = 0,\\\\1 \\quad \\ \\ \\  \\text{} \\, x > 0\\end{cases}\n\\]\\[\nV = min(V_{-}, V_{+})\n\\]สมมติการวัด wound healing assay (วัดการเคลื่อนที่ของเซลล์) ก่อนและหลัง treat ยาลองคำนวณเอง หลักการคือคำนวณความต่างของก่อนและหลัง (หรือคู่เทียบ)คำนวณความต่างของก่อนและหลัง (หรือคู่เทียบ)จัดอันดับของข้อมูลโดยเรียงจาก น้อยไปมาก และให้อันดับเป็นตัวเลข (อันดับที่เท่ากัน ให้เป็นค่าเฉลี่ยของลำดับนั้น เช่น อันดับ 2, 3, 4 เท่ากัน ให้อันดับเป็น (2+3+4)/3 = 5 ทุกตัวแปร)จัดอันดับของข้อมูลโดยเรียงจาก น้อยไปมาก และให้อันดับเป็นตัวเลข (อันดับที่เท่ากัน ให้เป็นค่าเฉลี่ยของลำดับนั้น เช่น อันดับ 2, 3, 4 เท่ากัน ให้อันดับเป็น (2+3+4)/3 = 5 ทุกตัวแปร)คำนวณค่า \\(V\\) โดยแยกเครื่องหมาย + และ - และเลือกค่า \\(V\\) ที่น้อยที่สุดคำนวณค่า \\(V\\) โดยแยกเครื่องหมาย + และ - และเลือกค่า \\(V\\) ที่น้อยที่สุด","code":"\nset.seed(123)\n\ntreat <- data.frame(sample = 1:20,\n  Before = runif(20, min = 400, max = 500),\n           After = detectnorm::rnonnorm(20, mean = 400, sd = 30, skew = 10, kurt = 5)$dat)\n\nhead(treat, 10)\nwilcox.test(treat$Before, treat$After, paired = TRUE, exact = TRUE)## \n##  Wilcoxon signed rank exact test\n## \n## data:  treat$Before and treat$After\n## V = 169, p-value = 0.01531\n## alternative hypothesis: true location shift is not equal to 0\ntreat_rank <- treat |> mutate(Diff = Before-After) |> \n                mutate(Absdiff = abs(Diff)) |> \n                mutate(Rank = rank(Absdiff, ties.method = \"average\")) \ntreat_rank\nsign_rank <- treat_rank |> group_by(sign(Diff)) |> \n              summarize(rank_sum = sum(Rank))\n\nV <- min(sign_rank$rank_sum)\nV## [1] 41\npval <- psignrank(V, 20,20)*2\npval## [1] 0.01531219"},{"path":"non-parametric-test.html","id":"kruskal-wallis-test","chapter":"10 Non-parametric test","heading":"10.2.4 Kruskal-Wallis test","text":"คือ การเปรียบเทียบค่าเฉลี่ยของลำดับว่ามาจากประชากรเดียวกันหรือไม่ ลักษณะการใช้เช่นเดียวกับ ANOVA\\[\nH = (N-1)\\frac{\\sum^{g}_{=1}n_{}(\\bar{r_{}}-\\bar{r})^{2}}{\\sum^{g}_{=1}\\sum^{n_{}}_{j=1}(r_{ij}-\\bar{r})^{2}}\n\\]ลองคำนวณเอง หลักการการจัดอันดับเหมือน Wilcoxon’s rank sum test","code":"\niris_pw_all <- df |> \n               select(Petal.Width, Species) # 3 groups\n\niris_kw <- kruskal.test(Petal.Width ~ Species, data = iris_pw_all)\niris_kw$p.value## [1] 3.261796e-29\niris_pw_all_ranked <- iris_pw_all |> arrange(`Petal.Width`) |> \n                        mutate(Rank = rank(`Petal.Width`, ties.method = \"average\"))\niris_pw_all_ranked\naverage_rank <- mean(iris_pw_all_ranked$Rank) # also = (nrow(iris_pw_all_ranked)+1)/2\naverage_rank## [1] 75.5\nbetween_group_var <- iris_pw_all_ranked |>\n                  group_by(Species) |> \n                   summarise(rank_var = ((mean(Rank) - average_rank)^2)*n())\nbetween_group_var\nwithin_group_var <- iris_pw_all_ranked |> \n                    mutate(rank_var = (Rank-average_rank)^2)\nwithin_group_var\nH <- ((nrow(iris_pw_all_ranked)-1))*sum(between_group_var$rank_var)/sum(within_group_var$rank_var)\nH## [1] 131.1854\npval <- pchisq(H, 2, lower.tail = FALSE)\npval## [1] 3.261796e-29"},{"path":"non-parametric-test.html","id":"correlation-test-1","chapter":"10 Non-parametric test","heading":"10.3 Correlation test","text":"","code":""},{"path":"non-parametric-test.html","id":"spearmans-correlation","chapter":"10 Non-parametric test","heading":"10.3.1 Spearman’s correlation","text":"เป็นการทดสอบความสัมพันธ์ในทิศทางของตัวแปรสองตัวแปรว่าเป็นไปในทางเดียวกันหรือไม่ (monotonic relationship)\\[ \\rho_{xy} =\\frac{cov(x,y)}{s(x) s(y)} \\]\\[\n\\rho_{xy} = \\frac{\\sum^{n}_{=1}(x_{}-\\bar{x})(y_{}-\\bar{y})}{\\sqrt{\\sum^{n}_{=1}(x_{}-\\bar{x})^{2}}\\sqrt{\\sum^{n}_{=1}(y_{}-\\bar{y})^{2}}}\n\\]โดย \\(x, y\\) คือ ลำดับของข้อมูล (ไม่ใช่ตัวข้อมูลเอง) ส่งผลให้การทดสอบนี้ เป็นการทดสอบการเพิ่มขึ้นของลำดับ ไม่ใช่การเพิ่มขึ้นของข้อมูล ดังนั้น จึงไม่ใช่การทดสอบความสัมพันธ์เป็นเชิงเส้นเหมือน Pearson’s correlation แต่เป็นการทดสอบเพียงว่าข้อมูลไปในทิศทางเดียวันหรือไม่การทดสอบใน R ใช้ลักษณะ code เดียวกันกับ Pearson’s correlation แต่เปลี่ยน argument เป็น method = \"pearson\" และข้อควรระวังก็คิดเหมือนกัน","code":"\npoly_data <- data.frame(x = seq(-10, 10, length.out = 100)) |> \n  mutate(y = x^9+x+10+rnorm(100, mean = 0, sd =3))\n\nggplot(poly_data, aes(x=x,y=y)) + geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw()\ncor(poly_data$x, poly_data$y, method = \"pearson\") # not quite linear## [1] 0.6870804\ncor(poly_data$x, poly_data$y, method = \"spearman\") # monotonic## [1] 0.9993399"},{"path":"regression-model.html","id":"regression-model","chapter":"11 Regression model","heading":"11 Regression model","text":"Regression model คือการสร้างสมการถดถอยของความสัมพันธ์ระหว่าง 2+ ตัวแปร โดยประกอบไปด้วยตัวแปรต้น (independent variable, \\(x\\)) คือ ตัวแปรที่เป็นต้นเหตุตัวแปรต้น (independent variable, \\(x\\)) คือ ตัวแปรที่เป็นต้นเหตุตัวแปรตาม (dependent variable, \\(y\\)) คือ ตัวแปรที่เป็นปลายเหตุ ซึ่งเป็นผลมาจากการเปลี่ยนแปลงของตัวแปรต้นตัวแปรตาม (dependent variable, \\(y\\)) คือ ตัวแปรที่เป็นปลายเหตุ ซึ่งเป็นผลมาจากการเปลี่ยนแปลงของตัวแปรต้นความสัมพันธ์ของตัวแปรต้นและตัวแปรตามจะเขียนในรูปแบบ \\(f(x) \\sim x\\)","code":""},{"path":"regression-model.html","id":"linear-regression","chapter":"11 Regression model","heading":"11.1 Linear regression","text":"","code":""},{"path":"regression-model.html","id":"model-summary","chapter":"11 Regression model","heading":"11.1.1 Model summary","text":"คือ การสร้างความสัมพันธ์ของตัวแปรแบบเชิงเส้น ใช้กับข้อมูลแบบต่อเนื่อง (continuous data)\\[\nh_{\\theta}(x) = \\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + \\ …  \\ + \\theta_{n}x_{n} + \\epsilon\n\\]ในการวัดความแม่นยำของ linear regression นั้นประกอบด้วยสามองค์ประกอบ\\[\n\\text{Total variation} = \\text{Explained variation} + \\text{Unexplained variation/Error}\n\\]\\[\n\\text{Total sum squares} \\ (TSS) = \\text{Sum squares regression} \\ (SSR) + \\text{Sum squares error} \\ (SSE)\n\\]\\[\n\\sum^{n}_{=1}(y_{}-\\bar{y}_{})^{2} = \\sum^{n}_{=1}(\\hat{y}_{}-\\bar{y}_{})^{2} + \\sum^{n}_{=1}(y_{}-\\hat{y}_{})^{2}\n\\]\\(TSS\\) = Total variation = ค่าความผันผวนระหว่างข้อมูลกับค่าเฉลี่ยของข้อมูล\\(TSS\\) = Total variation = ค่าความผันผวนระหว่างข้อมูลกับค่าเฉลี่ยของข้อมูล\\(SSR\\) = Explained variation = ค่าความผันผวนระหว่างค่าเฉลี่ยของข้อมูลกับเส้น regression\\(SSR\\) = Explained variation = ค่าความผันผวนระหว่างค่าเฉลี่ยของข้อมูลกับเส้น regression\\(SSE\\) = Error = ค่าความผันผวนระหว่างข้อมูลกับเส้น regression\\(SSE\\) = Error = ค่าความผันผวนระหว่างข้อมูลกับเส้น regression\\(R^{2}\\) คือ อัตราส่วนระหว่าง Explained variation กับ Total variation = \\(\\frac{SSR}{TSS} = 1-\\frac{SSE}{TSS}\\) ซึ่งจะบ่งบอกความสามารถของเส้นถดถอย ในการอธิบายข้อมูล (goodness fit)\\(F\\)-test คือการเปรียบเทียบความสามารถของเส้นถดถอย ว่าสามารถอธิบายข้อมูลได้ดีกว่า \\(H_{0}\\) อย่างมีนัยสำคัญหรือไม่ ภายใต้สมมติฐาน\\(H_{0}\\): \\(f(x) = \\theta_{0} + c\\) หรือ สามารถอธิบายข้อมูลได้โดยใช้แค่ค่าเฉลี่ย\\(H_{0}\\): \\(f(x) = \\theta_{0} + c\\) หรือ สามารถอธิบายข้อมูลได้โดยใช้แค่ค่าเฉลี่ย\\(H_{}\\): \\(f(x) = \\theta_{0} + x_{1}\\theta_{1} + … + \\epsilon\\)\\(H_{}\\): \\(f(x) = \\theta_{0} + x_{1}\\theta_{1} + … + \\epsilon\\)ซึ่งเป็นการเทียบอัตราส่วน explained กับ unexplained variation เช่นเดียวกับ ANOVA\\[F =\\frac{MSR}{MSE} = \\frac{TSS-SSE}{SSE}/\\frac{DF_{TSS}-DF_{SSE}}{DF_{SSE}}\\]\\(t\\)-test คือการเปรียบเทียบเส้น regression เมื่อมีตัวแปรนั้น ว่าอธิบายได้ดีกว่าเมื่อไม่มีตัวแปรนั้นหรือไม่\\(H_{0}\\): \\(\\theta = 0\\)\\(H_{0}\\): \\(\\theta = 0\\)\\(H_{}\\): \\(\\theta \\neq 0\\)\\(H_{}\\): \\(\\theta \\neq 0\\)จะเห็นว่าสมการนั้นเหมือน One-sample t-test แต่เขียนในรูปแบบ regression\\[\nt = \\frac{\\theta-\\theta_{0}}{SE(\\theta)}\n\\]\\[\nSE(\\theta) = \\sqrt{\\frac{1}{n-2} \\times {\\sum_{=1}^{n}\\frac{(y_{} - \\hat{y_{}})^2}{(x_{} - \\hat{x_{}})^2}}}\n\\]","code":"\ndata(\"Diabetes\", package = \"heplots\")\n\nggplot(Diabetes, aes(x = glufast, y = sspg)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw()## \n## Call:\n## lm(formula = sspg ~ glufast, data = Diabetes)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -197.030  -59.050   -0.371   68.950  142.060 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  39.4534    13.3348   2.959  0.00362 ** \n## glufast       1.1866     0.0969  12.247  < 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 74.33 on 143 degrees of freedom\n## Multiple R-squared:  0.5119, Adjusted R-squared:  0.5085 \n## F-statistic:   150 on 1 and 143 DF,  p-value: < 2.2e-16\ndiabetes_fit <- lm(sspg ~ glufast, data = Diabetes) \nsummary(diabetes_fit)## \n## Call:\n## lm(formula = sspg ~ glufast, data = Diabetes)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -197.030  -59.050   -0.371   68.950  142.060 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  39.4534    13.3348   2.959  0.00362 ** \n## glufast       1.1866     0.0969  12.247  < 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 74.33 on 143 degrees of freedom\n## Multiple R-squared:  0.5119, Adjusted R-squared:  0.5085 \n## F-statistic:   150 on 1 and 143 DF,  p-value: < 2.2e-16"},{"path":"regression-model.html","id":"prediction","chapter":"11 Regression model","heading":"11.1.2 Prediction","text":"ข้อดีของสมการถอดถอย คือ สามารถใช้ในการทำนายข้อมูลตัวแปรตามชุดใหม่ได้ จากผลลัพธ์ขั้นต้นในคอลัมน์ coef พบว่าทุกๆ glufast ที่เพิ่มขึ้น 1.186 หน่วย ส่งผลให้ sspg เพิ่มขึ้น 1 หน่วย ซึ่งเขียนเป็นสมการได้ว่า\\[\nf(x) = 39.4354 \\ + 1.1866\\times(\\text{glufast}) + \\epsilon\n\\]โดยสมการนี้จะอยู่ใน diabetes_fit","code":"\nnew_sspg <- data.frame(glufast = 1:400) \nnew_sspg <- new_sspg |> \n  mutate(predicted_sspg = predict(diabetes_fit, newdata = new_sspg))\n\nggplot(new_sspg, aes(x = glufast, y = predicted_sspg)) +\n  geom_point(size = 0.3) + theme_bw()"},{"path":"regression-model.html","id":"logistic-regression","chapter":"11 Regression model","heading":"11.2 Logistic regression","text":"คือ สมการถดถอยซึ่งมีคุณสมบัติในการจำแนกตัวแปรแบบสองตัวแปร (binary classification) ซึ่งเขียนอยู่ในรูปของ ค่าลอการิธึมของอัตราส่วนความเสี่ยง (log odds)\\[\nlog(\\frac{h(x)}{1-h(x)}) = \\theta_{0} + x_{1}\\theta_{1} + x_{2}\\theta_{2} + \\ ... \\ + x_{n}\\theta_{n} + \\epsilon = z\n\\]\\[\n\\frac{h(x)}{1-h(x)} = e^{z}\n\\]\\[\nh(x) = \\frac{1}{1+e^{z}}\n\\]\\[\nh(x) = \\frac{1}{1+e^{\\theta_{0} + x_{1}\\theta_{1} + x_{2}\\theta_{2} + \\ ... \\ + x_{n}\\theta_{n} + \\epsilon}}\n\\]ความพิเศษของสมการนี้คือ ขอบเขตของ \\(h(x)\\) จะอยู่ระหว่าง (0, 1) เสมอ ซึ่งส่งผลให้สามารถคำนวณกลับไปทำนายอัตราการเกิดเหตุการณ์จากอัตราส่วนความเสี่ยงได้ต่อไปเราจะทำนายว่า glufast เพื่อให้ตัวแปรเป็น binary เราจะรวม Overt_Diabetic และ Chemical_Diabetic เป็นกลุ่มเดียวกัน","code":"\nlog_df <- data.frame(x = -20:20) |> mutate(y = 1/(1+exp(0 + 0.75*x)))\nggplot(log_df, aes(x = x, y = y)) + geom_line() + theme_bw() +\n  labs(y = \"h(x)\")\nDiabetes_mixed <- Diabetes |> mutate(group = \n                                       case_match(group,\n                                                  \"Normal\" ~ 0,\n                                                  \"Chemical_Diabetic\" ~ 1,\n                                                  \"Overt_Diabetic\" ~ 1))\n\nggplot(Diabetes_mixed, aes(x = glufast, y = group)) + \n  geom_point() +\n  geom_smooth(method = \"glm\",  method.args = list(family = \"binomial\"), \n              se = FALSE) +\n  theme_bw()\nlogit_fit <- glm(group ~ glufast, family = \"binomial\", \n                 data = Diabetes_mixed) \nlogit_fit## \n## Call:  glm(formula = group ~ glufast, family = \"binomial\", data = Diabetes_mixed)\n## \n## Coefficients:\n## (Intercept)      glufast  \n##    -11.7611       0.1158  \n## \n## Degrees of Freedom: 144 Total (i.e. Null);  143 Residual\n## Null Deviance:       200.7 \n## Residual Deviance: 121.9     AIC: 125.9\nnew_group <- data.frame(glufast = 1:200) \nnew_group <- new_group |> \n  mutate(predicted_group = predict(logit_fit, \n                                   newdata = new_group, type = \"response\"))\n\nggplot(new_group, aes(x = glufast, y = predicted_group)) +\n  geom_point() + theme_bw()"},{"path":"regression-model.html","id":"poisson-quassipoisson-and-negative-binomial-regression","chapter":"11 Regression model","heading":"11.3 Poisson, quassipoisson, and negative binomial regression","text":"Poission regression คือ สมการถดถอยที่ใช้ในการทำนายความถี่ หรือค่าเฉลี่ยของการเกิดเหตุการณ์นั้นๆ มักใช้กับข้อมูลที่ไม่ต่อเนื่อง (discrete value) พิจารณาข้อมูลแบบ Poisson distribution\\[\nf(k) = P(X = k) = \\frac{\\lambda^{k}}{k!}e^{-\\lambda}\n\\]จะพบว่ามีตัวแปรที่สามารถทำนายได้เมื่อมีข้อมูลอีกชนิดหนึ่ง คือ ค่าเฉลี่ยการเกิดเหตุการณ์ \\((\\lambda)\\) และ จำนวนเหตุการณ์ที่เกิด \\((k)\\) จึงออกมาเป็นสมการถดถอยได้สองรูปแบบสำหรับ \\(\\lambda\\)\\[\n\\lambda = e^{\\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2}+…+\\theta_{n}x_{n}}\n\\]\\[\nln(\\lambda) = \\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2}+…+\\theta_{n}x_{n}\n\\]สำหรับ \\(k\\) เราจำเป็นต้องเปลี่ยน \\(\\lambda\\) ให้อยู่ในรูป \\(k/t\\) และย้ายไปเป็นตัวแปรควบคุมเวลา (offset) ซึ่งจะมี regression coefficient = 1 เสมอ\\[ \\lambda = \\frac{k}{t} = e^{\\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2}+…+\\theta_{n}x_{n}} \\]\\[ ln(k) - \\ln(t) = \\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2}+…+\\theta_{n}x_{n} \\]\\[\nln(k) =  \\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2}+…+\\theta_{n}x_{n} + \\ln(t) \\rightarrow  \\text{offset}\n\\]ซึ่งสมการนี้เป็นสมการพื้นฐานของการนับจำนวนใดๆ ดังเช่นตัวอย่างนี้ คือความสัมพันธ์ของตัวแปรต่างๆ กับอัตราการตายในโรคมะเร็งปากมดลูกสังเกตว่ายิ่งอายุเยอะ อัตราการตายยิ่งน้อยลงอย่างมีนัยสำคัญ ซึ่งไม่น่าจะเป็นไปได้ ทั้งนี้ เพราะยังไม่ได้ปรับระยะเวลาติดตาม โดยการใส่ offset เป็น person-month เข้าไปคำนวณด้วยจะพบว่าหลังจากปรับตามระยะเวลาติดตาม กลุ่มอายุที่เพิ่มขึ้นจะส่งผลให้การตายเพิ่มขึ้นอย่างมีนัยสำคัญอย่างไรก็ตาม พิจารณาดูแล้วอัตราการตายไม่ได้เพิ่มขึ้นมากตามกลุ่มอายุ ซึ่งอาจจะเป็นผลบวกลวง เมื่อกลับมาพิจารณาแล้ว Poisson regression มีสมมติฐานที่สำคัญตาม Poisson distribution คือต้องเป็นจำนวนนับการกระจายตัวของข้อมูล = Dispersion parameter (\\(\\phi\\)) = Variance/Mean = 1เมื่อตรวจสอบจากผลลัพธ์ของสมการถอดถอย โดยพิจารณาจาก \\(\\text{residuals/deviance}\\) แล้วพบว่า \\(\\phi > 1\\) ซึ่งหมายความว่าข้อมูลตั้งต้นนั้นมีการกระจายตัวของข้อมูลสูงเกินไป (-dispersed) จึงไม่เป็นไปตามสมมติฐานของ Poisson ณ จุดนี้จึงจำเป็นต้องใช้ ส่วนขยายสมการของ Poisson regression เรียกว่า Quasipoisson regression ซึ่งจะทำการปรับความแปรปรวน ตามการเพิ่มขึ้นของความแปรปรวนต่อค่าเฉลี่ย\\[\nV = \\phi\\mu_{}\n\\] \\[\n\\phi = \\frac{\\chi^{2}}{\\text{DF}} = \\frac{1}{n-k}{\\sum_{=1}^{n}\\frac{(Y_{}-\\hat{\\mu_{}})^{2}}{\\hat{\\mu_{}}}}\n\\]จะเห็นว่าหลังจากปรับ dispersion parameter แล้ว age_group ไม่ได้ส่งผลให้การตายเพิ่มขึ้นอย่างมีนัยสำคัญแต่อย่างใด ปัญหาของ Quasipoisson คือ อาจจะไม่มี parameter ที่ต้องการ เช่น AIC เป็นต้น ซึ่งสามารถใช้อีกหนึ่งสมการถดถอยที่นิยมใช้คือ Negative binomial regression จาก package MASS ซึ่งปรับตามอัตราส่วนความแปรปรวนเช่นกัน\\[\nV = u_{}(1+\\frac{u_{}}{\\phi})\n\\]ผลลัพธ์ที่ได้จะใกล้เคียงกันกับสมการถดถอย Quasipoisson ทั้งสองสมการนี้จะนิยมใช้ในการตั้งสมการถดถอยในจำนวนนับจากงานทดลอง high-troughput เช่น RNA-sequencing เนื่องจากข้อมูลประเภทนี้มักมีเป็นข้อมูลจำนวนนับที่มีการกระจายตัวสูงมาก (\\(\\phi > 1\\))","code":"\ncervix_mort <- read.csv(\"Resource/cervix_mort.csv\") |>  # aggregrated data for demonstration\n                mutate(histo_major = fct_relevel(histo_major, \"Squamous cell carcinoma\",\n                                                 \"Adenocarcinoma\",\n                                                 \"Adenosquamous carcinoma\",\n                                                 \"Others\"))\nglm(dead ~  age_group + histo_major + stage, family = \"poisson\", data = cervix_mort) |> summary()## \n## Call:\n## glm(formula = dead ~ age_group + histo_major + stage, family = \"poisson\", \n##     data = cervix_mort)\n## \n## Coefficients:\n##                                     Estimate Std. Error z value Pr(>|z|)    \n## (Intercept)                         7.172968   0.031870  225.07   <2e-16 ***\n## age_group                          -0.748325   0.010905  -68.62   <2e-16 ***\n## histo_majorAdenocarcinoma          -1.413401   0.025945  -54.48   <2e-16 ***\n## histo_majorAdenosquamous carcinoma -2.850308   0.049905  -57.12   <2e-16 ***\n## histo_majorOthers                  -1.731075   0.029393  -58.89   <2e-16 ***\n## stage                               0.209258   0.008536   24.52   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for poisson family taken to be 1)\n## \n##     Null deviance: 25897.8  on 59  degrees of freedom\n## Residual deviance:  9499.4  on 54  degrees of freedom\n## AIC: 9832.1\n## \n## Number of Fisher Scoring iterations: 5\nggplot(cervix_mort, aes (x = age_group, y = dead)) +\n  geom_jitter() +\n  geom_smooth(method = \"glm\", method.args = list(family = \"poisson\"), se = FALSE) +\n  scale_x_continuous(breaks = 1:4) +\n  theme_bw()\npois_fit <- glm(dead ~  age_group + histo_major + stage + offset(log(person_month)),\n                family = \"poisson\", data = cervix_mort)\nsummary(pois_fit)## \n## Call:\n## glm(formula = dead ~ age_group + histo_major + stage + offset(log(person_month)), \n##     family = \"poisson\", data = cervix_mort)\n## \n## Coefficients:\n##                                     Estimate Std. Error  z value Pr(>|z|)    \n## (Intercept)                        -7.138354   0.035957 -198.523  < 2e-16 ***\n## age_group                           0.037519   0.014553    2.578  0.00994 ** \n## histo_majorAdenocarcinoma          -0.076841   0.025947   -2.961  0.00306 ** \n## histo_majorAdenosquamous carcinoma -0.001698   0.049964   -0.034  0.97289    \n## histo_majorOthers                   0.408249   0.029643   13.772  < 2e-16 ***\n## stage                               0.918984   0.007915  116.101  < 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for poisson family taken to be 1)\n## \n##     Null deviance: 15452.8  on 59  degrees of freedom\n## Residual deviance:  2386.7  on 54  degrees of freedom\n## AIC: 2719.4\n## \n## Number of Fisher Scoring iterations: 5\nnew_data <- expand_grid(age_group = 1:4,\n                       histo_major = unique(cervix_mort$histo_major),\n                       stage = 1:4,\n                       person_month = 1200)\nnew_data <- new_data |> \n  mutate(predicted_dead = predict(pois_fit, newdata = new_data, type = \"response\"))\n\nggplot(new_data, aes (x = age_group, y = predicted_dead, col = histo_major)) +\n  geom_line() +\n  facet_wrap(~stage)+\n  scale_y_continuous(breaks = seq(0,60,10)) +\n  theme_bw()\nquasipois_fit <- glm(dead ~  age_group + histo_major + stage + offset(log(person_month)),\n                family = \"quasipoisson\", data = cervix_mort)\nsummary(quasipois_fit)## \n## Call:\n## glm(formula = dead ~ age_group + histo_major + stage + offset(log(person_month)), \n##     family = \"quasipoisson\", data = cervix_mort)\n## \n## Coefficients:\n##                                     Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)                        -7.138354   0.256738 -27.804   <2e-16 ***\n## age_group                           0.037519   0.103913   0.361    0.719    \n## histo_majorAdenocarcinoma          -0.076841   0.185263  -0.415    0.680    \n## histo_majorAdenosquamous carcinoma -0.001698   0.356744  -0.005    0.996    \n## histo_majorOthers                   0.408249   0.211657   1.929    0.059 .  \n## stage                               0.918984   0.056517  16.260   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for quasipoisson family taken to be 50.98103)\n## \n##     Null deviance: 15452.8  on 59  degrees of freedom\n## Residual deviance:  2386.7  on 54  degrees of freedom\n## AIC: NA\n## \n## Number of Fisher Scoring iterations: 5\nnb_fit <- MASS::glm.nb(dead ~  age_group + histo_major + stage + offset(log(person_month)), \n                 data = cervix_mort)\nsummary(nb_fit)## \n## Call:\n## MASS::glm.nb(formula = dead ~ age_group + histo_major + stage + \n##     offset(log(person_month)), data = cervix_mort, init.theta = 1.720086921, \n##     link = log)\n## \n## Coefficients:\n##                                    Estimate Std. Error z value Pr(>|z|)    \n## (Intercept)                        -6.74220    0.37648 -17.908   <2e-16 ***\n## age_group                           0.13619    0.09497   1.434    0.152    \n## histo_majorAdenocarcinoma          -0.11835    0.28789  -0.411    0.681    \n## histo_majorAdenosquamous carcinoma -0.09216    0.30632  -0.301    0.764    \n## histo_majorOthers                   0.16574    0.28407   0.583    0.560    \n## stage                               0.82974    0.08937   9.285   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for Negative Binomial(1.7201) family taken to be 1)\n## \n##     Null deviance: 144.871  on 59  degrees of freedom\n## Residual deviance:  69.168  on 54  degrees of freedom\n## AIC: 598.94\n## \n## Number of Fisher Scoring iterations: 1\n## \n## \n##               Theta:  1.720 \n##           Std. Err.:  0.339 \n## \n##  2 x log-likelihood:  -584.937"},{"path":"survival-analysis.html","id":"survival-analysis","chapter":"12 Survival analysis","heading":"12 Survival analysis","text":"ในงานวิจัยที่กระทำกับผู้ป่วย หรือแม้กระทั้งเซลล์นั้น บางครั้งจะมีความจำเป็นที่ต้องทำการวิเคราะห์ข้อมูลเพื่อเปรียบเทียบสร้างแบบจำลองที่สามารถทำนายเวลาที่ใช้ก่อนที่จะเกิดเหตุการณ์ที่ท่านสนใจ (event) เช่น เวลาที่ผู้ป่วยจะเสียชีวิตจากโรคมะเร็งนับตั้งแต่วันวินิจฉัย เวลาของเซลล์ที่จะตายหลังจากใส่สารบางอย่างที่สนใจ เป็นต้นลักษณะพิเศษของการวิเคราะห์ survival analysis คือ มีการวิเคราะห์โดยใช้ปัจจัยที่เรียกว่า censoring ร่วม ซึ่งคือการที่ เหตุการณ์ที่คาดหวังว่าจะเกิดนั้นไม่มาถึงแม้ว่าจะครบตามเวลาที่ผู้วิจัยสังเกตการณ์แล้ว ซึ่งทำให้ไม่สามารถมั่นใจได้ว่าเหตุการณ์นั้นจะเกิดต่อไปหรือไม่ ณ เวลาหลังจากนี้การ censor โดยหลักมี 3 แบบ คือRight-censor (ดังรูป) คือ ไม่แน่ใจข้อมูลการเกิด event เวลาสุดท้ายที่พบ ซึ่งพบมมากที่สุดRight-censor (ดังรูป) คือ ไม่แน่ใจข้อมูลการเกิด event เวลาสุดท้ายที่พบ ซึ่งพบมมากที่สุดLeft-censor คือ ไม่แน่ใจข้อมูลช่วงเวลาเริ่มต้น เช่น diagnosis วันไหนLeft-censor คือ ไม่แน่ใจข้อมูลช่วงเวลาเริ่มต้น เช่น diagnosis วันไหนInterval-censor คือ เวลาช่วงใดช่วงหนึ่งหายไปInterval-censor คือ เวลาช่วงใดช่วงหนึ่งหายไป","code":""},{"path":"survival-analysis.html","id":"kaplein-meier-estimate","chapter":"12 Survival analysis","heading":"12.1 Kaplein-Meier estimate","text":"Kaplein-Meier estimate (KM) คือกราฟแสดงอัตราการเกิดของเหตุการณ์เมื่อเทียบกับเวลาที่ผ่านไป โดยหลักการคำนวณ survival คือ\\[ \\hat{S}(t) = \\prod_{: t_{} \\leq t}(1- \\frac{d_{}}{n_{}})\\]\\[\n\\text{Survival proability} = \\frac{n.risk - n.event}{n.risk}\n\\]อธิบายหลักการอย่างง่ายของ KM นั่นคือ ทุกเคสทียังไม่เกิดเหตุการณ์นั้น จะเป็น “เคสที่เสี่ยงต่อการเกิดเหตุการณ์ (risk)” ซึ่งจำนวนเคสแรกเริ่มที่เสี่ยง (number risk) จะเท่ากับจำนวนเคสทั้งหมด (sample size) โดยจะนับการเกิด event ตามปกติ เพียงแต่ถ้าเคสนั้นถูก censor นั้น n.risk จะลดลงด้วย ทำให้อัตราการเกิด event ยังไม่เปลี่ยนแปลง ดังตัวอย่างตามตารางเมื่อนำไปพล็อตกราฟแล้วจะได้ผลดังนี้สังเกตุว่าส่วนที่ censor (มีสัญลักษณ์ +) จะไม่มีการตกลงของกราฟ แต่เมื่อถึงเวลาที่มี event เกิดขึ้น การตกลงของกราฟจะสูงกว่าเมื่อไม่มี censor นำมาก่อน","code":""},{"path":"survival-analysis.html","id":"การสราง-km-ใน-r","chapter":"12 Survival analysis","heading":"12.1.1 การสร้าง KM ใน R","text":"ตัวอย่างข้อมูลของผู้ป่วยมะเร็งรังไข่ที่ได้รับการรักษาโดยการผ่าตัดอธิบายตัวแปร:age = อายุage = อายุfutime = ระยะเวลาติดตามตั้งแต่วินิจฉัยจนเสียชีวิต/มาพบแพทย์ครั้งสุดท้ายfutime = ระยะเวลาติดตามตั้งแต่วินิจฉัยจนเสียชีวิต/มาพบแพทย์ครั้งสุดท้ายfustat = 0 - censor, 1 - deadfustat = 0 - censor, 1 - deadresid.ds = มีชิ้นส่วนของมะเร็งหลงเหลือหลังจากการผ่าตัด (ผ่าตัดได้ไม่หมด)resid.ds = มีชิ้นส่วนของมะเร็งหลงเหลือหลังจากการผ่าตัด (ผ่าตัดได้ไม่หมด)rx = กลุ่มการรักษาrx = กลุ่มการรักษาecog.ps = ECOG performance status คะแนนน้อยแปลว่าผู้ป่วยมีสุขภาพโดยรวมดีecog.ps = ECOG performance status คะแนนน้อยแปลว่าผู้ป่วยมีสุขภาพโดยรวมดีเมื่อใช้ function Surv() จะทำการเปลี่ยน futime ให้รับรู้การ censor สังเกตว่าผู้ป่วยที่ ไม่เกิดเหตุการณ์จะมีสัญลักษณ์ + อยู่ข้างหลัง บ่งบอกว่าข้อมูลนั้นถูก censor นั่นหมายความว่า ผู้ป่วยจะเกิดเหตุการณ์หรือไม่ก็ได้หลังจากนี้ เพียงแต่ผู้วิจัยไม่สามารถทราบได้แล้วการพล็อต KM นั้นสามารถทำได้โดยใช้ package survminer โดยเริ่มจากการสร้างตาราง survival curve จากคำสั่ง survfit()หลังจากนั้นใช้คำสั่ง ggsurvplot() เพื่อทำการสร้างกราฟจะเห็นว่าผู้ป่วยกลุ่มนี้มี median survival อยู่ประมาณ 1.75 ปีจะพบว่า ถ้าผ่าตัดแล้วไม่เหลือร่องรอยของโรค จะมีอัตราการรอดชีวิตที่ดีกว่า แต่ยังไม่ถึงระดับมีนัยสำคัญ","code":"\nlibrary(dplyr) \nlibrary(survival)\nnames(ovarian)## [1] \"futime\"   \"fustat\"   \"age\"      \"resid.ds\" \"rx\"       \"ecog.ps\"\ncensored_df <- ovarian |>    \n  mutate(censored_futime = Surv(ovarian$futime, ovarian$fustat)) \n\nhead(select(censored_df, futime, fustat, censored_futime))\nlibrary(survminer)\n\novarian_surv <- survfit(\n  Surv(futime/365.25, fustat) ~ 1, data = ovarian # เปลี่ยนเป็นปี\n  )\n\novarian_surv |> tidy() |> head(10)\nggsurvplot(ovarian_surv, risk.table = TRUE, break.time.by = 0.25, \n           surv.median.line = \"hv\") \novarian_surv_resid <- survfit(\n  Surv(futime/365.25, fustat) ~ resid.ds, data = ovarian\n  )\n\nggsurvplot(ovarian_surv_resid, risk.table = TRUE, break.time.by = 0.25,\n           surv.median.line = \"hv\", pval = TRUE)"},{"path":"survival-analysis.html","id":"log-rank-test","chapter":"12 Survival analysis","heading":"12.2 Log-rank test","text":"Log-rank test คือ non-parametric test สำหรับ univariate analysis ที่เปรียบเทียบความแตกต่างของอัตราการเกิด event ว่าแตกต่างอย่างมีนัยสำคัญหรือไม่Observed คือ จำนวน event ที่เกิดขึ้นในแต่ละกลุ่มObserved คือ จำนวน event ที่เกิดขึ้นในแต่ละกลุ่มExpected คือ จำนวน event ที่คาดว่าจะเกิดขึ้นในแต่ละกลุ่มExpected คือ จำนวน event ที่คาดว่าจะเกิดขึ้นในแต่ละกลุ่ม(O-E)^2/E = Chi-square statistics ของค่า observed และ expected(O-E)^2/E = Chi-square statistics ของค่า observed และ expectedChisq = ผลสุดท้ายของ Chi-square statistics = sum(O-E)^2/EChisq = ผลสุดท้ายของ Chi-square statistics = sum(O-E)^2/Ep = p-value ของ Chi-square statisticsp = p-value ของ Chi-square statisticsค่า log-rank นี้ สามารถแสดงใน KM ได้โดยใช้ pval = TRUE ตามหัวข้อเบื้องต้น","code":"\novarian_surv_diff <- survdiff(\n  Surv(futime/365.25, fustat) ~ resid.ds, data = ovarian\n  )\n\novarian_surv_diff## Call:\n## survdiff(formula = Surv(futime/365.25, fustat) ~ resid.ds, data = ovarian)\n## \n##             N Observed Expected (O-E)^2/E (O-E)^2/V\n## resid.ds=1 11        3     6.26      1.70      3.62\n## resid.ds=2 15        9     5.74      1.85      3.62\n## \n##  Chisq= 3.6  on 1 degrees of freedom, p= 0.06"},{"path":"survival-analysis.html","id":"cox-proportional-hazard-model","chapter":"12 Survival analysis","heading":"12.3 Cox-proportional hazard model","text":"Cox-proportional hazard model (CPH) เป็น semi-parametric model ซึ่งวัด risk ของการเกิด event นั้นๆ โดยมี function คือ\\[\nh(t) = h_{0}(t) \\times exp(b_{1}X_{1} + b_{2}X_{2}+ ... + b_{s}X_{p})\n\\]\\[\nln(\\frac{h(t)}{h_{0}(t)}) = b_{1}X_{1} + b_{2}X_{2}+ ... + b_{s}X_{p}\n\\]ซึ่ง \\(h(t)/h_{0}(t)\\) นั้นคือ hazard ratio (HR) หรือ ความเสี่ยงของการเกิด event นั้นๆการวิเคราะห์ CPH นั้นมีข้อดีกว่า log-rank คือสามารถประมาณการเชิงปริมาณ (quantitative measurement) ผ่าน HR และสามารถวิเคราะห์สมการแบบ multivariate analysis ได้exp(coef) = HR = \\(h(t)/h_{0}(t)\\) ในที่นี้ท่านสามารถอภิปรายได้ว่า อายุที่เพิ่มขึ้น 1 ปีนั้น ส่งผลให้เกิดอัตราการเสียชีวิตในผู้ป่วยมะเร็งรังไข่เพิ่มขึ้น 1.13 เท่า (13%) และมีนัยสำคัญทางสถิติexp(coef) = HR = \\(h(t)/h_{0}(t)\\) ในที่นี้ท่านสามารถอภิปรายได้ว่า อายุที่เพิ่มขึ้น 1 ปีนั้น ส่งผลให้เกิดอัตราการเสียชีวิตในผู้ป่วยมะเร็งรังไข่เพิ่มขึ้น 1.13 เท่า (13%) และมีนัยสำคัญทางสถิติp ในตาราง คือ ค่าคำนวณ p-value จาก Wald’s test ของแต่ละตัวแปรว่ามีผลต่ออัตราการรอดชีวิตหรือไม่p ในตาราง คือ ค่าคำนวณ p-value จาก Wald’s test ของแต่ละตัวแปรว่ามีผลต่ออัตราการรอดชีวิตหรือไม่p ข้างล่าง คือ overall p จาก likelihood ratio test ว่าจากทั้งหมด มีตัวแปรใดตัวแปรหนึ่งส่งผลให้อัตรากการรอดชีวิตเปลี่ยนไปอย่างมีนัยสำคัญทางสถิติหรือไม่p ข้างล่าง คือ overall p จาก likelihood ratio test ว่าจากทั้งหมด มีตัวแปรใดตัวแปรหนึ่งส่งผลให้อัตรากการรอดชีวิตเปลี่ยนไปอย่างมีนัยสำคัญทางสถิติหรือไม่","code":"\novarian_cox <- coxph(Surv(futime/365.25, fustat) ~ \n                       resid.ds + age + factor(rx), data = ovarian) \n\novarian_cox## Call:\n## coxph(formula = Surv(futime/365.25, fustat) ~ resid.ds + age + \n##     factor(rx), data = ovarian)\n## \n##                coef exp(coef) se(coef)      z       p\n## resid.ds     0.6964    2.0065   0.7585  0.918 0.35858\n## age          0.1285    1.1372   0.0473  2.718 0.00657\n## factor(rx)2 -0.8489    0.4279   0.6392 -1.328 0.18416\n## \n## Likelihood ratio test=16.77  on 3 df, p=0.0007889\n## n= 26, number of events= 12"},{"path":"survival-analysis.html","id":"การตรวจสอบ-assumption-validity-ของ-cph","chapter":"12 Survival analysis","heading":"12.3.1 การตรวจสอบ assumption validity ของ CPH","text":"CPH นั้นมี assumption ดังนี้:ตัวแปรแต่ละกลุ่มมีอัตราการเกิด event ที่แตกต่างกันตัวแปรแต่ละกลุ่มมีอัตราการเกิด event ที่แตกต่างกันHR เท่ากันทุกช่วงเวลา เช่น ที่ 1, 2, 5 ปี อัตราส่วนการเสียชีวิตระหว่างตัวแปรเท่ากันหมดHR เท่ากันทุกช่วงเวลา เช่น ที่ 1, 2, 5 ปี อัตราส่วนการเสียชีวิตระหว่างตัวแปรเท่ากันหมดตัวแปรมีความสัมพันธ์แบบ linear continuous variableตัวแปรมีความสัมพันธ์แบบ linear continuous variableไม่จำเป็นต้องทราบลักษณะการกระจายตัวของข้อมูลก่อน (จึงเป็น semi-parametric model)ไม่จำเป็นต้องทราบลักษณะการกระจายตัวของข้อมูลก่อน (จึงเป็น semi-parametric model)สามารถตรวจสอบ HR ได้โดยใช้ proportionality assumption test จาก Schoenfeld residuals โดย cox.zph()โดย test นี้จะทำการเปรียบเทียบ residuals ระหว่าง risk-weight average กับ ตัวแปรนั้นๆ ว่ามีการเปลี่ยนแปลงไปในทิศทางใดทิศทางหนึ่งหรือไม่ ถ้ามี (p < 0.05) หมายความว่า เวลาที่ผ่านไปอาจจะส่งผลให้ HR นั้นมีความแตกต่างกัน ซึ่งจะต้องทำ time-varying CPH เพิ่มเติมโดยในข้อมูล ovarian นี้ ไม่มีตัวใดที่ p-value < 0.05 จึงถือได้ว่า อัตราส่วนนั้นคงที่ และทำให้ CPH นั้น validในส่วนของ linearity สามารถตวจสอบโดยใช้ function ggcoxfunctional()จะเห็นว่า age นั้นการเพิ่มขึ้นแบบ linearity โดยมี deviation เล็กน้อย","code":"\novarian_coxzph <- cox.zph(ovarian_cox) \nggcoxzph(ovarian_coxzph)\novarian_linear_age <- ggcoxfunctional(Surv(futime/365.25, fustat)~  age+                                 + I(log(age)) + I(sqrt(age)), data = ovarian) \novarian_linear_age"},{"path":"bioconductor.html","id":"bioconductor","chapter":"13 Bioconductor","heading":"13 Bioconductor","text":"Bioconductor คือกลุ่มของ open-source package ที่ใช้ในการวิเคราะห์ข้อมูลประเภท bioinformatics ที่ครอบคลุมหลากหลายมากที่สุดใน R ซึ่งจุดเด่นหลักของ bioconductor นั้นคือการวิเคราะห์ข้อมูลประเภท high-throughout technology เช่นSummarizedExperiment, Biobase สำหรับการเก็บข้อมูลSummarizedExperiment, Biobase สำหรับการเก็บข้อมูลlimma สำหรับการวิเคราะห์ข้อมูล RNA microarray, RNA-seq, proteomicslimma สำหรับการวิเคราะห์ข้อมูล RNA microarray, RNA-seq, proteomicsedgeR, DESeq2 สำหรับการวิเคราะห์ข้อมูล RNA-seqedgeR, DESeq2 สำหรับการวิเคราะห์ข้อมูล RNA-seqmaftools สำหรับ สำหรับการวิเคราะห์ข้อมูล genomicsmaftools สำหรับ สำหรับการวิเคราะห์ข้อมูล genomicsclusterProfiler สำหรับ functional analysisclusterProfiler สำหรับ functional analysisComplexHeatmap, EnhancedVolcano, PCAtools สำหรับ visualizationComplexHeatmap, EnhancedVolcano, PCAtools สำหรับ visualizationและอื่นๆ อีกมากสามารถดูได้ที่ https://www.bioconductor.org/packages/release/bioc/การติดตั้ง package ต่างๆ จาก bioconductor ลงใน R นั้น จำเป็นเรียกจากชุดติดตั้งของ bioconductor โดยเฉพาะ ชื่อว่า BiocManagerหลังจากนั้น จะสามารถติดตั้ง package ได้โดยการเรียกชุดติดตั้ง BiocManager เช่นจะทำการติดตั้ง package limma ลงใน R ซึ่งหลังจากนั้นสามารถใช้คำสั่ง library เรียกได้ตามปกติ","code":"\nif (!require(\"BiocManager\", quietly = TRUE)) # ตรวจสอบว่ามีติดตั้งไว้แล้วหรือไม่\n    install.packages(\"BiocManager\")\nBiocManager::install(\"limma\")"},{"path":"limma.html","id":"limma","chapter":"14 Limma","heading":"14 Limma","text":"","code":""},{"path":"limma.html","id":"principle-1","chapter":"14 Limma","heading":"14.1 Principle","text":"Limma (Linear Model Microarray Data) เป็นหนึ่งใน bioconductor package ที่นิยมใช้อย่างแพร่หลายในการศึกษา ความแตกต่างของการแสดงออกของยีนระหว่างกลุ่มสองกลุ่ม (Differential gene expression; DGE) ในงานทดลอง Microarrayหลักการสำคัญของ limma คือการใช้สมการถดถอยเชิงเส้นในการหา DGE โดยมีสมมติฐานเบื้องต้นว่าค่าความเข้มพื้นหลังที่อ่านได้จาก Probe ของ Microarray นั้นมีการกระจายตัวแบบ Normal distribution ซึ่งหลักการนี้สามารถนำไปปรับใช้ในการหา Differential expression ในงานประเภทอื่นๆ ได้ด้วย เช่น RNA-seq, Proteomics\\(H_{0}\\): ไม่มีความแตกต่างกันในการแสดงออกของยีน\\(H_{0}\\): ไม่มีความแตกต่างกันในการแสดงออกของยีน\\(H_{}\\): มีความแตกต่างกันในการแสดงออกของยีน\\(H_{}\\): มีความแตกต่างกันในการแสดงออกของยีนจากกราฟ เส้นประคือเส้นของ \\(H_{0}\\) หมายถึงการแสดงออกของยีนทั้งหมดสามารถหาได้โดยใช้ค่าเฉลี่ยโดยรวมของทั้งสองกลุ่ม \\(\\text{Intensity} = \\theta + \\epsilon\\) และ เส้นทึบคือเส้นของ \\(H_{}\\) หมายคือเส้นสมการถดถอยที่ลากผ่านค่าเฉลี่ยของแต่ละกลุ่ม \\(\\text{Intensity }= \\theta + \\theta_{1}*\\text{Group} + \\epsilon\\) ซึ่งทั้งหมดนี้ ก็คือเส้นสมการถดถอยเชิงเส้นตามปกติโดยทั่วไปนั่นเอง โดย limma ซึ่งความแตกต่างตามสมมติฐานนั้น จะถูกทดสอบ โดย \\(t\\)-test (\\(F\\)-test ถ้ามากกว่าสองกลุ่ม)คำถามคือ วิธีการของ limma แตกต่างอย่างไรกับการสร้างสมการถดถอยโดยทั่วไป? เนื่องจากงานประเภท Bioinformatics นั้นมักมีค่าใช้จ่ายในแต่ละการทดลองสูง จำนวนตัวอย่างที่นำมาใช้ในการทดลองนั้นมีไม่มากนัก เช่น 3-4 ตัวอย่างต่อกลุ่ม\\[\nt = \\frac{\\beta}{SE} = \\frac{\\beta}{S/\\sqrt{n}}\n\\]ซึ่งเมื่อพิจารณาจากสูตรแล้ว จะเห็นว่าจำนวนตัวอย่างที่ต่ำ ส่งผลให้ \\(SE\\) สูง มีค่า \\(t\\) ที่แกว่ง (ตาม \\(S\\)) และมี Power ที่ต่ำด้วย เนื่องจากมีกลุ่มตัวอย่างน้อยผู้นิพนธ์ limma นั้นได้แก้ปัญหานี้โดยใช้หลักการสถิติแบบ Empirical Bayesian ชื่อว่า Moderated \\(t\\)-test โดยหลักการคือ เนื่องจากหลักการของการอ่านข้อมูลใน Microarray ในแต่ละยีนนั้นเป็นไปโดยพร้อมกัน อัตราส่วนความแปรปรวนของยีนแต่ละตัวที่อ่านค่าได้นั้นจะเท่าๆ กันตลอดทั้ง array ดังนั้นจึงสามารถยืมข้อมูลของความแปรปรวนมาจากทุกยีนทั้งหมด มาสร้างเป็น ความน่าจะเป็นก่อนหน้า (Prior probability) เพื่อนำมาถ่วงน้ำหนักกับยีนแต่ละตัว (Posterior probability) ภายหลังค่า mean variance นี้จะถูกนำไปถ่วงน้ำหนักความแปรปรวนเดิมของแต่ละยีน และจะถูกนำไปใช้ในการคำนวณใหม่ เรียกว่า moderated \\(t\\)\\[\n\\tilde{t_{gj}} = \\sqrt\\frac{d_{0} + d_{g}}{d_{g}}\\times\\frac{\\hat{\\beta_{gj}}}{\\sqrt{s^{2}_{*,g}/n_{gj}}}\n\\]\\[\ns^{2}_{*,g} = s^{2}_{g}+(\\frac{d_{0}}{d_{g}})s_{0}^{2}\n\\]สังเกตว่า ค่า \\(\\tilde{t}\\) นั้นจะถูก Moderated ให้เข้าสู่ \\(d_{0}\\) (Prior degree freedom) และ \\(s_{0}\\) (Prior variance) ส่งผลให้ถ้า \\(d_{g}\\) (Degree freedom แต่ละยีน) > \\(d_{0}\\) และ \\(s_{g}\\) (ความแปรปรวนแต่ละยีน) > \\(s_{0}\\): \\(d\\) และ \\(s^{2}\\) โดยรวมจะถูกดึงให้เพิ่มขึ้นถ้า \\(d_{g}\\) (Degree freedom แต่ละยีน) > \\(d_{0}\\) และ \\(s_{g}\\) (ความแปรปรวนแต่ละยีน) > \\(s_{0}\\): \\(d\\) และ \\(s^{2}\\) โดยรวมจะถูกดึงให้เพิ่มขึ้นถ้า \\(d_{g}\\) < \\(d_{0}\\) และ \\(s_{g}\\) < \\(s_{0}\\): \\(d\\) และ \\(s^{2}\\) โดยรวมจะถูกดึงให้ลดลงถ้า \\(d_{g}\\) < \\(d_{0}\\) และ \\(s_{g}\\) < \\(s_{0}\\): \\(d\\) และ \\(s^{2}\\) โดยรวมจะถูกดึงให้ลดลงถ้า \\(d_{g}\\) = \\(d_{0}\\) และ \\(s_{g}\\) = \\(s_{0}\\): \\(d\\) จะเพิ่มขึ้นในอัตราส่วนคงที่ (\\(\\sqrt{2}\\)) และ \\(s^{2}\\) โดยรวมจะเท่าเดิมถ้า \\(d_{g}\\) = \\(d_{0}\\) และ \\(s_{g}\\) = \\(s_{0}\\): \\(d\\) จะเพิ่มขึ้นในอัตราส่วนคงที่ (\\(\\sqrt{2}\\)) และ \\(s^{2}\\) โดยรวมจะเท่าเดิมทั้งหมดนี้จะส่งผลให้ มี Moderate effect ของการคำนวณค่า \\(\\tilde{t}\\) และมี Degree freedom ที่เพิ่มขึ้นส่งผลให้ Power สูงขึ้น (เพราะการกระจายตัวแคบลง)","code":"\ncx_nc <- GSE63514 |> \n  as.data.frame() |> \n  dplyr::select(contains(c(\"Normal\", \"Cancer\")))\ncx_var <- apply(cx_nc, 1, var)\n\nggplot(data = NULL, aes(x = cx_var)) + \n  geom_density(fill = \"skyblue\") +\n  scale_x_continuous(breaks = seq(0,3,0.25), limits = c(0,3)) +\n  annotate(\"text\", x = mean(cx_var)+0.35, y=4, label= \"Mean variance\") +\n  labs(x = \"Variance\") +\n  geom_vline(xintercept = mean(cx_var), linetype = \"dashed\")"},{"path":"limma.html","id":"example","chapter":"14 Limma","heading":"14.2 Example","text":"ต่อจากนี้จะยกตัวอย่างการคำนวณ DGE ระหว่างกลุ่มโดยใช้ limma ต่อจาก GSE63514 ซึ่งครั้งนี้จะเทียบทุกกลุ่ม และเทียบทุกยีนก่อนอื่นจะต้องสร้างสมการเชิงเส้นของกลุ่มแต่ละกลุ่มขึ้นมาก่อนแมทริกซ์ที่เห็นนี้ ข้อมูลของ Sample แต่ละคน โดยแต่ละคอลัมน์จะเป็นตัวแทนของกลุ่มของ Sample นั้น เช่น คนที่ 1 จะมีตัวเลข [0 0 0 0 1] บ่งบอกว่าเป็นชิ้นเนื้อประเภท Cancer และคนสุดท้ายเป็น [1 0 0 0 0] บ่งบอกว่าชิ้นเนื้อประเภท Normalต่อจากนั้นเราจะสร้าง contrast matrix ขึ้นมาเพื่อนำไปใช้อ้างอิงในการเทียบ DEGสังเกตว่าแต่ละคอลัมน์ผลรวมจะเท่ากับ 0 เนื่องจาก \\(H_{0}\\) ว่าไม่มีความแตกต่างกันในการแสดงออกของยีน (= 0) นั่นเองเมื่อได้ design matrix ต่อไปคือการ fit linear regression ตาม model โดยข้อมูลจะต้องอยู่ในรูปตัวเลขทั้งหมด ดังนั้นจะต้องปรับแต่ง ข้อมูล expression เริ่มต้นเล็กน้อยต่อจากนั้นจะ fit model ด้วย lmFit และเทียบแต่ละกลุ่มด้วย contrasts.fitสุดท้ายเราจะทำการคำนวณ Moderated t-test โดยใช้ eBayesสุดท้ายคือการแสดงผล DGE จากการคำนวณทั้งหมดโดยใช้ topTableซึ่งจะแสดง Moderated \\(F\\)-test (ANOVA) และ \\(p\\)-value, Adjusted \\(p\\)-valueและสามารถเรียกดู \\(t\\)-testแต่ละกลุ่มได้โดยการระบุ coefโดย logFC log2 fold-change ของ gene expression แต่ละตัวท่านสามารถสรุปข้อมูล DGE ได้โดยใช้ decideTests","code":"\npData <- GSE63514_meta |> \n  select(title) |> \n  mutate(group = gsub(\"-\\\\d+\", \"\", title))\nunique(pData$group)## [1] \"Normal\" \"CIN1\"   \"CIN2\"   \"CIN3\"   \"Cancer\"\ncx_mod <- model.matrix(~ 0 + group, data = pData)\nas.data.frame(cx_mod) # display as dataframe\ncontrasts <- apply(combn(colnames(cx_mod),2)[2:1,], 2, paste, collapse = \"-\")\ncontrasts##  [1] \"groupCIN1-groupCancer\"   \"groupCIN2-groupCancer\"   \"groupCIN3-groupCancer\"   \"groupNormal-groupCancer\"\n##  [5] \"groupCIN2-groupCIN1\"     \"groupCIN3-groupCIN1\"     \"groupNormal-groupCIN1\"   \"groupCIN3-groupCIN2\"    \n##  [9] \"groupNormal-groupCIN2\"   \"groupNormal-groupCIN3\"\ncontrasts.matrix <- makeContrasts(contrasts = contrasts, levels = colnames(cx_mod)) \ncontrasts.matrix##              Contrasts\n## Levels        groupCIN1-groupCancer groupCIN2-groupCancer groupCIN3-groupCancer groupNormal-groupCancer\n##   groupCancer                    -1                    -1                    -1                      -1\n##   groupCIN1                       1                     0                     0                       0\n##   groupCIN2                       0                     1                     0                       0\n##   groupCIN3                       0                     0                     1                       0\n##   groupNormal                     0                     0                     0                       1\n##              Contrasts\n## Levels        groupCIN2-groupCIN1 groupCIN3-groupCIN1 groupNormal-groupCIN1 groupCIN3-groupCIN2 groupNormal-groupCIN2\n##   groupCancer                   0                   0                     0                   0                     0\n##   groupCIN1                    -1                  -1                    -1                   0                     0\n##   groupCIN2                     1                   0                     0                  -1                    -1\n##   groupCIN3                     0                   1                     0                   1                     0\n##   groupNormal                   0                   0                     1                   0                     1\n##              Contrasts\n## Levels        groupNormal-groupCIN3\n##   groupCancer                     0\n##   groupCIN1                       0\n##   groupCIN2                       0\n##   groupCIN3                      -1\n##   groupNormal                     1\nGSE63514_fixed <- GSE63514 |> \n                    column_to_rownames(\"prob\")\ncx_fit <- lmFit(GSE63514_fixed, design = cx_mod)\ncx_fit_contrasts <- contrasts.fit(cx_fit, contrasts.matrix)\ncx_fit_contrasts_eB <- eBayes(cx_fit_contrasts)\ntopTable(cx_fit_contrasts_eB, n = 100) # 100 ตัวแรกที่ sig difference\ntopTable(cx_fit_contrasts_eB, coef = 1, n = 100) # เรียงตาม contrasts.matrix\nmap(1:length(colnames(contrasts.matrix)), \n    ~topTable(cx_fit_contrasts_eB, coef = .x)) |> \n  set_names(colnames(contrasts.matrix))## $`groupCIN1-groupCancer`\n##                  logFC   AveExpr         t      P.Value    adj.P.Val        B\n## 206025_s_at -1.2599869  6.600127 -7.954562 8.906110e-13 4.869415e-08 18.36296\n## 222835_at    2.7037467 11.390512  7.656871 4.369597e-12 9.910994e-08 16.87732\n## 232855_at    1.9511837  7.464893  7.581694 6.508984e-12 9.910994e-08 16.50502\n## 220090_at    5.1219007 11.675811  7.561290 7.250842e-12 9.910994e-08 16.40418\n## 205185_at    3.6701214 12.344023  7.312213 2.685207e-11 2.682614e-07 15.18098\n## 235651_at    2.5105300 11.627430  7.294601 2.943884e-11 2.682614e-07 15.09504\n## 203857_s_at -1.3379967  8.865472 -7.135465 6.732460e-11 5.258532e-07 14.32218\n## 226506_at    2.2236684 10.612391  6.929967 1.938536e-10 1.324868e-06 13.33417\n## 207821_s_at -0.8531452  7.215208 -6.723744 5.531008e-10 3.360087e-06 12.35491\n## 40016_g_at   1.6956215 11.063432  6.637076 8.558517e-10 4.077549e-06 11.94725\n## \n## $`groupCIN2-groupCancer`\n##                 logFC   AveExpr          t      P.Value    adj.P.Val        B\n## 206025_s_at -1.380196  6.600127 -10.011010 1.030733e-17 5.635535e-13 29.24779\n## 210495_x_at -2.715234 10.074149  -8.851861 6.668495e-15 1.617849e-10 23.13848\n## 216442_x_at -2.764813  9.747865  -8.800039 8.877086e-15 1.617849e-10 22.86809\n## 205464_at    2.458379  9.030410   8.665389 1.863583e-14 2.435352e-10 22.16703\n## 218468_s_at -2.659120  5.349137  -8.625147 2.324822e-14 2.435352e-10 21.95795\n## 219597_s_at  1.847612 10.636695   8.599759 2.672540e-14 2.435352e-10 21.82616\n## 211719_x_at -2.978875  9.677495  -8.468114 5.497177e-14 3.537199e-10 21.14420\n## 227140_at   -3.349588  6.795510  -8.460792 5.721706e-14 3.537199e-10 21.10635\n## 212464_s_at -2.941674  9.149103  -8.457596 5.822549e-14 3.537199e-10 21.08983\n## 220090_at    4.972371 11.675811   8.433644 6.636766e-14 3.628652e-10 20.96605\n## \n## $`groupCIN3-groupCancer`\n##                  logFC   AveExpr          t      P.Value    adj.P.Val        B\n## 206025_s_at -1.3149204  6.600127 -11.027724 3.311442e-20 1.810531e-15 34.44112\n## 218468_s_at -2.5804213  5.349137  -9.677614 6.709207e-17 1.834129e-12 27.33557\n## 227566_at   -1.2024603  6.615340  -8.972807 3.415686e-15 5.539439e-11 23.65417\n## 206026_s_at -1.3312089  6.219060  -8.941927 4.052630e-15 5.539439e-11 23.49384\n## 219597_s_at  1.6246901 10.636695   8.743700 1.211057e-14 1.324291e-10 22.46704\n## 210495_x_at -2.2247812 10.074149  -8.386172 8.599897e-14 7.836656e-10 20.62733\n## 205464_at    2.0342073  9.030410   8.290557 1.447645e-13 1.130714e-09 20.13838\n## 216442_x_at -2.2269918  9.747865  -8.195711 2.422825e-13 1.655849e-09 19.65479\n## 212464_s_at -2.4481475  9.149103  -8.138402 3.304613e-13 1.950668e-09 19.36330\n## 213434_at   -0.7553377  8.747262  -8.124238 3.567751e-13 1.950668e-09 19.29135\n## \n## $`groupNormal-groupCancer`\n##                 logFC   AveExpr          t      P.Value    adj.P.Val        B\n## 232855_at    2.353804  7.464893  10.762249 1.485735e-19 8.123254e-15 33.65727\n## 206025_s_at -1.407391  6.600127 -10.455133 8.425180e-19 2.303233e-14 31.99032\n## 207802_at    6.508949  7.727577  10.008609 1.044759e-17 1.904073e-13 29.57022\n## 205464_at    2.730049  9.030410   9.855695 2.468951e-17 2.847392e-13 28.74320\n## 212621_at   -1.668245  9.041825  -9.816828 3.071485e-17 2.847392e-13 28.53318\n## 226506_at    2.672522 10.612391   9.800471 3.367040e-17 2.847392e-13 28.44482\n## 210262_at    3.001186  6.730272   9.786321 3.645495e-17 2.847392e-13 28.36840\n## 214431_at   -1.402298 10.718458  -9.638181 8.369057e-17 5.086653e-13 27.56901\n## 202055_at   -1.184061  9.912045  -9.638095 8.373092e-17 5.086653e-13 27.56855\n## 222835_at    2.873757 11.390512   9.576350 1.183340e-16 6.469909e-13 27.23578\n## \n## $`groupCIN2-groupCIN1`\n##                  logFC  AveExpr         t      P.Value adj.P.Val         B\n## 217575_s_at -0.2603589 4.108856 -4.119514 6.827838e-05 0.9999659 -1.555995\n## 219450_at    1.3974047 8.021937  4.108238 7.128229e-05 0.9999659 -1.572421\n## 204779_s_at  1.0783374 9.084288  3.979722 1.157851e-04 0.9999659 -1.757629\n## 214611_at   -0.3799563 5.371863 -3.974482 1.180717e-04 0.9999659 -1.765101\n## 219358_s_at -0.5104374 7.798451 -3.972613 1.188977e-04 0.9999659 -1.767765\n## 216973_s_at  0.9522317 9.119675  3.794046 2.290469e-04 0.9999659 -2.018449\n## 242979_at   -1.3010652 7.799901 -3.791582 2.310954e-04 0.9999659 -2.021855\n## 228152_s_at -1.1207177 8.651740 -3.777430 2.431998e-04 0.9999659 -2.041386\n## 235350_at    1.5458201 7.528341  3.714830 3.043333e-04 0.9999659 -2.127184\n## 238175_at   -0.3896401 4.538269 -3.696149 3.252317e-04 0.9999659 -2.152598\n## \n## $`groupCIN3-groupCIN1`\n##                  logFC   AveExpr         t      P.Value  adj.P.Val        B\n## 204603_at    0.7024178  8.164955  5.356714 3.887100e-07 0.01455424 5.999781\n## 204775_at    0.6352418  7.355724  5.222561 7.081541e-07 0.01455424 5.472794\n## 202954_at    0.8500242 10.181699  5.147294 9.876396e-07 0.01455424 5.180686\n## 209054_s_at  0.7012696  9.439562  5.130188 1.064782e-06 0.01455424 5.114663\n## 225784_s_at -0.5082652  7.521747 -5.022461 1.703992e-06 0.01765170 4.702034\n## 226308_at    0.8984545  7.797713  4.964062 2.193210e-06 0.01765170 4.480667\n## 209053_s_at  0.7712176  8.902046  4.936377 2.470436e-06 0.01765170 4.376302\n## 219490_s_at  0.5818629  8.117920  4.926008 2.582782e-06 0.01765170 4.337314\n## 202183_s_at  0.8829252  8.037612  4.885240 3.074616e-06 0.01867829 4.184526\n## 226456_at    1.0098740 10.334927  4.802377 4.369883e-06 0.02274771 3.876535\n## \n## $`groupNormal-groupCIN1`\n##                  logFC   AveExpr         t      P.Value  adj.P.Val          B\n## 210262_at    1.8942513  6.730272  5.109272 1.167105e-06 0.06381149  0.1414762\n## 226702_at   -1.8232496  9.133420 -4.447203 1.888683e-05 0.51631880 -0.9456764\n## 219258_at   -0.9936006  8.488497 -4.236185 4.353151e-05 0.59048057 -1.2746881\n## 217905_at   -0.5415615  8.950872 -4.227458 4.503515e-05 0.59048057 -1.2880906\n## 229450_at   -1.6129526  9.183332 -4.170784 5.608285e-05 0.59048057 -1.3747156\n## 209969_s_at -1.4138293 10.354201 -4.133184 6.479897e-05 0.59048057 -1.4317897\n## 204510_at   -1.0598884  9.627055 -4.069143 8.270786e-05 0.64600748 -1.5282574\n## 227609_at   -1.1735956  9.637705 -4.001474 1.067367e-04 0.70559370 -1.6291527\n## 210766_s_at -0.6423773 11.534705 -3.978886 1.161471e-04 0.70559370 -1.6625908\n## 204994_at   -1.1295418 10.139366 -3.914339 1.475994e-04 0.80699981 -1.7574641\n## \n## $`groupCIN3-groupCIN2`\n##                  logFC   AveExpr         t      P.Value adj.P.Val           B\n## 31845_at     0.5943656  9.673283  4.745089 5.560039e-06 0.1145089  1.57530720\n## 214858_at   -0.8133322  5.396801 -4.732526 5.860234e-06 0.1145089  1.54352542\n## 232222_at    0.3363060  6.001814  4.715848 6.283067e-06 0.1145089  1.50141268\n## 241014_at   -1.1644315  6.254372 -4.243388 4.232694e-05 0.5785564  0.34663636\n## 205968_at    0.8210918  9.169976  4.159667 5.853537e-05 0.6236596  0.15019705\n## 220040_x_at -0.3462818  7.659149 -4.061818 8.503499e-05 0.6236596 -0.07605645\n## 229782_at   -0.7239349  6.901729 -3.981172 1.151596e-04 0.6236596 -0.25975588\n## 1563881_at  -0.7137692  4.397457 -3.971422 1.194271e-04 0.6236596 -0.28179416\n## 200060_s_at  0.3245884 11.538188  3.970706 1.197462e-04 0.6236596 -0.28341066\n## 236010_at   -0.5131600  5.533651 -3.936483 1.359910e-04 0.6236596 -0.36045186\n## \n## $`groupNormal-groupCIN2`\n##                 logFC   AveExpr         t      P.Value    adj.P.Val        B\n## 223556_at   -1.445308  9.156569 -7.093800 8.350796e-11 4.565797e-06 13.83546\n## 235609_at   -1.432506  9.066440 -6.867548 2.666254e-10 7.288873e-06 12.78063\n## 201930_at   -1.280896 11.792626 -6.667073 7.360367e-10 1.262858e-05 11.85781\n## 218039_at   -1.450594 11.879667 -6.597757 1.042446e-09 1.262858e-05 11.54149\n## 218585_s_at -1.642935 10.431612 -6.577297 1.154877e-09 1.262858e-05 11.44841\n## 205909_at   -1.310771  9.479550 -6.532028 1.447888e-09 1.319388e-05 11.24291\n## 225655_at   -1.473806 10.563237 -6.484394 1.835405e-09 1.366560e-05 11.02737\n## 226456_at   -1.292656 10.334927 -6.467152 1.999539e-09 1.366560e-05 10.94953\n## 204026_s_at -1.136500 11.876375 -6.437869 2.312056e-09 1.404574e-05 10.81756\n## 228273_at   -1.497697  9.925345 -6.403594 2.739372e-09 1.497751e-05 10.66344\n## \n## $`groupNormal-groupCIN3`\n##                  logFC   AveExpr         t      P.Value    adj.P.Val        B\n## 218585_s_at -2.1455228 10.431612 -9.819011 3.034047e-17 9.812847e-13 28.38863\n## 204510_at   -1.9576326  9.627055 -9.789077 3.589519e-17 9.812847e-13 28.22861\n## 221521_s_at -1.7711864 10.294773 -9.687331 6.353396e-17 1.157906e-12 27.68508\n## 222680_s_at -1.8101779  8.533391 -9.265312 6.725115e-16 6.884628e-12 25.43791\n## 225655_at   -1.8399722 10.563237 -9.254393 7.146915e-16 6.884628e-12 25.37995\n## 226456_at   -1.6163749 10.334927 -9.244420 7.555147e-16 6.884628e-12 25.32702\n## 235609_at   -1.6711061  9.066440 -9.158340 1.219785e-15 9.527392e-12 24.87058\n## 205339_at   -1.8494642  9.227739 -9.117800 1.528068e-15 1.044339e-11 24.65586\n## 204603_at   -0.9813232  8.164955 -9.000435 2.930854e-15 1.649719e-11 24.03517\n## 218039_at   -1.7300249 11.879667 -8.995189 3.017319e-15 1.649719e-11 24.00746\nresults <- decideTests(cx_fit_contrasts_eB, fc=log2(1.5)) \nsummary(results)##        groupCIN1-groupCancer groupCIN2-groupCancer groupCIN3-groupCancer groupNormal-groupCancer groupCIN2-groupCIN1\n## Down                    2221                  3818                  2402                    6317                   0\n## NotSig                 50408                 47570                 50026                   40811               54675\n## Up                      2046                  3287                  2247                    7547                   0\n##        groupCIN3-groupCIN1 groupNormal-groupCIN1 groupCIN3-groupCIN2 groupNormal-groupCIN2 groupNormal-groupCIN3\n## Down                    34                     0                   0                   311                  2214\n## NotSig               54548                 54675               54675                 54333                 50612\n## Up                      93                     0                   0                    31                  1849\nvennDiagram(results[,1:5]) # max 5 groups"},{"path":"limma.html","id":"mean-variance-relationship","chapter":"14 Limma","heading":"14.3 Mean-variance relationship","text":"ในบางข้อมูลนั้นมีความสัมพันธ์ระหว่างค่าเฉลี่ยและความแปรปรวน ซึ่งสามารถตรวจสอบได้โดยใช้ plotSAจากกราฟจะพบความสัมพันธ์ระหว่าง Average log-expression และ sqrt(sigma) แปลว่ามีความสัมพันธ์ระหว่างค่าเฉลี่ยและความแปรปรวน เนื่องจาก Linear model นั้นมีสมมติฐานว่า ความแปรปรวนนั้นคงที่ตลอด (Homoscedasticity) การสร้างสมการแบบธรรมดาอาจจะทำให้เกิด False positive มากกว่าปกติ ซึ่ง limma นั้นมีฟังก์ชันที่ปรับสมการตามแนวโน้มของความแปรปรวนด้วย eBayes(..., trend = TRUE)เมื่อทำการพล็อตความสัมพันธ์ระหว่างค่าเฉลี่ยและความแปรปรวนอีกครั้ง จะพบว่าโมเดลนั้นถูกปรับตามความแปรปรวนแล้วการใช้ trend = TRUE นี้มีความสำคัญมากในการประยุกต์ใช้ limma ในการวิเคราะห์ข้อมูลแบบอื่นๆ ที่ไม่ใช่ Microarray เช่น RNA-seq, Proteomics เนื่องจากข้อมูลมักจะมีความสัมพันธ์ระหว่างค่าเฉลี่ยกับตัวแปรสูง (Heteroscedasticity)","code":"\nplotSA(cx_fit_contrasts_eB) \ncx_fit_contrasts_eB_trend <- eBayes(cx_fit_contrasts, trend = TRUE)\nresults_trend <- decideTests(cx_fit_contrasts_eB, fc=log2(1.5)) \nsummary(results_trend)##        groupCIN1-groupCancer groupCIN2-groupCancer groupCIN3-groupCancer groupNormal-groupCancer groupCIN2-groupCIN1\n## Down                    2221                  3818                  2402                    6317                   0\n## NotSig                 50408                 47570                 50026                   40811               54675\n## Up                      2046                  3287                  2247                    7547                   0\n##        groupCIN3-groupCIN1 groupNormal-groupCIN1 groupCIN3-groupCIN2 groupNormal-groupCIN2 groupNormal-groupCIN3\n## Down                    34                     0                   0                   311                  2214\n## NotSig               54548                 54675               54675                 54333                 50612\n## Up                      93                     0                   0                    31                  1849\nplotSA(cx_fit_contrasts_eB_trend)"},{"path":"edger.html","id":"edger","chapter":"15 edgeR","heading":"15 edgeR","text":"","code":""},{"path":"edger.html","id":"principle-2","chapter":"15 edgeR","heading":"15.1 Principle","text":"edgeR (Empirical Analysis Gene Expression R) เป็น bioconductor package ที่นิยมใช้ในการศึกษา DGE ในการทดลอง RNA-seq ซึ่งตั้งอยู่บนสมมติฐานที่แตกต่างจาก limma เนื่องจากข้อมูล RNA-seq นั้นมีคุณสมบัติที่แตกต่างจากข้อมูลประเภท Microarray ดังนี้log(intensity) ของ Microarray ซึ่งเป็นข้อมูล Continuous จึงสามารถใช้โมเดลแบบ Linear ได้ แต่ ข้อมูล RNA-seq นั้นเป็นข้อมูล read count ที่ได้จากการนับ Sequencing จึงเหมาะกับการใช้โมเดลแบบ Poisson มากกว่าlog(intensity) ของ Microarray ซึ่งเป็นข้อมูล Continuous จึงสามารถใช้โมเดลแบบ Linear ได้ แต่ ข้อมูล RNA-seq นั้นเป็นข้อมูล read count ที่ได้จากการนับ Sequencing จึงเหมาะกับการใช้โมเดลแบบ Poisson มากกว่าHeteroscedasticity สูง จึงไม่สามารถใช้สมการถดถอยแบบ Poisson โดยปกติได้Heteroscedasticity สูง จึงไม่สามารถใช้สมการถดถอยแบบ Poisson โดยปกติได้กราฟซ้าย คือความสัมพันธ์ของค่าเฉลี่ยและความแปรปรวนของการกระจายตัวแบบ Poisson โดยทั่วไป ส่วนกราฟขวา เป็นการกระจายตัวของข้อมูล RNA-seq จะเห็นว่าเมื่อค่าเฉลี่ยเพิ่มมากขึ้นนั้น ความแปรปรวนจะเพิ่มในอัตราส่วนที่มากกว่า ทั้งนี้ เนื่องจาก มีปัจจัยของความแปรปรวนที่ไม่ใช่ความแปรปรวนของ Technical variability จากกระบวนการ RNA sequencing (ซึ่งเป็น การกระจายตัวแบบ Poisson) เพียงอย่างเดียว แต่มีความแปรปรวนของ Biological properties ในตัวอย่างมาเกี่ยวข้องด้วย","code":""},{"path":"edger.html","id":"negative-binomial-model","chapter":"15 edgeR","heading":"15.1.1 Negative binomial model","text":"","code":""},{"path":"edger.html","id":"handling-biological-variation","chapter":"15 edgeR","heading":"15.1.1.1 Handling biological variation","text":"จากข้อมูลขั้นต้น สมมติฐานของ edgeR คือ RNA-seq มี Technical variation ซึ่งมีการกระจายตัวแบบ Poisson และ Biological variation ซึ่งทำให้เกิดความแปรปรวนที่นอกเหนือจาก Poisson (Extra poisson variability) ส่งผลให้เกิดข้อมูลแบบ Overdispersion ซึ่งเมื่อทำการสร้างสมถดถอยของความสัมพันธ์ระหว่างความแปรปรวนกับค่าเฉลี่ยจะได้ว่า\\[\nvar(y_{gi}) = E_{\\pi}[var(y|\\pi)] + var_{\\pi}[E(y|\\pi)] = \\mu_{gi} + \\phi_{g}\\mu^{2}_{gi}\n\\]\\[\nCV^{2} = 1/\\mu_{gi} + \\phi\n\\]โดยที่ \\(\\sqrt{1/\\mu_{gi}}\\) คือ Coefficient variation (\\(S/\\mu\\); CV) จากการกระจายตัวแบบ Poisson ส่วน \\(\\sqrt{\\phi}\\) คือ รากที่สองของ CV จากการกระบวนการอื่น ซึ่งในที่นี้คือ Biological properties ของตัว Sample ดังนั้นจะได้ว่า\\[\n\\text{Total CV}^{2} = \\text{Technical CV}^{2} + \\text{Biological CV}^{2}\n\\]สมมติฐานของ edgeR นั้นตั้งอยู่บนพื้นฐานที่ว่า Technical CV นั้นจะลดลงเมื่อจำนวน Sequencing depth นั้นเพิ่มมากขึ้น (\\(1/\\mu_{gi}\\)) แต่ Biological CV นั้นจะยังคงอยู่ไม่ว่า Sequencing depth จะเพิ่มมากขึ้นเท่าไร ดังนั้นสิ่งสำคัญที่เป็นตัวแปรก่อกวนการวัด DGE (ซึ่ง Systemic variability) คือ Biological CV (\\(\\sqrt{\\phi}\\)) นั่นเอง","code":""},{"path":"edger.html","id":"estimation-of-phi-and-dge","chapter":"15 edgeR","heading":"15.1.1.2 Estimation of \\(\\phi\\) and DGE","text":"edgeR ทำการสร้างสมการถดถอย Negative binomial จากการประเมินค่า \\(\\phi\\) โดยวิธีที่เรียกว่า Quantile-adjusted maximum likelihood ซึ่งใช้จำนวน Read ทั้งหมดในแต่ละยีนมาสร้างเป็นตาราง Pseudo-countหลังจากนั้น edgeR จะคำนวณ DGE โดยการใช้ Exact test ซึ่งเป็นการรวมโอกาสทั้งหมดที่จะสุ่มได้ Condition ที่ต้องการ ซึ่งวิธีคล้าย Fisher’s exact test ที่มีการคำนึงถึง effective library size และเป็นวิธี classic method ของ edgeR ที่มีข้อจำกัดคือสามารถเปรียบเทียบ DGE ได้ระหว่างสองสภาวะเท่านั้น และไม่สามารถจำลองความแปรปรวนอื่นๆ นอกเหนือจากความแปรปรวนของยีนได้","code":""},{"path":"edger.html","id":"extension-of-negative-binomial","chapter":"15 edgeR","heading":"15.1.2 Extension of negative binomial","text":"นอกจาก global BCV dispersion แล้ว edgeR ยังสามารถคำนวณ BCV ของแต่ละยีนได้โดยใช้ Quasi-likelihood ของสมการถดถอย Negative binomial\\[\nvar(y_{gi}) = \\sigma^{2}_{g}(\\mu_{gi} + \\phi\\mu_{gi}^{2})\n\\]ซึ่งหมายความว่า ทุกๆ ความแปรปรวนของ \\(var(y_{gi})\\) ที่เพิ่มขึ้นจะถูกทำนายด้วยค่า \\(\\phi\\) (Negative binomial parameter; Global BCV) และ \\(\\sigma^{2}\\) (Quasi-likelihood parameter; Gene-specific BCV) ซึ่งปัญหาของสมการนี้คือจำนวณ replicate ที่ไม่มากพอในแต่ละยีน edgeR แก้จึงปัญหานี้โดยประยุกต์เทคนิกของ limma มาใช้ ซึ่งก็คือ Empirical Bayes ซึ่งยืมความแปรปรวนมาจากทุกยีนนั่นเอง","code":"\nplotBCV(bladder_dge)"},{"path":"distribution.html","id":"distribution","chapter":"16 Distribution","heading":"16 Distribution","text":"","code":""},{"path":"distribution.html","id":"norm-dist","chapter":"16 Distribution","heading":"16.1 Normal distribution","text":"คือ ลักษณะการกระจายตัวของข้อมูลที่เป็นรูประฆังคว่ำ ซึ่งพบมากสุดในธรรมชาติ\\[\nf(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^{2}}\n\\]\\(Z\\) distribution = standard normal distribution ของประชากร ที่มี \\(\\mu = 0\\), \\(\\sigma = 1\\)สามารถสร้าง \\(Z\\) score ได้จาก\\[\nZ = \\frac{x-\\mu}{\\sigma}\n\\]ค่าของ \\(Z\\)-score ที่พบบ่อย","code":""},{"path":"distribution.html","id":"t-dist","chapter":"16 Distribution","heading":"16.2 \\(t\\) distribution","text":"คือ การกระจายตัวของความต่างของค่าเฉลี่ยระหว่างกลุ่มตัวอย่างที่สุ่มจากประชากร ใช้ใน t-test\\[\nf(t) = \\frac{\\Gamma(\\frac{v+1}{2})}{\\sqrt{v\\pi}\\Gamma(\\frac{v}{2})}(1+\\frac{t^{2}}{v})^{-\\frac{v+1}{2}}\n\\]plot(x, dt(x, df = 10, ncp = 0), = -4, = +4, type = “l”)(ncp 1:6){สามารถสร้าง \\(t\\)-score (\\(t\\) -value ) ได้จาก\\[\nt = \\frac{\\bar{x}-\\mu}{s/\\sqrt{n}}\n\\]หมายเหตุ \\(t\\)-score บางครั้งเป็นคำศัพท์เฉพาะทางEducation assessment \\(\\mu = 50\\), \\(\\sigma = 10\\)Education assessment \\(\\mu = 50\\), \\(\\sigma = 10\\)Bone density เทียบกับผู้ป่วยอายุ 30 ปี \\(\\mu = 0\\), \\(\\sigma = 1\\)Bone density เทียบกับผู้ป่วยอายุ 30 ปี \\(\\mu = 0\\), \\(\\sigma = 1\\)","code":"\nt_dist <- data.frame(x = x, \n                        `DF 1` = dt(x, df = 1),\n                        `DF 2` = dt(x, df = 2),\n                        `DF 4` = dt(x, df = 4),\n                        `DF 8` = dt(x, df = 8)) |> \n  pivot_longer(-x,names_to = \"Param\", values_to  = \"T.distribution\" ) \n\nggplot(t_dist, aes(x = x, y = T.distribution, col = Param)) + \n  geom_line(alpha = 0.8, linewidth = 0.5) +\n  xlim(-4,4) +\n  labs(title = \"t-distribution\", x = \"Values\", y = \"Rate\")"},{"path":"distribution.html","id":"uniform-distribution","chapter":"16 Distribution","heading":"16.3 Uniform distribution","text":"คือ การกระจายตัวของข้อมูลที่อัตราการเกิดเท่าๆ กัน เช่น ทอยลูกเต๋าไม่ถ่วงน้ำหนัก 1 ลูก ดึงไพ่จากสำรับ เป็นต้น\\[\nf(x) = \\begin{cases}\n\\frac{1}{b-} \\ \\text{} \\ \\leq x \\leq b \\\\\n0 \\ \\text{} \\ x<\\ \\text{} \\ x>b\n\\end{cases}\n\\]","code":"\nx <- seq(0,10,1)\n\nunif_dist <- data.frame(x = x, \n                     dice = dunif(x, min = 1 ,max = 6)) |> \n  pivot_longer(-x,names_to = \"Param\", values_to  = \"Uniform.distribution\" ) \n\nggplot(unif_dist, aes(x = x, y = Uniform.distribution)) + \n  geom_point() +\n  geom_segment(col = \"darkblue\", xend = x, yend = 0) +\n  scale_x_continuous(breaks = 0:10, limits = c(0,10)) +\n  labs(title = \"Dice rolls\", x = \"Face\", y = \"Rate\")"},{"path":"distribution.html","id":"binomial-distribution","chapter":"16 Distribution","heading":"16.4 Binomial distribution","text":"คือ การกระจายตัวของโอกาสสำเร็จในการทดลองที่มีผลลัพธ์สองรูปแบบ เช่น หัว/ก้อย ชนะ/แพ้\\[\nf(x,n,p) = P(X = x) = {n\\choose x}p^{x}(1-p)^{n-k}  \n\\]","code":"\n# 20 trials, prob of success = 10% to 90%\nbinom_dist <- map_dfc(c(0.1, 0.3, 0.5, 0.7, 0.9), ~dbinom(1:20, 20, .x)) |> \n  set_names(paste0(\"Prob = \", c(0.1, 0.3, 0.5, 0.7, 0.9) )) |> \n  mutate(numb_success = 1:20) |> \n  pivot_longer(!numb_success, names_to = \"Prob\", values_to = \"rate\") \n\nggplot(binom_dist, aes(x = numb_success, y = rate, col = Prob)) + \n  geom_point(size = 0.8) +\n  geom_line() +\n  scale_x_continuous(breaks = seq(0,21,1), limits = c(0,21)) +\n  labs(x = \"Number of success\", y = \"Rate\")"},{"path":"distribution.html","id":"negative-binomial-distribution","chapter":"16 Distribution","heading":"16.5 Negative binomial distribution","text":"คือ การกระจายของจำนวนครั้งที่ไม่สำเร็จก่อนที่จะได้จำนวนครั้งของการสำเร็จที่ต้องการ\\[\np(k) = {r-1+k \\choose r-1}p^{r-1}(1-p)^{k}p = {r-1+k \\choose k}p^{r}(1-p)^{k}\n\\]","code":"\nnbprob_dist <- map_dfc(c(0.1, 0.3, 0.5, 0.7, 0.9), \\(x) dnbinom(1:20, 20,x)) |> \n  set_names(paste0(\"Prob = \", c(0.1, 0.3,0.5,0.7,0.9) )) |> \n  mutate(numb_failure = 1:20) |> \n  pivot_longer(!numb_failure, names_to = \"Prob\", values_to = \"rate\") \n\nggplot(nbprob_dist, aes(x = numb_failure, y = rate, col = Prob)) + \n  geom_point(alpha = 0.9, size =2) +\n  geom_line() +\n  scale_x_continuous(breaks = seq(0,20,2)) +\n  theme_bw() +\n  labs(x = \"Number of failures\", y = \"Rate\")"},{"path":"distribution.html","id":"hypergeometric-distribution","chapter":"16 Distribution","heading":"16.6 Hypergeometric distribution","text":"คือ การกระจายตัวของโอกาสที่จะสุ่มได้เป้าหมายที่ต้องการจากการหยิบสุ่มแบบใส่คืน (Sampling replacement) ใช้ใน Fisher’s exact test\\[\nf(x,n,M,N) = p(X=x) = \\frac{{M \\choose x}{N-M \\choose n-x}}{N \\choose n}\n\\]","code":"\nhyper_dist <- map_dfc(c(10,20,30), ~dhyper(1:30, .x, 30, 30)) |>  \n  set_names(paste0(\"Black = \", c(10,20,30))) |> \n  mutate(numb_success = 1:30) |> \n  pivot_longer(!numb_success, names_to = \"Pop\", values_to = \"rate\") \n\nggplot(hyper_dist, aes(x = numb_success, y = rate, col = Pop)) + \n  geom_point(size = 0.8) +\n  geom_line() +\n  scale_x_continuous(breaks = seq(0,30,2), limits = c(0,30)) +\n  labs(title = \"Probablity of getting black balls from 30 picks\", \n       x = \"Number of black balls picked\", y = \"Rate\", col = \"Total black balls\\n in the bag\")"},{"path":"distribution.html","id":"poisson-dist","chapter":"16 Distribution","heading":"16.7 Poisson distribution","text":"คือ การกระจายตัวของโอกาสที่จะเกิดเหตุการณ์เท่ากับจำนวนครั้งที่ต้องการภายใต้ช่วงเวลาใดเวลาหนึ่ง\\[\nf(k) = P(X = k) = \\frac{\\lambda^{k}}{k!}e^{-\\lambda}\n\\]\\[\n\\lambda = \\frac{k}{t}\n\\]การกระจายตัวแบบ Poisson เป็นการกระจายตัวแบบพื้นฐานในการนับจำนวน gene ที่เกิดขึ้นจาก RNA sequencing profile","code":"\npois_dist <- map_dfc(c(1, 2, 4, 10), ~dpois(1:20, .x)) |>  \n  set_names(paste0(\"Mean = \", c(1, 2, 4, 10))) |> \n  mutate(numb_event = 1:20) |> \n  pivot_longer(!numb_event, names_to = \"Mean\", values_to = \"value\") |> \n  mutate(Mean = fct_relevel(Mean, paste0(\"Mean = \", c(1, 2, 4, 10))))\n\nggplot(pois_dist, aes(x = numb_event, y = value, col = Mean)) + \n  geom_point(size = 0.8) +\n  geom_line() + \n  scale_x_continuous(breaks = seq(0,20,2), limits = c(0,21)) +\n  labs(title = \"Probablity that certain number of events will occur\", \n       x = \"Number of events\", y = \"Rate\", col = \"Average number of events\")"},{"path":"session-info.html","id":"session-info","chapter":"17 Session info","heading":"17 Session info","text":"","code":"\nsessionInfo()## R version 4.3.1 (2023-06-16 ucrt)\n## Platform: x86_64-w64-mingw32/x64 (64-bit)\n## Running under: Windows 11 x64 (build 22621)\n## \n## Matrix products: default\n## \n## \n## locale:\n## [1] LC_COLLATE=English_United Kingdom.utf8  LC_CTYPE=English_United Kingdom.utf8   \n## [3] LC_MONETARY=English_United Kingdom.utf8 LC_NUMERIC=C                           \n## [5] LC_TIME=English_United Kingdom.utf8    \n## \n## time zone: Asia/Bangkok\n## tzcode source: internal\n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n##  [1] survminer_0.4.9     ggpubr_0.6.0        cowplot_1.1.1       broom_1.0.5         survival_3.5-7     \n##  [6] corrplot_0.92       granova_2.2         car_3.1-2           carData_3.0-5       pwrss_0.3.1        \n## [11] lubridate_1.9.2     forcats_1.0.0       stringr_1.5.0       dplyr_1.1.2         purrr_1.0.2        \n## [16] readr_2.1.4         tidyr_1.3.0         tibble_3.2.1        ggplot2_3.4.3       tidyverse_2.0.0    \n## [21] edgeR_3.42.4        affy_1.78.2         Biobase_2.60.0      BiocGenerics_0.46.0 limma_3.56.2       \n## \n## loaded via a namespace (and not attached):\n##  [1] mnormt_2.1.1          Rdpack_2.5            gridExtra_2.3         rlang_1.1.1           magrittr_2.0.3       \n##  [6] compiler_4.3.1        mgcv_1.8-42           png_0.1-8             vctrs_0.6.3           pkgconfig_2.0.3      \n## [11] crayon_1.5.2          fastmap_1.1.1         backports_1.4.1       labeling_0.4.3        KMsurv_0.1-5         \n## [16] utf8_1.2.3            rmarkdown_2.25        markdown_1.9          tzdb_0.4.0            preprocessCore_1.62.1\n## [21] bit_4.0.5             xfun_0.40             zlibbioc_1.46.0       cachem_1.0.8          jsonlite_1.8.7       \n## [26] psych_2.3.9           jpeg_0.1-10           parallel_4.3.1        R6_2.5.1              bslib_0.5.1          \n## [31] stringi_1.7.12        jquerylib_0.1.4       Rcpp_1.0.11           bookdown_0.35         knitr_1.44           \n## [36] zoo_1.8-12            Matrix_1.6-0          splines_4.3.1         timechange_0.2.0      tidyselect_1.2.0     \n## [41] rstudioapi_0.15.0     abind_1.4-5           yaml_2.3.7            ggtext_0.1.2          lattice_0.21-8       \n## [46] withr_2.5.0           evaluate_0.22         xml2_1.3.5            survMisc_0.5.6        pillar_1.9.0         \n## [51] affyio_1.70.0         BiocManager_1.30.22   generics_0.1.3        vroom_1.6.3           nleqslv_3.3.4        \n## [56] truncnorm_1.0-9       hms_1.1.3             commonmark_1.9.0      munsell_0.5.0         scales_1.2.1         \n## [61] xtable_1.8-4          glue_1.6.2            detectnorm_1.0.0      tools_4.3.1           data.table_1.14.8    \n## [66] locfit_1.5-9.8        ggsignif_0.6.4        fs_1.6.3              grid_4.3.1            rbibutils_2.2.15     \n## [71] colorspace_2.1-0      nlme_3.1-162          cli_3.6.1             km.ci_0.5-6           fansi_1.0.4          \n## [76] downlit_0.4.3         gtable_0.3.4          rstatix_0.7.2         sass_0.4.7            digest_0.6.33        \n## [81] farver_2.1.1          memoise_2.0.1         htmltools_0.5.5       lifecycle_1.0.3       gridtext_0.1.5       \n## [86] bit64_4.0.5           MASS_7.3-60"}]
