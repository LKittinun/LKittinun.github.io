[{"path":"index.html","id":"preface","chapter":"Preface","heading":"Preface","text":"เอกสารนี้จัดทำขึ้นเพื่อจุดประสงค์ขึ้นเพื่อแนะนำการใช้ R เบื้องต้น สำหรับนักวิทยาศาสตร์ที่มีความสนใจในการใช้ R ในการวิเคราะห์ข้อมูล ซึ่งผู้ใช้งานจำเป็นจะต้องมีความรู้เรื่อง basic R ต่างๆ เล็กน้อย เพื่อที่จะได้ใช้งานได้อย่างไม่ติดขัดOnline version: https://tmrc.psu.ac.th/RNAseq/_book/index.html","code":""},{"path":"index.html","id":"r-installation","chapter":"Preface","heading":"R installation","text":"","code":""},{"path":"index.html","id":"r-console","chapter":"Preface","heading":"R console","text":"ผู้ที่ต้องการใช้ R สามารถดาวน์โหลดโปรแกรม ได้ที่นี่ https://cran.r-project.org/bin/windows/base/ โดยตัว R console จะมีหน้าตาดังภาพ","code":""},{"path":"index.html","id":"rstudio","chapter":"Preface","heading":"Rstudio","text":"อย่างไรก็ตาม การใช้งาน R ด้วยโปรแกรมนี้จะใช้งานค่อนข้างยาก โดยส่วนใหญผู้ใช้การจะต้องดาวน์โหลด IDE (integrated development environment) มาอำนวยความสะดวกในการเขียนคำสั่ง ซึ่ง IDE ที่ได้รับความนิยมมากที่สุด คือ Rstudio สามารถดาวน์โหลดได้ที่ https://posit.co/download/rstudio-desktop/นี่คือหน้าต่าง default ของ Rstudio โดยส่วนประกอบหลักคือText editor มุมซ้ายบน คือ ที่ๆ เราจะเขียน script ไว้เพื่อ runEnvironment มุมขวาบน คือ ส่วนที่เก็บข้อมูล variable ต่างๆ ที่เรา assignR console มุมซ้ายล่าง คือ ส่วนที่ R ทำงานจริงๆ ซึ่งก็คือ ตัว R console ที่เราโหลดมาตอนแรกนั่นเองส่วน Output ที่จะมีไว้แสดงที่อยู่ของไฟล์ รูปภาพที่ render ออกมา และ อื่นๆ ตามที่เราจะปรับแต่งเราสามารถเขียนไว้ script ไว้ที่ text editor และกด run คำสั่งแต่ละบรรทัดได้โดยการกด Ctrl + Enterยินดีด้วย! เท่านี้ท่านก็สามารถเริ่มใช้งาน R ได้แล้ว","code":""},{"path":"basic-r.html","id":"basic-r","chapter":"1 Basic R","heading":"1 Basic R","text":"","code":""},{"path":"basic-r.html","id":"basic-operation","chapter":"1 Basic R","heading":"1.1 Basic operation","text":"ท่านสามารถใช้ R ในการคำนวณต่างๆ ได้ เช่น บวก ลบ คูณ หาร ยกกำลัง เป็นต้น","code":"\n3+2## [1] 5\n3-2## [1] 1\n3*2## [1] 6\n3/2## [1] 1.5\n3^2## [1] 9\nlog(3)## [1] 1.098612\nsqrt(3)## [1] 1.732051\n3==3 # ตรวจสอบว่าข้อมูลเหมือนกันหรือไม่## [1] TRUE"},{"path":"basic-r.html","id":"variable","chapter":"1 Basic R","heading":"1.2 Variable","text":"","code":""},{"path":"basic-r.html","id":"variable-assignment","chapter":"1 Basic R","heading":"1.2.1 Variable assignment","text":"R สามารถเก็บข้อมูลต่างๆ ไว้ในตัวแปรได้ เพื่อที่สามารถนำมาใช้ในภายหลัง โดยการเก็บตัวแปรนั้นจะใช้เครื่องหมาย <-","code":"\nx <- 2\nx## [1] 2\ny <- 3\ny## [1] 3\nx+y # ท่านสามารถนำตัวแปรมาทำ operation ได้ตามปกติ## [1] 5\nx*y## [1] 6\nx <- 5 # การลงข้อมูลในตัวแปรเดิมจะเป็นการลบตัวแปรเก่า\nx## [1] 5\nhelloworld <- (x+y)^(x-y) # สามารถตั้งชื่ออะไรก็ได้ตราบใดที่ไม่เว้นวรรค\nhelloworld## [1] 64"},{"path":"basic-r.html","id":"type-of-variable","chapter":"1 Basic R","heading":"1.2.2 Type of variable","text":"R นั้นสามารถรองรับตัวแปรต่างๆ ได้หลากหลาย ซึ่งเป็นได้ทั้ง ตัวเลข หรือตัวอักษร หรือแม้กระทั่งเก็บหลายข้อมูลภายในตัวแปรเดียวได้ลักษณะตัวแปรต่างๆ ใน R มีดังนี้ในบางครั้ง class ที่ R ทำการเดามาให้ตั้งแต่แรกอาจจะไม่ใช่ลักษณะตัวแปรที่ท่านต้องการ ท่านสามารถใช้ คำสั่ง .*() ในการเปลี่ยน class ของตัวแปรนั้นได้","code":"\nx <- \"Hello world\" # ตัวอักษร\nx## [1] \"Hello world\"\ny <- c(1,2,3,4) # เก็บหลายตัวข้อมูลในตัวแปรเดียว\ny## [1] 1 2 3 4\nz <- list(c(1,2,3), 4, c(\"hello world\", \"I love R\"))  # เก็บข้อมูลในรูปแบบ list\nz## [[1]]\n## [1] 1 2 3\n## \n## [[2]]\n## [1] 4\n## \n## [[3]]\n## [1] \"hello world\" \"I love R\"\nclass(x) # ท่านสามารถเช็คชนิดของตัวแปรได้โดยใช้ function class()## [1] \"character\"\nx <- c(1,2,3,4,5)\nclass(x) # ไม่ต้องการให้คิดเป็นตัวเลข เช่น ตัวแปรที่จริงแล้วอาจจะเป็น กลุ่ม1 กลุ่ม2## [1] \"numeric\"\nx <- as.factor(x)\nclass(x) # เปลี่ยนเป็น factor## [1] \"factor\"\nx_list <- list(\"A\"= c(1,2,3,4,5), \"B\" = c(\"a\",\"b\",\"c\",\"d\",\"e\"))\nx_list## $A\n## [1] 1 2 3 4 5\n## \n## $B\n## [1] \"a\" \"b\" \"c\" \"d\" \"e\"\nas.data.frame(x_list) # เปลี่ยนเป็น dataframe"},{"path":"basic-r.html","id":"matrix-and-dataframe","chapter":"1 Basic R","heading":"1.3 Matrix and Dataframe","text":"เนื่องจาก R นั้นเป็นโปรแกรมที่ส่วนมากใช้ในการวิเคราะห์ทางสถิติ ซึ่งเกี่ยวข้อมูลส่วนใหญ่จะถูกเก็บในรูปของตาราง R จึงมีตัวแปรที่เก็บข้อมูลในรูปของตารางโดยเฉพาะ เรียกว่า matrix และ dataframe ซึ่งท่านจะใช้เป็นหลักในการวิเคราะห์ข้อมูลใน Rโดยตารางนั้นจะประกอบด้วยสองส่วนหลักๆ คล้าย excel spreadsheet ได้แก่Column (คอลัมน์): คือ ข้อมูลในแนวตั้ง ซึ่งแถวบนสุดจะเป็นชื่อ column นั้นๆRow (แถว): คือ ข้อมูลในแนวนอนโดย matrix นั้น สามารถเก็บ variable ในรูปแบบเดียวกันได้เท่านั้น แต่ dataframe สามารถเก็บข้อมูลต่างชนิดร่วมกันได้ โดยมีข้อแม้ว่า column เดียวกัน จะต้องเป็นข้อมูลชุดเดียวกัน","code":"\nmat <- matrix(c(1,2,3,4), nrow=2)\nmat##      [,1] [,2]\n## [1,]    1    3\n## [2,]    2    4\nclass(mat)## [1] \"matrix\" \"array\"\ndf <- data.frame(x=c(3,4),y=c(2,5),z=c(4,7))\ndf\nclass(df)## [1] \"data.frame\""},{"path":"basic-r.html","id":"subset","chapter":"1 Basic R","heading":"1.4 Subset","text":"ท่านสามารถดึงข้อมูลแค่บางส่วนออกมาจาก vector, list, matrix หรือ dataframe ได้ เรียกว่าการ subsetในส่วนของ matrix และ dataframe นั้น ท่านสามารถ subset ตามตำแหน่งได้ โดยการระบุ row และ column ตามลำดับในส่วนของ dataframe นั้น ท่านสามารถ subset ได้โดยใช้ชื่อของ column อีกด้วย","code":"\nx <- c(\"a\",\"b\",\"c\",\"d\")\nx[3] # subset โดยระบุตำแหน่ง## [1] \"c\"\nx[1:3] # subset หลายตำแหน่ง## [1] \"a\" \"b\" \"c\"\nx[c(1,3)] # subset หลากหลายตำแหน่งแบบจำเพาะ## [1] \"a\" \"c\"\ny <- list(c(1,2,3), c(\"a\",\"b\",\"c\"))\ny[1] # subset list ตามตำแหน่ง (จะได้ list ย่อยออกมา)## [[1]]\n## [1] 1 2 3\ny[[1]] # ดึงข้อมูลที่อยู่ใน list ออกมา## [1] 1 2 3\nmat##      [,1] [,2]\n## [1,]    1    3\n## [2,]    2    4\nmat[1,2] # 1st row, 2nd column## [1] 3\ndf\ndf[1,3] # 1st row, 3rd column## [1] 4\ndf[\"x\"] # subset เป็น column ย่อย\ndf[[\"x\"]] # subset ข้อมูลที่อยู่ใน column นั้น## [1] 3 4\ndf[[2, \"x\"]] # ระบุแถวด้วย## [1] 4\ndf$x # เหมือนกัน df[[\"x\"]]## [1] 3 4"},{"path":"r-function.html","id":"r-function","chapter":"2 R function","heading":"2 R function","text":"function (ฟังก์ชัน) คือ ชุดของคำสั่งที่จะสั่งการให้ R ทำงานตามจุดประสงค์ที่ท่านตั้งไว้ โดยตัว function นั้น จะประกอบไปด้วยfunction ที่มีมาพร้อมกับ R ตั้งแต่ต้น (base R function)function ที่ผู้นิพนธ์ท่านอื่นเขียนไว้ และรวบรวมมาเป็น ชุดของ function เรียกว่า packagefunction ที่ท่านเขียนขึ้นมาเอง","code":""},{"path":"r-function.html","id":"anatomy-of-function","chapter":"2 R function","heading":"2.1 Anatomy of function","text":"function นั้นประกอบด้วย 4 ส่วน คือ 1. Function name (ชื่อฟังก์ชัน) 2. Argument (รายละเอียดของฟังก์ชัน) 3. Function body (รายละเอียดของฟังก์ชัน) 4. Return (ผลลัพธ์ของฟังก์ชัน)ยกตัวอย่างฟังก์ชันหา ค่าเฉลี่ยของข้อมูลจะเห็นว่า function นี่รับข้อมูล 2 ตัวแปร คือ x และ y ซึ่งท่านจะต้องแทนค่าที่ท่านต้องการลงไปใน function หลังจากนั้น function จะทำการประมวลผลและส่งผลลัพธ์กลับมาในผู้เริ่มต้น ส่วนใหญ่ท่านมักจะไม่ใช้ function ที่เขียนขึ้นมาเองมากนัก เนื่องจาก basic operation ส่วนใหญ่จะมีผู้นิพนธ์ขึ้นมาให้แล้ว","code":"\nfind_mean <- function(x, y){\n  (x + y)/2\n}\n\nfind_mean(2, 3)## [1] 2.5\nfind_mean(3, 5)## [1] 4"},{"path":"r-function.html","id":"base-r-function","chapter":"2 R function","heading":"2.2 Base R function","text":"Base R function คือ function ที่ติดกับ R มาตั้งแต่แรก ซึ่งท่านสามารถเรียกใช้ได้เลยโดยไม่ต้องทำการเรียก package ขึ้นมาก่อนในส่วนของการ manipulate dataframe นั้น คำสั่งต่างๆ ที่น่ารู้มีดังนี้สามารถดู base R function ทั้งหมดได้ที่ https://stat.ethz.ch/R-manual/R-devel/library/base/html/00Index.htmlถ้าท่านต้องการดูว่า function นั้นใช้งานอย่างไร ให้ใส่เครื่องหมาย ? หน้า function นั้น เช่น ?mean() ?colSums()","code":"\nmax(c(1,2,4,5,5,68)) # find max value## [1] 68\nmin(c(1,4,5,6,-20)) # find min value## [1] -20\nmean(c(1,2,3,4)) # find mean## [1] 2.5\nmedian(c(1,2,5,3,4)) # find median## [1] 3\nunique(c(1,1,1,1,2,2,4,5,5,6,7,8)) # display only unique values## [1] 1 2 4 5 6 7 8\ndf <- data.frame(x = c(3,3,6,7,8,9),y = c(2,5,8,1,2,3),z = c(4,7,9,4,7,8))\ndf\nhead(df, 5) # ดู 5 แถวแรก\ntail(df , 5) # ดู 5 แถวล่าง\nrowMeans(df) # หาค่า mean แต่ละแถว## [1] 3.000000 5.000000 7.666667 4.000000 5.666667 6.666667\ncolMeans(df) # หาค่า mean แต่ละ columns##   x   y   z \n## 6.0 3.5 6.5\nrownames(df) # ชื่อแถว## [1] \"1\" \"2\" \"3\" \"4\" \"5\" \"6\"\ncolnames(df) # ชื่อ column## [1] \"x\" \"y\" \"z\""},{"path":"what-is-tidyverse.html","id":"what-is-tidyverse","chapter":"3 What is tidyverse","heading":"3 What is tidyverse","text":"Tidyverse เป็น package ซึ่งนิพนธ์โดย Haley Wickham และคณะ โดย function ส่วนใหญ่ใน tidyverse นั้นเกี่ยวข้องกับการปรับแต่งข้อมูลจาก dataframe ซึ่งจะอำนวยความสะดวกให้ท่านสามารถทำงานได้มากขึ้นกว่าการใช้ base R ข้อเสียของ tidyverse นั้น อาจจะทำให้ run ช้ากว่า และมีปรับแต่งให้ตรงกับการใช้งานจำเพาะได้ยากกว่า แต่สำหรับผู้ที่ไม่ใช่ R hardcore นั้น tidyverse ถือว่าเป็น package ที่อำนวยความสะดวกได้อย่างดีเยี่ยมการจะใช้งาน package ใดๆ นั้น เริ่มจากท่านจะต้องติดตั้ง package นั้นลงบนเครื่องของท่านก่อน โดยคำสั่ง install.packages() โดยการโดย tidyverse นั้นจะเป็น package ใหญ่ และจะแบ่งเป็นหลาย package ย่อยๆ ได้อีก โดยท่านสามารถเรียกใช้ ทั้งหมดได้ หรือ เรียกใช้แค่ package ย่อย","code":"\ninstall.packages(\"tidyverse\") \nlibrary(tidyverse) "},{"path":"importing-data.html","id":"importing-data","chapter":"4 Importing data","heading":"4 Importing data","text":"","code":""},{"path":"importing-data.html","id":"importing-data-with-readr","chapter":"4 Importing data","heading":"4.1 Importing data with readr","text":"ก่อนที่ท่านจะทำการวิเคราะห์ข้อมูลได้นั้น ท่านจำเป็นที่จะต้องนำข้อมูลเข้ามาใน R ให้ได้ก่อน ซึ่ง tidyverse ได้มี package สำหรับการนำข้อมูลจากสกุลไฟล์ที่เป็นที่นิยมส่วนใหญ่เข้าสู่ R ได้เกือบทั้งหมด โดยใช้ function read_*()ไฟล์ที่ได้อ่านเข้ามานี้ คือ gene expression ของ DNA microarray ในชิ้นเนื้อผู้ป่วยมะเร็งปากมดลูก ซึ่งจะถูกนำไปใช้ต่อใน ตัวอย่างท้ายบท","code":"\nlibrary(readr) # ต้อง run ทุกครั้งที่จะใช้งาน\n\nGSE63514 <- read_csv(\"Resource/GSE63514_norm.csv\")\n\nhead(GSE63514, 10) \nGSE63514_meta <- read_csv(\"Resource/GSE63514_meta.csv\")\n\nhead(GSE63514_meta, 10)"},{"path":"importing-data.html","id":"other-packages","chapter":"4 Importing data","heading":"4.2 Other packages","text":"ท่านสามารถเขียนข้อมูลจาก R ลงไปในไฟล์ที่ท่านต้องการด้วย write_()* อีกด้วย อย่างไรก็ตาม แม้ว่า readr นั้นจะสามารถอ่านและเขียนไฟล์ได้ครอบคลุมเป็นอย่างมาก ในบางสกุลไฟล์นั้น อาจจะต้องใช้การอ่านจาก package อื่น","code":""},{"path":"data-wrangling.html","id":"data-wrangling","chapter":"5 Data wrangling","heading":"5 Data wrangling","text":"","code":""},{"path":"data-wrangling.html","id":"data-manipulation-with-dplyr","chapter":"5 Data wrangling","heading":"5.1 Data manipulation with dplyr","text":"dplyr คือ package ย่อยของ tidyverse ซึ่งทำหน้าที่จัดการ dataframe ที่ท่านนำเข้าไปใน R ให้เป็นในรูปแบบที่ท่านต้องการ","code":"\nlibrary(dplyr) "},{"path":"data-wrangling.html","id":"basic-dataframe-manipulation","chapter":"5 Data wrangling","heading":"5.1.1 Basic dataframe manipulation","text":"ในกรณีนี้จะใช้ข้อมูลตัวอย่าง iris เพื่อสาธิตการใช้ dplyr โดย iris เป็นข้อมูลของความยาวกลีบของพันธุ์ดอกไม้ต่างๆรูปจาก: https://www.datacamp.com/tutorial/machine-learning--rfunction หลักๆ ของ dplyr จะเกี่ยวข้องกับ data manipulation เป็นส่วนใหญ่ ในที่นี้จะแนะนำที่จำเป็นต้องใช้ในบทอื่นglimpse() มีไว้ดูภาพรวมข้อมูลselect() เลือก column ที่ต้องการโดยใช้ตำแหน่งหรือชื่อ column ก็ได้filter() กรองแถว (row) ที่ต้องการ โดยต้องระบุ ว่าต้องการข้อมูล ที่ column ไหน และต้องการกรองค่าที่เท่าไรสังเกตว่าจะเห็นเครื่องหมาย |> ซึ่งใน R ท่านจะเรียกว่า “pipe operator” เป็นสิ่งที่เป็นเอกลักษณ์ใน R ซึ่งส่งผลให้สามารถ run operation ได้ต่อๆ กัน เพื่อให้อ่านได้ง่ายบรรทัดสุดท้าย สำหรับ dataframe จะไม่สามารถดึงมาทั้ง column ได้ ซึ่งจะต้องใช้ข้อมูลอีกแบบ (tibble) แต่จะไม่กล่าวถึง ณ ที่นี่Note: การ subset โดย dplyr นั้นสามารถทำใน dataframe/tibble เท่านั้น ไม่สามารถทำใน matrix ได้ (ต้องใช้วิธีของ base R)ในส่วนการเรียงข้อมูลนั้นจะใช้ function arrange()mutate() เป็นคำสั่งที่ใช้ในการสร้างคอลัมน์ใหม่ให้เป็นในแบบที่ต้องการได้ท่านสามารถจัดกลุ่มตัวแปรได้โดยใช้ group_by() โดยมักจะใช้คู่กับ summarize() ซึ่งเป็นคำสั่งที่ใช้ในการสรุปข้อมูลทั้งหมดตามที่ต้องการrename() สามารถใช้ในการเปลี่ยนชื่อคอลัมน์ ระวังว่าชื่อที่ต้องการจะอยู่ด้านซ้ายของเครื่องหมาย = ซึ่งไม่เหมือนคำสั่งอื่น","code":"\ndf <- iris # โหลด dataframe ตัวอย่างที่ติดมากับ base R\nhead(df, 5)\nglimpse(df)## Rows: 150\n## Columns: 5\n## $ Sepal.Length <dbl> 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.8, 4.8, 4.3, 5.8, 5.7, 5.4, 5.1, 5.7, 5…\n## $ Sepal.Width  <dbl> 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3.0, 3.0, 4.0, 4.4, 3.9, 3.5, 3.8, 3…\n## $ Petal.Length <dbl> 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.6, 1.4, 1.1, 1.2, 1.5, 1.3, 1.4, 1.7, 1…\n## $ Petal.Width  <dbl> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.1, 0.1, 0.2, 0.4, 0.4, 0.3, 0.3, 0…\n## $ Species      <fct> setosa, setosa, setosa, setosa, setosa, setosa, setosa, setosa, setosa, setosa, setosa, setosa, …\ndf |> select(Species) |> head(5) # เลือก column \"Species\"\ndf |> select(2) |> head(5) # เลือก column ที่ 2\ndf |> select(1:2) |> head(5) # เลือก 2 column\ndf |> select(contains(\"Length\")) |> head(5) # เลือก column ที่มีคำว่า \"Length\"\n# เลือกแถวที่ Species == virginica\ndf |>  filter(Species == \"virginica\") |>  head(5)\n# เลือกแถวที่ Species = setosa, Sepal.Length = 5.4\ndf |>  \n  filter(Species == \"setosa\" & Sepal.Length == 5.4) |>  head(5)\n# เลือกแถวที่ Sepal.Length = 5.1 หรือ 4.9\ndf |>  filter(Sepal.Length == 5.1 | Sepal.Length == 4.9) |>  head(10)\n# เลือกแถวที่ Species = setosa คอลัมน์ Sepal.Length\ndf |> \n  filter(Species == \"setosa\") |> \n  select(Sepal.Length) |> head(5)\n# เหมือนกับข้างบน แต่ไม่ใช้ pipe operator จะทำความเข้าใจได้ยากกว่า\nselect(filter(df, Species == \"setosa\"), Sepal.Length) |>  head(5)\n# ใช้แค่ base R solution จะไม่สามารถดึงออกมาเป็น dataframe ได้\ndf[df[\"Species\"] == \"setosa\", \"Sepal.Length\"]##  [1] 5.1 4.9 4.7 4.6 5.0 5.4 4.6 5.0 4.4 4.9 5.4 4.8 4.8 4.3 5.8 5.7 5.4 5.1 5.7 5.1 5.4 5.1 4.6 5.1 4.8 5.0 5.0 5.2\n## [29] 5.2 4.7 4.8 5.4 5.2 5.5 4.9 5.0 5.5 4.9 4.4 5.1 5.0 4.5 4.4 5.0 5.1 4.8 5.1 4.6 5.3 5.0\ndf |> \n  arrange(Sepal.Length) |> head(5) # เรียง Sepal.Length จากน้อยไปมาก\ndf |> \n  arrange(desc(Sepal.Length)) |>  head(5) # เรียง Sepal.Length จากมากไปน้อย\ndf |> \n  mutate(Sepal_mm = Sepal.Length*100) # มิลลิเมตร\ndf |> \n  mutate(Sepal.Length = log10(Sepal.Length)) # สามารถแทนที่ column เดิมได้ด้วย\ndf |>  \n  group_by(Species) |>  # จัดกลุ่มตาม Species\n  summarize(Sepal.Length = sum(Sepal.Length), Sepal.Width = mean(Sepal.Width)) # รวมความยาวทั้งหมด และเฉลี่ยความกว้าง\ndf |> \n  rename(\"Sepal_length\" = \"Sepal.Length\", \"Sepal_width\" = \"Sepal.Width\") "},{"path":"data-wrangling.html","id":"joining-data","chapter":"5 Data wrangling","heading":"5.1.2 Joining data","text":"หลายครั้งที่การจัดการกับข้อมูลนั้นมีที่มาจากหลายส่วน โดยคอลัมน์หลักร่วมเพียงไม่กี่คอลัมน์ ผู้วิเคราะห์สามารถรวมตารางจากหลายแห่งเข้าด้วยกันได้โดยการใช้คำสั่ง x_join เพื่อความสะดวกในการวิเคราะห์","code":""},{"path":"data-wrangling.html","id":"mutating-join","chapter":"5 Data wrangling","heading":"5.1.2.1 Mutating join","text":"Mutating join คือการรวมตารางสองตารางเข้าด้วยกันภายใต้เงื่อนไขต่างๆ ในคอลัมน์หลักที่กำหนดต่อไปจะใช้ตารางดังต่อไปนี้ในการแสดงตัวอย่างInner join รวมบรรทัดที่มีตัวแปรที่มีร่วมกันทั้งสองตารางOuter join/Full join รวมทุกบรรทัดLeft join รวมบรรทัดจากตาราง y ที่มีตัวแปรในตาราง x และคงบรรทัดในตาราง x ทั้งหมดRight join รวมบรรทัดจากตาราง x ที่มีตัวแปรในตาราง y และคงบรรทัดในตาราง y ทั้งหมด","code":"\ninner_join(score_df, grade_df, by = \"Name\")\nfull_join(score_df, grade_df, by = \"Name\")\nleft_join(score_df, grade_df, by = \"Name\")\nright_join(score_df, grade_df, by = \"Name\")"},{"path":"data-wrangling.html","id":"filtering-join","chapter":"5 Data wrangling","heading":"5.1.2.2 Filtering join","text":"Filtering join คือการกรองบรรทัดในตาราง xโดยเงื่อนไขจากตาราง ysemi join กรองบรรทัดในตาราง x ที่มีตัวแปรในตาราง yanti join กรองบรรทัดในตาราง x ที่ไม่มีตัวแปรในตาราง y","code":"\nsemi_join(score_df, grade_df, by = \"Name\")\nanti_join(score_df, grade_df, by = \"Name\")"},{"path":"data-wrangling.html","id":"reshape","chapter":"5 Data wrangling","heading":"5.2 Reshaping data with tidyr","text":"","code":""},{"path":"data-wrangling.html","id":"data-structure","chapter":"5 Data wrangling","heading":"5.2.1 Data structure","text":"โดยปกติแล้วรูปแบบลักษณะของการบันทึกข้อมูลนั้นจะมีอยู่ 2 ลักษณะWide form เป็นลักษณะที่ง่ายต่อการบันทึก วิเคราะห์และอ่านผลเบื้องต้น โดยมีรูปแบบคือ ในแต่ละแถวนั้น จะมีข้อมูลหลักที่ไม่ซ้ำกัน (มักจะเป็นข้อมูลระบุตัวตน)Long form เป็นลักษณะที่ง่ายต่อการ visualize โดยมีรูปแบบคือ สามารถมีข้อมูลหลักที่ซ้ำกันได้ลองทำการดูที่ข้อมูล iris อีกครั้งจะเห็นว่า ข้อมูลในแต่ละแถวนั้น คือ ดอกไม้ 1 ดอก จำนวนคอลัมน์จะมากกว่าข้อมูลแบบ long form","code":"\nhead(df, 10)\ndf_id <- df |> \n  mutate(flower_id = row_number(), \n         .before = everything()) # สร้าง unique id ดอกไม้แต่ละดอก\n\nhead(df_id)"},{"path":"data-wrangling.html","id":"wide-to-long","chapter":"5 Data wrangling","heading":"5.2.2 Wide to long","text":"ท่านสามารถเปลี่ยนข้อมูลจาก wide form เป็น long form ได้โดย package tidyr โดยใช้ function pivot_longer()ซึ่งจะทำให้สามารถวิเคราะห์ข้อมูลได้สะดวกขึ้น ยกตัวอย่างถ้าเราต้องการสรุปข้อมูลชุดนี้ถ้าลองทำในข้อมูล wide formจะเห็นว่าค่อนข้าง intensive และผิดพลาดง่ายปล. อย่างไรก็ตาม dplyr ในสมัยนี้มีการพัฒนาไปมาก การวิเคราะห์ ใน wide form ก็สามารถทำได้โดยง่าย ขึ้นอยู่กับว่าถนัดแบบใดมากกว่าอีก ประเด็นสำคัญ ของข้อมูลประเภท long form นั้นคือ สามารทำ visualization ที่ซับซ้อนได้ดีกว่า wide form เป็นอย่างมาก ดังตัวอย่าง Boxplot1, Boxplot2","code":"\nlong_df <- df_id |> \n    pivot_longer(cols = !c(flower_id, Species), \n                 names_to = \"Metrics\", values_to = \"cm\") #ไม่รวมคอลัมน์ Species\n\nhead(long_df,10)\nsummary_df <- long_df |> \n  group_by(Species, Metrics) |>\n  summarize(`Median (cm)` = median(cm),`Mean (cm)` = mean(cm), `sd (cm)` = sd(cm))\n\nsummary_df\ndf |> \n  group_by(Species) |> \n  summarize(mean_Petal_L = mean(Petal.Length), \n            median_Petal_L = median(Petal.Length), \n            sd_Petal_L = sd(Petal.Length),\n            mean_Petal_W = mean(Petal.Width), \n            median_Petal_W = median(Petal.Width), \n            sd_Petal_W = sd(Petal.Width),\n            mean_Setal_L = mean(Sepal.Length), \n            median_Setal_L = median(Sepal.Length), \n            sd_Setal_L = sd(Sepal.Length),\n            mean_Setal_W = mean(Sepal.Width), \n            median_Setal_W = median(Sepal.Width), \n            sd_Setal_W = sd(Sepal.Width),\n            )\ndf |> \n  group_by(Species) |>    \n  summarize(across(everything(), list(median = median, mean = mean, sd = sd)))"},{"path":"data-wrangling.html","id":"long-to-wide","chapter":"5 Data wrangling","heading":"5.2.3 Long to wide","text":"ท่านสามารถเปลี่ยนกลับเป็น wide form ได้เช่นกันหรือท่านอยากจะเปลี่ยนข้อมูลที่สรุปแล้วให้เป็น wide form ก็เป็นได้","code":"\nwide_df <- long_df |> \n    pivot_wider(names_from = \"Metrics\", values_from = \"cm\")\n\nhead(wide_df, 10)\nsummary_df |> \n  pivot_wider(names_from = \"Metrics\", \n              values_from = c(\"Median (cm)\" ,\"Mean (cm)\", \"sd (cm)\"))"},{"path":"data-visualization.html","id":"data-visualization","chapter":"6 Data visualization","heading":"6 Data visualization","text":"","code":""},{"path":"data-visualization.html","id":"ggplot2","chapter":"6 Data visualization","heading":"6.1 General visualization with ggplot2","text":"ggplot2 คือ package ย่อยอีกตัวของ tidyverse ซึ่งใช้สำหรับการพล็อตกราฟ","code":""},{"path":"data-visualization.html","id":"simple-anatomy-of-ggplot","chapter":"6 Data visualization","heading":"6.1.1 (Simple) Anatomy of ggplot","text":"aes คือ aesthetic ซึ่งหมายถึงการ map ข้อมูลของท่านเข้ากับตำแหน่งของกราฟ\nx = แกน x, y = แกน y\ncol = สี, fill = สีพื้นหลัง\nx = แกน x, y = แกน ycol = สี, fill = สีพื้นหลังgeom_*() คือ การกำหนดว่าท่านต้องการที่จะ plot กราฟอะไรtheme_*() คือ การกำหนด theme ของกราฟ เพื่อความสวยงาม เช่น theme_bw(), theme_classic()การสร้างภาพที่สมบูรณ์นั้นมีส่วนจำเป็นที่ประกอบด้วย aes และ geom ตรงส่วนอื่นเป็นส่วนเสริมที่จะช่วยให้ภาพมีความสวยงามขึ้นสังเกตว่าจะยังไม่มีกราฟใดๆ ปรากฏ ท่านจำเป็นต้องใช้ function geom เพื่อทำการสร้างภาพนั้นขึ้น","code":"ggplot(data = your_data, aes(x = x, y = y, col = col, fill = fill)) +\n  geom_*() +\n  theme_*() +\n  ...\nlibrary(ggplot2) \ndf\nggplot(df, aes(x = Sepal.Width, y = Sepal.Length))"},{"path":"data-visualization.html","id":"scatter-plot","chapter":"6 Data visualization","heading":"6.1.2 Scatter plot","text":"สังเกตการ mapping ของ aes()","code":"\nggplot(df, aes(x = Sepal.Width, y = Sepal.Length, col = Species)) + geom_point()"},{"path":"data-visualization.html","id":"straight-line","chapter":"6 Data visualization","heading":"6.1.3 Straight line","text":"ท่านสามารถเพิ่มเส้นที่ท่านต้องการได้โดย geom_hline (แนวตั้ง), geom_vline (แนวนอน), geom_abline (แนวเฉียง)สังเกตว่าท่านสามารถปรับค่าจำพวก สี ลักษณะเส้นต่างๆ ได้ โดย parameter นั้น ต้องอยู่นอก aes มิเช่นนั้น function จะพยายามไปดึงข้อมูลจากกราฟมาที่ถูกต้อง ท่านต้องนำ col ไปอยู่นอก aes จึงจะได้สีที่ท่านต้องการ","code":"\nggplot(df, aes(x = Sepal.Width, y = Sepal.Length, col = Species)) + \n  geom_point() + \n  geom_hline(yintercept = 6, linetype = \"dashed\", col = \"red\", linewidth = 1) + \n  geom_vline(xintercept = 2.7, linetype = \"dotted\", col = \"blue\", linewidth = 1.25) + \n  geom_abline(intercept = 2, slope = 1, linetype = \"dotdash\", col = \"black\", linewidth = 1.5)\nggplot(df, aes(x = Sepal.Width, y = Sepal.Length, col = \"darkviolet\")) + # ผิด\n  geom_point() + \n  geom_hline(yintercept = 6, linetype = \"dashed\", col = \"red\", linewidth = 1) + \n  geom_vline(xintercept = 2.7, linetype = \"dotted\", col = \"blue\", linewidth = 1.25) + \n  geom_abline(intercept = 2, slope = 1, linetype = \"dotdash\", col = \"black\", linewidth = 1.5)\nggplot(df, aes(x = Sepal.Width, y = Sepal.Length)) + # ผิด\n  geom_point(col = \"darkviolet\") + \n  geom_hline(yintercept = 6, linetype = \"dashed\", col = \"red\", linewidth = 1) + \n  geom_vline(xintercept = 2.7, linetype = \"dotted\", col = \"blue\", linewidth = 1.25) + \n  geom_abline(intercept = 2, slope = 1, linetype = \"dotdash\", col = \"black\", linewidth = 1.5)"},{"path":"data-visualization.html","id":"bar-chart","chapter":"6 Data visualization","heading":"6.1.4 Bar chart","text":"geom_bar() ใช้สำหรับนับจำนวนของ column นั้น ไม่มีค่า yส่วน geom_col() จะรับค่า y ด้วย โดยข้อมูล x ที่ซ้ำกันจะถูกนำมารวมกันสังเกตว่าค่าที่ได้เกิดจากการรวมกันของข้อมูลทั้งคอลัมน์ (สังเกตที่เส้นสีดำเป็นเส้นต่อๆ กัน ไม่ใช่เส้นเดียว) ซึ่งมักไม่เป็นที่ต้องการในการแสดง โดยมักเกิดจากความผิดพลาดมากกว่า (โดยเฉพาะถ้าไม่ได้ใส่ col = black) และส่วนใหญ่มักจะใช้ในการแสดงค่าเฉลี่ยมากกว่าผลรวม ในการนี้ ควรใช้คำสั่ง dplyr::summarize() ในการสรุปข้อมูลก่อนจะเห็นว่ากราฟแสดงค่าเฉลี่ยซึ่งตรงตามความต้องการทั่วไปมากกว่า (สังเกตแกน y)","code":"\nggplot(df, aes(x = Species, fill = Species)) + # fill ไว้สำหรับแบ่งสีใน barchart\n  geom_bar(col = \"black\", width = 0.5) # ความกว้าง 50% \nggplot(df, aes(x = Species, y = Sepal.Width, fill = Species)) + \n  geom_col(col = \"black\", width = 0.5) \ndf |> \n  group_by(Species) |> \n  summarize(across(everything(), mean)) |> \n  ggplot(aes(x = Species, y = Sepal.Width, fill = Species)) + \n  geom_col(col = \"black\", width = 0.5) "},{"path":"data-visualization.html","id":"multi_boxplot","chapter":"6 Data visualization","heading":"6.1.5 Box plot","text":"ทำการสร้าง box plotถ้าท่านต้องการสร้าง plot ที่แสดงหลาย metrics ท่านจะต้องเปลี่ยนข้อมูลเป็น long form เสียก่อน","code":"\nggplot(df, aes(x = Species, y = Sepal.Width, fill = Species)) +\n  geom_boxplot(width = 0.5) \nhead(long_df, 10)\nlong_df |> \n    ggplot(aes(x = Species, y = cm, fill = Metrics)) +\n    geom_boxplot() "},{"path":"data-visualization.html","id":"histogram","chapter":"6 Data visualization","heading":"6.1.6 Histogram","text":"ในการทำงานสถิตินั้น โดยส่วนใหญ่จะต้องทำการตรวจสอบการกระจายของข้อมูลก่อนวิเคราะห์ทางสถิติ ซึ่งสามารถทำได้โดยใช้ geom_histogram()หรือ geom_density()ทั้งนี้ ท่านสามารถพล็อตหลายกราฟเข้าด้วยกันได้ ด้วยการ + ตามหลังไปเรื่อยๆ เพียงแต่ต้องระวังเรื่อง scale ที่ต้องเป็นระดับเดียวกัน","code":"\nggplot(df, aes(x = Sepal.Width)) + \n  geom_histogram(fill = \"skyblue\", binwidth = 0.1)  # binwidth = ความกว้างของแต่ละช่วงข้อมุล\nggplot(df, aes(x = Sepal.Width)) + \n  geom_density(fill = \"violet\", alpha = 0.5)\nggplot(df, aes(x = Sepal.Width)) +\n  geom_histogram(aes(y = after_stat(density)), binwidth = 0.1, fill = \"skyblue\") + # ปรับเป็นความถี่\n  geom_density(fill = \"violet\", alpha = 0.5) +\n  theme_bw() # ลบภาพพื้นหลังสีเทาออก"},{"path":"data-visualization.html","id":"fitting-a-statistical-model","chapter":"6 Data visualization","heading":"6.1.7 Fitting a statistical model","text":"ท่านสามารถที่พล็อต statistical model ได้โดยใช้ geom_smooth() ยกตัวอย่าง เช่น ถ้าอยากดูความสัมพันธ์ของ Sepal.Length และ Petal.Length","code":"\nggplot(df, aes(x = Sepal.Length, y = Petal.Length, color = Species)) + # สีตาม Species\n  geom_point(color = \"black\") +\n  geom_smooth(method = \"loess\") + # fit a LOESS model\n  theme_bw()\nggplot(df, aes(x = Sepal.Length, y = Petal.Length, color = Species)) + # สีตาม Species\n  geom_point(color = \"black\") +\n  geom_smooth(method = \"lm\") + # fit a linear model\n  theme_bw()"},{"path":"data-visualization.html","id":"faceting","chapter":"6 Data visualization","heading":"6.1.8 Faceting","text":"ในบางครั้งท่านอาจจะต้องการที่จะพล็อตกราฟแยกกันเป็นส่วนๆ มากกว่ารวมกันในกราฟเดียว ท่านสามารถแบ่ง partition ของการพล็อตแต่ละกลุ่มได้โดยใช้ facetทั้งหมดที่แสดงนี้ เป็นเพียงกราฟพื้นฐานเท่านั้น ยังมีการปรับแต่งอื่นๆ ได้อีกมาก สามารถศึกษาเพิ่มเติมได้ที่:Function reference: https://ggplot2.tidyverse.org/reference/Function reference: https://ggplot2.tidyverse.org/reference/Plot gallery: https://r-graph-gallery.com/Plot gallery: https://r-graph-gallery.com/","code":"\nggplot(df, aes(x = Sepal.Length, y = Petal.Length, color = Species)) + # สีตาม Species\n  geom_point(color = \"black\") +\n  geom_smooth(method = \"lm\") +\n  facet_wrap(~Species) + # แบ่งเป็นหลายกลุ่ม\n  theme_bw()\nggplot(df, aes(x = Sepal.Length,  fill = Species)) + # สีตาม Species\n  geom_histogram(binwidth = 0.1) +\n  facet_wrap(~Species, scales = \"free_x\", nrow = 2) + # ทำให้แกน x ไม่ fix ค่า\n  theme_bw()"},{"path":"GSE63514.html","id":"GSE63514","chapter":"7 Case study: Microarray visualization","heading":"7 Case study: Microarray visualization","text":"ต่อไปนี้จะเป็นตัวอย่างในการใช้ R ในการวิเคราะห์ข้อมูล molecular data เบื้องต้น โดยใช้ข้อมูลจาก GEO dataset GSE63514 ซึ่งเป็น gene expression microarray","code":""},{"path":"GSE63514.html","id":"import-files","chapter":"7 Case study: Microarray visualization","heading":"7.1 Import files","text":"ไฟล์แรกที่อ่านเข้ามาคือ GSE63514_norm.csv ซึ่งเป็นไฟล์ microarray expression ของชิ้นเนื้อปากมดลูก ประกอบด้วย ตัวอย่าง Normal , CIN1 , CIN2 , CIN3 , Cancer ในที่นี้เราจะทำการวิเคราะห์ 10,000 gene แรกส่วนที่สองคือ metadata (ข้อมูลระบุตัวตน) ของข้อมูลนี้ส่วนที่สามคือไฟล์ annotation ของ probe","code":"\nlibrary(tidyverse) \n\nGSE63514 <- read_csv(\"Resource/GSE63514_norm.csv\") |> \n  head(10000)\nnames(GSE63514)##   [1] \"probe\"                                  \"GSM1551311_Normal-01_U133_Plus2.CEL.gz\"\n##   [3] \"GSM1551312_Normal-02_U133_Plus2.CEL.gz\" \"GSM1551313_Normal-03_U133_Plus2.CEL.gz\"\n##   [5] \"GSM1551314_Normal-04_U133_Plus2.CEL.gz\" \"GSM1551315_Normal-05_U133_Plus2.CEL.gz\"\n##   [7] \"GSM1551316_Normal-06_U133_Plus2.CEL.gz\" \"GSM1551317_Normal-07_U133_Plus2.CEL.gz\"\n##   [9] \"GSM1551318_Normal-08_U133_Plus2.CEL.gz\" \"GSM1551319_Normal-09_U133_Plus2.CEL.gz\"\n##  [11] \"GSM1551320_Normal-10_U133_Plus2.CEL.gz\" \"GSM1551321_Normal-11_U133_Plus2.CEL.gz\"\n##  [13] \"GSM1551322_Normal-12_U133_Plus2.CEL.gz\" \"GSM1551323_Normal-13_U133_Plus2.CEL.gz\"\n##  [15] \"GSM1551324_Normal-14_U133_Plus2.CEL.gz\" \"GSM1551325_Normal-15_U133_Plus2.CEL.gz\"\n##  [17] \"GSM1551326_Normal-16_U133_Plus2.CEL.gz\" \"GSM1551327_Normal-17_U133_Plus2.CEL.gz\"\n##  [19] \"GSM1551328_Normal-18_U133_Plus2.CEL.gz\" \"GSM1551329_Normal-19_U133_Plus2.CEL.gz\"\n##  [21] \"GSM1551330_Normal-20_U133_Plus2.CEL.gz\" \"GSM1551331_Normal-21_U133_Plus2.CEL.gz\"\n##  [23] \"GSM1551332_Normal-22_U133_Plus2.CEL.gz\" \"GSM1551333_Normal-23_U133_Plus2.CEL.gz\"\n##  [25] \"GSM1551334_Normal-24_U133_Plus2.CEL.gz\" \"GSM1551335_CIN1-01_U133_Plus2.CEL.gz\"  \n##  [27] \"GSM1551336_CIN1-02_U133_Plus2.CEL.gz\"   \"GSM1551337_CIN1-03_U133_Plus2.CEL.gz\"  \n##  [29] \"GSM1551338_CIN1-04_U133_Plus2.CEL.gz\"   \"GSM1551339_CIN1-05_U133_Plus2.CEL.gz\"  \n##  [31] \"GSM1551340_CIN1-06_U133_Plus2.CEL.gz\"   \"GSM1551341_CIN1-07_U133_Plus2.CEL.gz\"  \n##  [33] \"GSM1551342_CIN1-08_U133_Plus2.CEL.gz\"   \"GSM1551343_CIN1-09_U133_Plus2.CEL.gz\"  \n##  [35] \"GSM1551344_CIN1-10_U133_Plus2.CEL.gz\"   \"GSM1551345_CIN1-11_U133_Plus2.CEL.gz\"  \n##  [37] \"GSM1551346_CIN1-12_U133_Plus2.CEL.gz\"   \"GSM1551347_CIN1-13_U133_Plus2.CEL.gz\"  \n##  [39] \"GSM1551348_CIN1-14_U133_Plus2.CEL.gz\"   \"GSM1551349_CIN2-01_U133_Plus2.CEL.gz\"  \n##  [41] \"GSM1551350_CIN2-02_U133_Plus2.CEL.gz\"   \"GSM1551351_CIN2-03_U133_Plus2.CEL.gz\"  \n##  [43] \"GSM1551352_CIN2-04_U133_Plus2.CEL.gz\"   \"GSM1551353_CIN2-05_U133_Plus2.CEL.gz\"  \n##  [45] \"GSM1551354_CIN2-06_U133_Plus2.CEL.gz\"   \"GSM1551355_CIN2-07_U133_Plus2.CEL.gz\"  \n##  [47] \"GSM1551356_CIN2-08_U133_Plus2.CEL.gz\"   \"GSM1551357_CIN2-09_U133_Plus2.CEL.gz\"  \n##  [49] \"GSM1551358_CIN2-10_U133_Plus2.CEL.gz\"   \"GSM1551359_CIN2-11_U133_Plus2.CEL.gz\"  \n##  [51] \"GSM1551360_CIN2-12_U133_Plus2.CEL.gz\"   \"GSM1551361_CIN2-13_U133_Plus2.CEL.gz\"  \n##  [53] \"GSM1551362_CIN2-14_U133_Plus2.CEL.gz\"   \"GSM1551363_CIN2-15_U133_Plus2.CEL.gz\"  \n##  [55] \"GSM1551364_CIN2-16_U133_Plus2.CEL.gz\"   \"GSM1551365_CIN2-17_U133_Plus2.CEL.gz\"  \n##  [57] \"GSM1551366_CIN2-18_U133_Plus2.CEL.gz\"   \"GSM1551367_CIN2-19_U133_Plus2.CEL.gz\"  \n##  [59] \"GSM1551368_CIN2-20_U133_Plus2.CEL.gz\"   \"GSM1551369_CIN2-21_U133_Plus2.CEL.gz\"  \n##  [61] \"GSM1551370_CIN2-22_U133_Plus2.CEL.gz\"   \"GSM1551371_CIN3-01_U133_Plus2.CEL.gz\"  \n##  [63] \"GSM1551372_CIN3-02_U133_Plus2.CEL.gz\"   \"GSM1551373_CIN3-03_U133_Plus2.CEL.gz\"  \n##  [65] \"GSM1551374_CIN3-04_U133_Plus2.CEL.gz\"   \"GSM1551375_CIN3-05_U133_Plus2.CEL.gz\"  \n##  [67] \"GSM1551376_CIN3-06_U133_Plus2.CEL.gz\"   \"GSM1551377_CIN3-07_U133_Plus2.CEL.gz\"  \n##  [69] \"GSM1551378_CIN3-08_U133_Plus2.CEL.gz\"   \"GSM1551379_CIN3-09_U133_Plus2.CEL.gz\"  \n##  [71] \"GSM1551380_CIN3-10_U133_Plus2.CEL.gz\"   \"GSM1551381_CIN3-11_U133_Plus2.CEL.gz\"  \n##  [73] \"GSM1551382_CIN3-12_U133_Plus2.CEL.gz\"   \"GSM1551383_CIN3-13_U133_Plus2.CEL.gz\"  \n##  [75] \"GSM1551384_CIN3-14_U133_Plus2.CEL.gz\"   \"GSM1551385_CIN3-15_U133_Plus2.CEL.gz\"  \n##  [77] \"GSM1551386_CIN3-16_U133_Plus2.CEL.gz\"   \"GSM1551387_CIN3-17_U133_Plus2.CEL.gz\"  \n##  [79] \"GSM1551388_CIN3-18_U133_Plus2.CEL.gz\"   \"GSM1551389_CIN3-19_U133_Plus2.CEL.gz\"  \n##  [81] \"GSM1551390_CIN3-20_U133_Plus2.CEL.gz\"   \"GSM1551391_CIN3-21_U133_Plus2.CEL.gz\"  \n##  [83] \"GSM1551392_CIN3-22_U133_Plus2.CEL.gz\"   \"GSM1551393_CIN3-23_U133_Plus2.CEL.gz\"  \n##  [85] \"GSM1551394_CIN3-24_U133_Plus2.CEL.gz\"   \"GSM1551395_CIN3-25_U133_Plus2.CEL.gz\"  \n##  [87] \"GSM1551396_CIN3-26_U133_Plus2.CEL.gz\"   \"GSM1551397_CIN3-27_U133_Plus2.CEL.gz\"  \n##  [89] \"GSM1551398_CIN3-28_U133_Plus2.CEL.gz\"   \"GSM1551399_CIN3-29_U133_Plus2.CEL.gz\"  \n##  [91] \"GSM1551400_CIN3-30_U133_Plus2.CEL.gz\"   \"GSM1551401_CIN3-31_U133_Plus2.CEL.gz\"  \n##  [93] \"GSM1551402_CIN3-32_U133_Plus2.CEL.gz\"   \"GSM1551403_CIN3-33_U133_Plus2.CEL.gz\"  \n##  [95] \"GSM1551404_CIN3-34_U133_Plus2.CEL.gz\"   \"GSM1551405_CIN3-35_U133_Plus2.CEL.gz\"  \n##  [97] \"GSM1551406_CIN3-36_U133_Plus2.CEL.gz\"   \"GSM1551407_CIN3-37_U133_Plus2.CEL.gz\"  \n##  [99] \"GSM1551408_CIN3-38_U133_Plus2.CEL.gz\"   \"GSM1551409_CIN3-39_U133_Plus2.CEL.gz\"  \n## [101] \"GSM1551410_CIN3-40_U133_Plus2.CEL.gz\"   \"GSM1551411_Cancer-01_U133_Plus2.CEL.gz\"\n## [103] \"GSM1551412_Cancer-02_U133_Plus2.CEL.gz\" \"GSM1551413_Cancer-03_U133_Plus2.CEL.gz\"\n## [105] \"GSM1551414_Cancer-04_U133_Plus2.CEL.gz\" \"GSM1551415_Cancer-05_U133_Plus2.CEL.gz\"\n## [107] \"GSM1551416_Cancer-06_U133_Plus2.CEL.gz\" \"GSM1551417_Cancer-07_U133_Plus2.CEL.gz\"\n## [109] \"GSM1551418_Cancer-08_U133_Plus2.CEL.gz\" \"GSM1551419_Cancer-09_U133_Plus2.CEL.gz\"\n## [111] \"GSM1551420_Cancer-10_U133_Plus2.CEL.gz\" \"GSM1551421_Cancer-11_U133_Plus2.CEL.gz\"\n## [113] \"GSM1551422_Cancer-12_U133_Plus2.CEL.gz\" \"GSM1551423_Cancer-13_U133_Plus2.CEL.gz\"\n## [115] \"GSM1551424_Cancer-14_U133_Plus2.CEL.gz\" \"GSM1551425_Cancer-15_U133_Plus2.CEL.gz\"\n## [117] \"GSM1551426_Cancer-16_U133_Plus2.CEL.gz\" \"GSM1551427_Cancer-17_U133_Plus2.CEL.gz\"\n## [119] \"GSM1551428_Cancer-18_U133_Plus2.CEL.gz\" \"GSM1551429_Cancer-19_U133_Plus2.CEL.gz\"\n## [121] \"GSM1551430_Cancer-20_U133_Plus2.CEL.gz\" \"GSM1551431_Cancer-21_U133_Plus2.CEL.gz\"\n## [123] \"GSM1551432_Cancer-22_U133_Plus2.CEL.gz\" \"GSM1551433_Cancer-23_U133_Plus2.CEL.gz\"\n## [125] \"GSM1551434_Cancer-24_U133_Plus2.CEL.gz\" \"GSM1551435_Cancer-25_U133_Plus2.CEL.gz\"\n## [127] \"GSM1551436_Cancer-26_U133_Plus2.CEL.gz\" \"GSM1551437_Cancer-27_U133_Plus2.CEL.gz\"\n## [129] \"GSM1551438_Cancer-28_U133_Plus2.CEL.gz\"\nhead(GSE63514_meta, 10)\nhgu133plus2_genenames <- read_csv(\"Resource/hgu133plus2_genenames.csv\") |> \n  select(-1) # remove row number\nhead(hgu133plus2_genenames, 10)"},{"path":"GSE63514.html","id":"cleaning-data","chapter":"7 Case study: Microarray visualization","heading":"7.2 Cleaning data","text":"สมมติว่าในตัวอย่างนี้ จะทำการวิเคราะห์แค่ระหว่าง Normal, CIN1, และ Cancer เท่านั้น จึงจำเป็นที่จะต้องกรองข้อมูลที่ไม่ต้องการออกไปเสียก่อนเมื่อดูในตัวแปร exps_nc จะพบว่า probe นั้นเป็นชื่อเฉพาะของตัวเครื่อง ไม่ใช้ชื่อสากล ในที่นี้จะทำการเปลี่ยน probe ให้เป็นชื่อ gene นั้นๆ แต่ว่าชื่อ list รายชื่อนั้นเป็นชื่อทั้งหมดของ probe สังเกตได้จากจำนวนแถวที่ไม่เท่ากันในที่นี้ การใช้คำสั่ง *_join() จะทำให้สามารถรวมแค่แถวที่ต้องการได้","code":"\nexprs_nc <- GSE63514 |> select(probe, contains(c(\"Normal\", \"CIN1\", \"Cancer\")))\nmeta_nc <- GSE63514_meta |> \n  filter(grepl(\"Normal|CIN1|Cancer\", title)) |> \n  select(title, `characteristics_ch1.1`, `dissection:ch1`)\nnames(exprs_nc) <- c(\"prob\", meta_nc$title) # เปลี่ยนชื่อให้อ่านง่าย\n\nhead(exprs_nc, 10)\nhead(meta_nc, 10)\nnrow(exprs_nc)## [1] 10000\nnrow(hgu133plus2_genenames)## [1] 54675\ngene_nc <- exprs_nc |> \n            left_join(hgu133plus2_genenames, by = c(\"prob\"=\"PROBEID\")) |> \n            relocate(c(\"SYMBOL\", \"ENTREZID\", \"GENENAME\"), .after = \"prob\")\n\ngene_nc\nnrow(gene_nc)## [1] 10000"},{"path":"GSE63514.html","id":"top10_boxplot","chapter":"7 Case study: Microarray visualization","heading":"7.3 Visualization","text":"ต่อไป เราจะทำการแสดงผล gene expression 10 ตัวที่มีการแสดงออกมากที่สุดในทั้ง experiment นี้ขั้นแรก เราจะทำการรวม intensity ทั้งหมดใน 1 gene ผ่าน function rowSums() และเรียง total_intensity จากมากไปน้อย หลังจากนั้นเลือก top10 intensity ออกมาโดยใช้ function head()จะเห็นว่าข้อมูลของเรา อยู่ในลักษณะ wide form ในการสร้าง boxplot นั้น ข้อมูลจำเป็นต้องอยู่ในลักษณะ long form เราจะใช้ function pivot_longer()ท่านอาจจะอยากเพิ่มเส้นค่าเฉลี่ยเพื่อดูว่า global mean intensity เป็นเท่าไรตัวกลุ่ม RPL ดูน่าสนใน เนื่องจาก intensity ใน cancer ต่ำกว่า global mean แต่จะมีนัยสำคัญหรือไม่ต้องใช้การวิเคราะห์ทางสถิติเพิ่มเติมทีหลังต่อไป เราอยากที่จะแบ่งว่า tissue ที่เป็น whole section กับ laser captured มีการแสดงออกที่แตกต่างกันอย่างไร เราจะใช้ facet_wrap() เข้ามาช่วยพล็อตอัตราส่วนจำนวนของ laser capture vs whole sectionเห็นว่าผลที่ได้ประหลาด เนื่องจาก laser capturedและ laser-captured เป็นตัวแปรซ้ำ ต้องแก้ไขเสียก่อนเมื่อข้อมูลที่ได้ถูกต้อง จะเห็นว่า มีเฉพาะกลุ่ม cancer เท่านั้น ที่มีการตัดแบบ whole sectionหลังจากนั้นเราจะทำการพล็อต intensity ในแต่ละ gene","code":"\ntop10_intensity <- gene_nc |> \n  select(-prob, -ENTREZID, -GENENAME) |> \n  mutate(total_intensity = \n           rowSums(select(gene_nc, -prob, -ENTREZID, -GENENAME, -SYMBOL)),\n         .before = \"Normal-01\") |> \n  arrange(desc(total_intensity)) |> \n  head(10)\n\ntop10_intensity\ntop10_long <- top10_intensity |> \n              select(-total_intensity) |> \n              pivot_longer(-SYMBOL, names_to = \"Case\", values_to = \"Intensity\") |> \n              separate(Case, into = c(\"Group\", \"Number\"), sep = \"-\", remove = FALSE)\nggplot(top10_long, aes(x = SYMBOL, y = Intensity, fill = Group)) + \n  geom_boxplot() +\n  theme_bw() +\n  theme(axis.text.x = \n          element_text(angle = 45, vjust = 1, hjust=1)) # หมุนแกน x เพื่อความสวยงาม\nglobal_mean_intensity <- mean(top10_long$Intensity)\nglobal_mean_intensity## [1] 14.01397\nggplot(top10_long, aes(x = SYMBOL, y = Intensity, fill = Group)) + \n  geom_boxplot() +\n  geom_hline(yintercept = global_mean_intensity, linetype = \"dashed\", color = \"darkviolet\", linewidth = 1) +\n  theme_bw() +\n  theme(axis.text.x = \n          element_text(angle = 45, vjust = 1, hjust=1))\ntop10_long_dissec <- top10_long |> \n                      left_join(select(meta_nc, title, `dissection:ch1`), \n                                by = c(\"Case\" = \"title\"))\ntop10_long_dissec\nggplot(top10_long_dissec, aes(x = `dissection:ch1`, fill = Group)) + \n  geom_bar(col = \"black\", width = 0.5, position = \"dodge\") + \n  theme_bw()\ntop10_long_dissec <- top10_long_dissec |> \n                      mutate(`dissection:ch1` = gsub(\"-\", \" \", `dissection:ch1`))\n\nggplot(top10_long_dissec, aes(x = `dissection:ch1`, fill = Group)) + \n  geom_bar(col = \"black\", width = 0.5, position = \"dodge\") + \n  theme_bw()\nggplot(top10_long_dissec, aes(x = SYMBOL, y = Intensity, fill = Group)) + \n  geom_boxplot() +\n  facet_wrap(~`dissection:ch1`) +\n  theme_bw() +\n  theme(axis.text.x = \n          element_text(angle = 45, vjust = 1, hjust=1))"},{"path":"hypothesis-testing.html","id":"hypothesis-testing","chapter":"8 Hypothesis testing","heading":"8 Hypothesis testing","text":"การทดสอบสมมติฐาน คือ การใช้วิธีทางสถิติในตอบคำถามสมมติฐานที่ต้องการ โดยมีขั้นตอน คือ","code":""},{"path":"hypothesis-testing.html","id":"สรางสมมตฐาน-construct-the-hypothesis","chapter":"8 Hypothesis testing","heading":"8.1 สร้างสมมติฐาน (Construct the hypothesis)","text":"สมมติฐานว่าง (Null hypothesis; \\(H_{0}\\)) คือสมมติฐานที่ต้องการทดสอบ ซึ่งเปรียบเทียบได้กับสิ่งที่ทุกคนมีความเชื่อกันอยู่แล้ว (default belief) หรือไม่ทราบแน่ชัดว่าเป็นอย่างไร ซึ่งจะเป็นแนวปฏิเสธไว้ก่อน คือ ไม่มีความแตกต่างกันสมมติฐานทางเลือก (Alternative hypothesis; \\(H_{}\\)) คือสมมติฐานที่คาดหวังว่าจะเป็นการค้นพบใหม่","code":""},{"path":"hypothesis-testing.html","id":"ทำการวเคราะหคาทางสถต-construct-the-test-statistics","chapter":"8 Hypothesis testing","heading":"8.2 ทำการวิเคราะห์ค่าทางสถิติ (Construct the test statistics)","text":"โดยเครื่องมือจะมีหลายรูปแบบตามลักษณะของข้อมูล เช่น t-test, Chi-square เป็นต้น ซึ่งผลลัพธ์จากการหาค่าทางสถิติจะเป็นไปตามการทดสอบนั้นๆ เช่น t-test: \\(t\\), Chi-square: \\(X^{2}\\), F-test: \\(F\\) เป็นต้น","code":""},{"path":"hypothesis-testing.html","id":"หา-p-value","chapter":"8 Hypothesis testing","heading":"8.3 หา p-value","text":"คือ โอกาสที่สามารถสังเกตค่าทางสถิติที่มากกว่าค่าการวิเคราะห์ทางสถิติที่โดยไม่ได้อยู่ภายใต้ \\(H_{0}\\) โดยทางปฏิบัติแล้วคือ การสร้างแบบจำลองข้อมูลภายใต้ \\(H_{0}\\) ขึ้นมาแล้วแล้วดูว่า ที่ค่าสถิตินั้น มีโอกาสไม่เกิดเท่าไรยกตัวอย่าง เมื่อวิเคราะห์ t-test จะทำการสร้าง t-distribution ขึ้นมา (ตัวอย่างของการวิเคราะห์ อยู่บทถัดไป ) ภายใต้ \\(H_{0}\\) ว่า mean = 10ที่ -0.7345 < \\(t\\) < 0.7345 (พื้นที่ใต้กราฟสีขาว) หมายถึงโอกาสที่ค่านั้นเกิดจากความบังเอิญภายใต้ \\(H_{0}\\) ที่ยังเป็นจริง คิดเป็น AUC ได้ที่ \\(t\\) < -0.7345 หรือ \\(t\\) > 0.7345 (พื้นที่ใต้กราฟสีฟ้า) หมายถึงโอกาสที่ค่านั้นไม่ได้เกิดจากความบังเอิญภายใต้ \\(H_{0}\\) ที่ยังเป็นจริง (extreme value) คิดเป็น AUC ได้โดย AUC_blue = p-value = พื้นที่ใต้กราฟสีฟ้า = ~46.4%","code":"\nlibrary(tidyverse)\nt_dist <- dt(seq(-5,5,0.01), df = 99) # t-distribution มี mean = 0 sd = 1\n\ntval <- 0.7345 # t-value วิธีคำนวณอยู่ในบท t-test\n\ndensity_df <- data.frame(x = seq(-5,5,0.01), y = t_dist) |>\n  mutate(area = ifelse(between(x,-tval,tval), TRUE,FALSE))\n\nggplot(density_df, aes(x,y)) + \n  geom_area(fill = \"skyblue\", color = \"black\") +\n  geom_area(data = filter(density_df, area), fill = \"white\", color = \"black\") +\n  geom_vline(xintercept = c(-tval,tval), linetype = \"dashed\") +\n  theme_bw()\ndensity_df |> \n  filter(area) |> \n  summarize(AUC_white = sum(y)) |> pull()## [1] 53.59248\ndensity_df |> \n  filter(!area) |> \n  summarize(AUC_blue = sum(y)) |> pull()## [1] 46.40728\np <- 2*pt(0.7345, 99, lower.tail = FALSE) \np # p-value## [1] 0.4643803"},{"path":"hypothesis-testing.html","id":"เปรยบเทยบ-p-value-กบ-คาวกฤต-critical-value-ทยอมรบได","chapter":"8 Hypothesis testing","heading":"8.4 เปรียบเทียบ p-value กับ ค่าวิกฤติ (critical value) ที่ยอมรับได้","text":"จุดนี้จะเป็นการตัดว่า ท่านสามารถยอมรับความบังเอิญนี้ที่กี่ % โดยทั่วไปมักใช้ที่น้อยกว่า 5% (0.05) หรือ 1% (0.01) ซึ่งแบ่งเป็นLeft-tailed คือ โอกาสที่ critical value \\(\\leq H_{0}\\)Left-tailed คือ โอกาสที่ critical value \\(\\leq H_{0}\\)Right-tailed คือ โอกาสที่ critical value \\(\\geq H_{0}\\)Right-tailed คือ โอกาสที่ critical value \\(\\geq H_{0}\\)Two-tailed คือ โอกาสที่ critical value \\(\\neq H_{0}\\) นิยมใช้วิเคราะห์มากที่สุดTwo-tailed คือ โอกาสที่ critical value \\(\\neq H_{0}\\) นิยมใช้วิเคราะห์มากที่สุดจะเห็นว่า โอกาสที่ความแตกต่างนั้นไม่ได้เกิดจากความบังเอิญภายใต้ \\(H_{0}\\) นั้นอยู่ที่ 46% ซึ่งมากกว่า 5% ที่ต้องการ จึงไม่สามารถ reject null hypothesis ได้ เรียกอีกแบบหนึ่งว่า ไม่ได้แตกต่างอย่างมีนัยสำคัญ (จนสามารถ reject \\(H_{0}\\) ได้)ตรงส่วนพื้นที่ระหว่าง critical value (ระหว่างเส้นประสีแดง) คือ พิสัยของความแตกต่างที่สามารถรับได้ ซึ่งจะถูกนำไปใช้ในการคำนวณค่าความเชื่อมั่น (confidence interval) ต่อไป","code":"\ncrit <- qt(1-0.05/2, df = 99) # ตัดที่ <= p 0.05, two-tailed\n\ndensity_df <- density_df |> \n  mutate(crits = ifelse(between(x,-crit,crit), TRUE,FALSE))\n\nggplot(density_df, aes(x,y)) + \n  geom_area(fill = \"darkred\", color = \"black\") +\n  geom_area(data = filter(density_df, crits), fill = \"skyblue\", color = \"black\") + \n  geom_area(data = filter(density_df, area), fill = \"white\", color = \"black\") +\n  geom_vline(xintercept = c(-tval,tval), linetype = \"dashed\") +\n  geom_vline(xintercept = c(-crit,crit), linetype = \"dashed\", color = \"red\") +\n  theme_bw()"},{"path":"hypothesis-testing.html","id":"trade-off-ของ-p-value-threshold","chapter":"8 Hypothesis testing","heading":"Trade-off ของ p-value threshold","text":"การตั้งค่าวิกฤตินั้นมี trade-ระหว่าง false positive และ false negative ที่ต้องพิจารณาType error = false positive = \\(\\alpha\\) = critical valueType error = false positive = \\(\\alpha\\) = critical valueType II error = false negative = \\(\\beta\\) = 1 - powerType II error = false negative = \\(\\beta\\) = 1 - power\\(\\therefore\\) power = true negative","code":""},{"path":"parametric-test.html","id":"parametric-test","chapter":"9 Parametric test","heading":"9 Parametric test","text":"Parametric test คือ การวิเคราะห์ทางสถิติที่เราทราบลักษณะการกระจายตัวของข้อมูลอย่างชัดเจน แต่มีข้อดีคือการเปรียบเทียบข้อมูลจะมีความแม่นยำสูง","code":""},{"path":"parametric-test.html","id":"sec-t-test","chapter":"9 Parametric test","heading":"9.1 t-test","text":"คือ การคำนวณทางสถิติที่เปรียบเทียบค่าเฉลี่ย (mean) และความแปรปรวน (sd) ระหว่างสองกลุ่ม แบ่งเป็น","code":""},{"path":"parametric-test.html","id":"one-t","chapter":"9 Parametric test","heading":"9.1.1 One sample t-test","text":"เป็นการเปรียบเทียบความแตกต่างของ mean ระหว่าง sample กับ population\\[\nt = \\frac{\\bar{x} - \\mu_{0}}{SE} = \\frac{\\bar{x} - \\mu_{0}}{s/\\sqrt{n}}\n\\]เพื่อให้เห็นภาพของความต่างใน test นี้เราจะทำการสร้างกราฟเปรียบว่า sample นั้น มี mean ต่างจาก population ที่ mean = 10 และ mean = 30 หรือไม่จะเห็นว่าเมื่อดูลักษณะการกระจายตัวของข้อมูลแล้ว Samp_10 ที่มี mean = 10 นั้น ไม่ต่างจากประชากรที่มี mean = 10 แต่ดูแตกต่างอย่างเห็นได้ชัดกับประชากรที่มี mean = 30 t.test จะช่วยตัดสินว่าค่าที่ได้นั้นแตกต่างกันจริงหรือไม่ hypothesis ที่ตั้งคือCase 1: Population mean = 10\\(H_{0}\\): mean ของ sample นั้น ไม่ต่างจาก mean ของ population ที่ mean = 10\\(H_{0}\\): mean ของ sample นั้น ไม่ต่างจาก mean ของ population ที่ mean = 10\\(H_{}\\): mean ของ sample นั้น ต่างจาก mean ของ population ที่ mean = 10\\(H_{}\\): mean ของ sample นั้น ต่างจาก mean ของ population ที่ mean = 10Case 2: Population mean = 40\\(H_{0}\\): mean ของ sample นั้น ไม่ต่างจาก mean ของ population ที่ mean = 40\\(H_{0}\\): mean ของ sample นั้น ไม่ต่างจาก mean ของ population ที่ mean = 40\\(H_{}\\): mean ของ sample นั้น ต่างจาก mean ของ population ที่ mean = 40\\(H_{}\\): mean ของ sample นั้น ต่างจาก mean ของ population ที่ mean = 40จะเห็นว่าต่างจาก population ที่ mean = 30 อย่างมีนัยสำคัญ (p = \\(2.2 \\times 10^{-16}\\) < critical point (0.05) )พิจารณาที่มาของ p-value นั้นมีที่มาจากสูตรขั้นต้นจะเห็นว่าค่า t นั้นเท่ากับ ค่าที่ได้จาก function t.test ขั้นต้น เมื่อสร้าง t-distribution ที่มี \\(H_{0}\\) คือ mean = 0 แล้วจะพบว่าค่านี้มากกว่า critical value","code":"\nset.seed(123)\nnorm_10_pop <- rnorm(1000, mean = 10, sd = 4) # สร้างประชากร mean = 10, sd = 4\nnorm_10_sample <- sample(norm_10_pop, 100) # สุ่มตัวอย่างมาจากประชากร 100 ราย\nnorm_30_pop <- rnorm(1000, mean = 30, sd = 4)\nnorm_30_sample <- sample(norm_30_pop, 100)\nnorm_pop_df <- data.frame(Pop_10 = norm_10_pop, Pop_30 = norm_30_pop) |>\n  pivot_longer(everything(), names_to = \"Pop\", values_to = \"Values\")  \n\nnorm_sample_df <- data.frame(Samp_10 = norm_10_sample, Samp_30 = norm_30_sample) |>    pivot_longer(everything(), names_to = \"Samp\", values_to = \"Values\")  \n\nggplot(norm_pop_df, aes(x = Values, fill = Pop)) +    \n  geom_density(aes(y = after_stat(count)),color = \"black\", alpha = 0.5) + \n  geom_density(data = norm_sample_df, \n               aes(x  = Values, y = after_stat(count), fill = Samp), \n               color = \"black\", alpha = 0.7) + theme_bw()\nt.test(norm_10_sample, mu = 10) # p > 0.05## \n##  One Sample t-test\n## \n## data:  norm_10_sample\n## t = 0.73547, df = 99, p-value = 0.4638\n## alternative hypothesis: true mean is not equal to 10\n## 95 percent confidence interval:\n##   9.533936 11.015052\n## sample estimates:\n## mean of x \n##  10.27449\nt.test(norm_10_sample, mu = 30) # p <= 0.05## \n##  One Sample t-test\n## \n## data:  norm_10_sample\n## t = -52.852, df = 99, p-value < 2.2e-16\n## alternative hypothesis: true mean is not equal to 30\n## 95 percent confidence interval:\n##   9.533936 11.015052\n## sample estimates:\n## mean of x \n##  10.27449\nhypothesized_mean <- 30\nmean_sample <- mean(norm_10_sample)\nsd_sample <- sd(norm_10_sample)\n\nt <- (mean_sample - hypothesized_mean)/(sd_sample/sqrt(length(norm_10_sample)))\n\nt## [1] -52.85159\n2*pt(t, df = 99) # p-value## [1] 2.306252e-74"},{"path":"parametric-test.html","id":"ind-t","chapter":"9 Parametric test","heading":"9.1.2 Independent t-test","text":"เป็นการเปรียบเทียบ mean ระหว่าง sample สองกลุ่มที่ไม่เกี่ยวเนื่องกัน\\[\nt = \\frac{\\bar{x_{1}}-\\bar{x_{2}}}{\\sqrt{\\frac{s^{2}_1}{n_{1}}+\\frac{s^{2}_2}{n_{2}}}}\n\\]\\[\nS_{p}^{2} = \\frac{(n_{1}-1)s^{2}_{1}+(n_{2}-1)s^{2}_{2}}{{n_{1}} + n_{2} - 2}\n\\]กลับไปดูภาพขั้นต้น ครั้งนี้จะเทียบระหว่าง sample สองกลุ่ม คือ norm_10_sample และ norm_30_sample ว่ามี mean ที่แตกต่างกันอย่างมีนัยสำคัญหรือไม่\\(H_{0}\\): mean ของ norm_10_sample และ norm_30_sample นั้นไม่แตกต่างกัน (\\(\\text{mean difference} = 0\\))\\(H_{0}\\): mean ของ norm_10_sample และ norm_30_sample นั้นไม่แตกต่างกัน (\\(\\text{mean difference} = 0\\))\\(H_{}\\): mean ของ norm_10_sample และ norm_30_sample นั้นแตกต่างกัน (\\(\\text{mean difference} \\neq 0\\))\\(H_{}\\): mean ของ norm_10_sample และ norm_30_sample นั้นแตกต่างกัน (\\(\\text{mean difference} \\neq 0\\))สรุปได้ว่า mean ของ sample ทั้งสองกลุ่มนั้นแตกต่างกันอย่างมีนัยสำคัญปล. บางครั้งข้อมูลอาจจะมีความแปรปรวนไม่เท่ากัน ในที่นี้มักจะใช้ Welch's t-test โดย t.test(…, var.equal = FALSE) โดยสมการนี้จะทำการปรับความแปรปรวนให้ด้วย","code":"\nt.test(norm_10_sample, norm_30_sample, var.equal = TRUE)## \n##  Two Sample t-test\n## \n## data:  norm_10_sample and norm_30_sample\n## t = -38.469, df = 198, p-value < 2.2e-16\n## alternative hypothesis: true difference in means is not equal to 0\n## 95 percent confidence interval:\n##  -20.93623 -18.89440\n## sample estimates:\n## mean of x mean of y \n##  10.27449  30.18981"},{"path":"parametric-test.html","id":"pair-t","chapter":"9 Parametric test","heading":"9.1.3 Paired t-test","text":"เป็นการเปรียบเทียบ mean ระหว่าง sample สองกลุ่มที่เกี่ยวเนื่องกัน (ก่อน-หลัง แม่-ลูก เป็นต้น)\\[\nt = \\frac{\\bar{x}_{d} -\\mu_{0}}{{s_{d} / \\sqrt{n}}}\n\\]\\[ s_{d} = \\sqrt{\\sum(x_{d}-\\bar{x}_{d})/(n-1)}\\]จะเห็นว่ามีความแตกต่างในส่วนของ \\(DF\\) (degree freedom) ซึ่งเกิดจากการจับคู่หาความต่าง 100 ครั้ง เนื่องจากค่าที่เปรียบเทียบนั้นอยู่ในตัวอย่างเดียวกัน (แม่ลูก คู่ที่ 1 แม่ลูกคู่ที่ 2 … เป็นต้น) เมื่อเปรียบเทียบกับ independent t-test เนื่องจากเป็นการหา mean ในกลุ่มของตัวเอง 2 ครั้ง และมาเทียบความต่างกันดังนั้น การเลือก paired vs independent นั้นมีความสำคัญ ขึ้นอยู่กับโจทย์การศึกษาของท่านด้วย","code":"\nt.test(norm_10_sample, norm_30_sample, paired = TRUE)## \n##  Paired t-test\n## \n## data:  norm_10_sample and norm_30_sample\n## t = -37.802, df = 99, p-value < 2.2e-16\n## alternative hypothesis: true mean difference is not equal to 0\n## 95 percent confidence interval:\n##  -20.96067 -18.86996\n## sample estimates:\n## mean difference \n##       -19.91532"},{"path":"parametric-test.html","id":"ANOVA","chapter":"9 Parametric test","heading":"9.2 Analysis of Variance (ANOVA)","text":"คือ การคำนวณทางสถิติที่เปรียบเทียบค่าเฉลี่ย (mean) และความแปรปรวน (sd) ระหว่างสองกลุ่มขึ้นไป โดยมีสมมติฐาน คือ\\(H_{0}\\): ค่าเฉลี่ยของทุกกลุ่มเท่ากัน (\\(\\mu_{1} = \\mu_{2} = \\mu_{3} = … = \\mu_{k}\\))\\(H_{0}\\): ค่าเฉลี่ยของทุกกลุ่มเท่ากัน (\\(\\mu_{1} = \\mu_{2} = \\mu_{3} = … = \\mu_{k}\\))\\(H_{}\\): ค่าเฉลี่ยของกลุ่มใดกลุ่มหนึ่งต่างจากกลุ่มอื่น\\(H_{}\\): ค่าเฉลี่ยของกลุ่มใดกลุ่มหนึ่งต่างจากกลุ่มอื่นการวิเคราะห์ ANOVA นั้นมีหลายแบบone-way ANOVA เป็นการหาความแตกต่างของ 1 ตัวแปรone-way ANOVA เป็นการหาความแตกต่างของ 1 ตัวแปรtwo-way ANOVA เป็นการหาความแตกต่างของ 2 ตัวแปรtwo-way ANOVA เป็นการหาความแตกต่างของ 2 ตัวแปรMANOVA เป็นการหาความแตกต่างที่มากกว่า 2 ตัวแปรMANOVA เป็นการหาความแตกต่างที่มากกว่า 2 ตัวแปรnested ANOVA เป็นการหาความแตกต่างที่ใน 1 ตัวแปรนั้น มีตัวแปรย่อยอีกnested ANOVA เป็นการหาความแตกต่างที่ใน 1 ตัวแปรนั้น มีตัวแปรย่อยอีกณ ที่นี้จะกล่าวถึงแค่ one-way ANOVA ซึ่งมีความซับซ้อนน้อย โดยหลักการโดยง่ายของ ANOVA คือ การเปรียบเทียบความต่างของ ค่าเฉลี่ยทั้งกลุ่ม (global mean) เปรียบเทียบกับ ผลรวมของค่าเฉลี่ยแต่ละกลุ่ม (group mean)การวิเคราะห์ทางสถิติของ ANOVA นั้นใช้ F-test ซึ่งเป็นการเปรียบเทียบระหว่าง ความแปรปรวนที่อธิบายได้ และความแปรปรวนที่อธิบายไม่ได้\\[F^{*} = \\frac{\\text{Explained variance}}{\\text{Unexplained variance}} =  \\frac{\\text{group variance}}{\\text{Within groups variance}}\\]group variance คือ ความแปรปรวนของค่าเฉลี่ยแต่ละกลุ่มกับค่าเฉลี่ยทั้งหมดBetween group variance คือ ความแปรปรวนของค่าเฉลี่ยแต่ละกลุ่มกับค่าเฉลี่ยทั้งหมดWithin group variance คือ ความแปรปรวนของข้อมูลในกลุ่มนั้น ซึ่งไม่สามารถอธิบายได้ภายใต้สมมติฐานงานวิจัยนั้นWithin group variance คือ ความแปรปรวนของข้อมูลในกลุ่มนั้น ซึ่งไม่สามารถอธิบายได้ภายใต้สมมติฐานงานวิจัยนั้นอธิบายโดยใช้ตัวอย่าง iris ในที่นี้เราจะเปรียบเทียบตวามต่างของ Sepal.Width ในแต่ละ Speciesอธิบายด้วยภาพรูปสามเหลี่ยม คือ mean ของ Petal.Width ในดอกไม้แต่ละ Speciesรูปสามเหลี่ยม คือ mean ของ Petal.Width ในดอกไม้แต่ละ Speciesจุดสีดำ คือ ค่า Petal.Width ในดอกไม้แต่ละดอกจุดสีดำ คือ ค่า Petal.Width ในดอกไม้แต่ละดอกจุดสีเขียว คือ global mean (grand mean) คือ ค่าเฉลี่ย Petal.Width เมื่อรวมดอกไม้ทุก Speciesจุดสีเขียว คือ global mean (grand mean) คือ ค่าเฉลี่ย Petal.Width เมื่อรวมดอกไม้ทุก Speciesจุดประสงค์ของ F-test คือการเปรียบเทียบอัตราส่วนระหว่าง ความแปรปรวนของค่าเฉลี่ยแต่ละกลุ่มกับค่าเฉลี่ยทั้งหมด (mean ของความต่างจุดเขียวกับสามเหลี่ยม) ใกล้กันกับความแปรปรวนของข้อมูลในกลุ่มนั้น (mean ของความต่างระหว่างจุดดำกับกับสามเหลี่ยม) หรือไม่ (ratio ~ 1) ซึ่งค่า \\(F\\) นั้นจะถูกนำไปคิด p-value จาก F-distribution (หลักการเดียวกันกับ t-test)สังเกตว่า ท่านไม่สามารถบอกได้ว่ากลุ่มไหนเป็นกลุ่มที่มีค่าเฉลี่ยที่แตกต่างจากทั้งกลุ่ม การที่จะทราบนั้นต้องทำ t.test เปรียบเทียบกันในแต่ละกลุ่ม \\(3\\choose2\\) = 3 ครั้ง การค้นหากลุ่มที่มีความต่างหลัง ANOVA นี้ เรียกว่า post-hoc testp-value น้อยกว่า 0.05 ทุกกลุ่ม หมายความว่า ทุกกลุ่มมีค่าเฉลี่ยของ Petal.Width ที่แตกต่างกัน","code":"\naov(Sepal.Width ~ Species, data = iris) |> summary()##              Df Sum Sq Mean Sq F value Pr(>F)    \n## Species       2  11.35   5.672   49.16 <2e-16 ***\n## Residuals   147  16.96   0.115                   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nlibrary(granova)\ngranova.1w(iris$Sepal.Width, group = iris$Species)## $grandsum\n##     Grandmean        df.bet       df.with        MS.bet       MS.with        F.stat        F.prob SS.bet/SS.tot \n##          3.06          2.00        147.00          5.67          0.12         49.16          0.00          0.40 \n## \n## $stats\n##            Size Contrast Coef Wt'd Mean Mean Trim'd Mean Var. St. Dev.\n## versicolor   50         -0.29      2.77 2.77        2.80 0.10     0.31\n## virginica    50         -0.08      2.97 2.97        2.96 0.10     0.32\n## setosa       50          0.37      3.43 3.43        3.41 0.14     0.38\npairwise.t.test(iris$Sepal.Width, iris$Species)## \n##  Pairwise comparisons using t tests with pooled SD \n## \n## data:  iris$Sepal.Width and iris$Species \n## \n##            setosa  versicolor\n## versicolor < 2e-16 -         \n## virginica  9.1e-10 0.0031    \n## \n## P value adjustment method: holm"},{"path":"parametric-test.html","id":"correlation-test","chapter":"9 Parametric test","heading":"9.3 Correlation test","text":"","code":""},{"path":"parametric-test.html","id":"pearson","chapter":"9 Parametric test","heading":"9.3.1 Pearson correlation","text":"เป็นการทดสอบความสัมพันธ์เชิงเส้นของตัวแปรสองตัวแปร\\[\nr_{xy} =\\frac{cov(x,y)}{s(x) s(y)}\n\\]\\[\nr_{xy} = \\frac{\\sum^{n}_{=1}(x_{}-\\bar{x})(y_{}-\\bar{y})}{\\sqrt{\\sum^{n}_{=1}(x_{}-\\bar{x})^{2}}\\sqrt{\\sum^{n}_{=1}(y_{}-\\bar{y})^{2}}}\n\\]การแปลผลของ correlation ขึ้นอยู่กับระดับของความสัมพันธ์ = 0-1 ยิ่งเข้าใกล้ 1 ยิ่งสัมพันธ์กันมากระดับของความสัมพันธ์ = 0-1 ยิ่งเข้าใกล้ 1 ยิ่งสัมพันธ์กันมากทิศทางของความสัมพันธ์ = + ไปทิศทางเดียวกัน - ไปทิศทางตรงข้ามกันทิศทางของความสัมพันธ์ = + ไปทิศทางเดียวกัน - ไปทิศทางตรงข้ามกันท่านสามารถสร้างตาราง correlation และ p-value ได้ด้วย package corrplotข้อควรระวัง p-value ของ correlation test นั้นอยู่ภายใต้สมมติฐาน (\\(t\\)-test/\\(F\\)-test)\\(H_{0}\\): ไม่มีความสัมพันธ์เชิงเส้นของทั้งสองตัวแปร (\\(r_{xy} = 0\\))\\(H_{0}\\): ไม่มีความสัมพันธ์เชิงเส้นของทั้งสองตัวแปร (\\(r_{xy} = 0\\))\\(H_{0}\\): มีความสัมพันธ์เชิงเส้นของทั้งสองตัวแปร (\\(r_{xy} \\neq 0\\))\\(H_{0}\\): มีความสัมพันธ์เชิงเส้นของทั้งสองตัวแปร (\\(r_{xy} \\neq 0\\))ซึ่งถ้า \\(p\\) < 0.05 หมายความว่า ท่านมีความมั่นใจมากเพียงพอว่า ความสัมพันธ์เชิงเส้นของทั้งสองตัวแปรนั้น มีมากกว่าการวาดเส้นจากการสร้างจุดแบบสุ่ม ท่านยังคงต้องแปรผลร่วมกับค่า correlation coefficient ต่อไปเช่น\\(r_{x,y}\\) = 0.2, \\(p\\) < 0.05 มั่นใจว่ามีความสัมพันธ์เชิงเส้นของสองตัวแปร ความสัมพันธ์เป็นไปในทิศทางเดียวกัน แต่ความสัมพันธ์เชิงเส้นอยู่ในระดับน้อย\\(r_{x,y}\\) = 0.2, \\(p\\) < 0.05 มั่นใจว่ามีความสัมพันธ์เชิงเส้นของสองตัวแปร ความสัมพันธ์เป็นไปในทิศทางเดียวกัน แต่ความสัมพันธ์เชิงเส้นอยู่ในระดับน้อย\\(r_{x,y}\\) = 1, \\(p\\) = 1 ความสัมพันธ์เชิงเส้นอยู่ในระดับดีเยี่ยม แต่ไม่มั่นใจว่ามีความสัมพันธ์กันจริงหรือไม่ เนื่องจากข้อมูลน้อย (เช่น มีข้อมูลเพียงสองจุด \\(r_{x,y}\\) ย่อมเท่ากับ 1)\\(r_{x,y}\\) = 1, \\(p\\) = 1 ความสัมพันธ์เชิงเส้นอยู่ในระดับดีเยี่ยม แต่ไม่มั่นใจว่ามีความสัมพันธ์กันจริงหรือไม่ เนื่องจากข้อมูลน้อย (เช่น มีข้อมูลเพียงสองจุด \\(r_{x,y}\\) ย่อมเท่ากับ 1)\\(r_{x,y}\\) = 0.3, \\(p\\) = 1 ความสัมพันธ์เชิงเส้นอยู่ในระดับน้อย แต่ไม่มั่นใจว่ามีความสัมพันธ์กันจริงหรือไม่ เนื่องจากข้อมูลน้อยเกินไป ควรเก็บข้อมูลเพิ่ม\\(r_{x,y}\\) = 0.3, \\(p\\) = 1 ความสัมพันธ์เชิงเส้นอยู่ในระดับน้อย แต่ไม่มั่นใจว่ามีความสัมพันธ์กันจริงหรือไม่ เนื่องจากข้อมูลน้อยเกินไป ควรเก็บข้อมูลเพิ่ม\\(r_{x,y}\\) = -1, \\(p\\) < 0.05 มั่นใจว่ามีความสัมพันธ์เชิงเส้นของสองตัวแปร ความสัมพันธ์เป็นไปในทิศทางตรงข้าม และความสัมพันธ์เชิงเส้นอยู่ในระดับดีเยี่ยม\\(r_{x,y}\\) = -1, \\(p\\) < 0.05 มั่นใจว่ามีความสัมพันธ์เชิงเส้นของสองตัวแปร ความสัมพันธ์เป็นไปในทิศทางตรงข้าม และความสัมพันธ์เชิงเส้นอยู่ในระดับดีเยี่ยมนั่นหมายความว่า ยิ่งจำนวนตัวอย่างเพิ่มขึ้น ความมั่นใจยิ่งเพิ่มขึ้น ไม่ใช่ความสัมพันธ์เพิ่มขึ้น","code":"\nggplot(iris, aes(x = Sepal.Length, y = Petal.Length)) + \n  geom_point(aes(col = Species)) +\n  geom_smooth(method = \"lm\", se = FALSE)\ncor(iris$Sepal.Length, iris$Petal.Length)## [1] 0.8717538\nlibrary(corrplot)\n\niris_cor <- cor(iris[1:4])\niris_cor##              Sepal.Length Sepal.Width Petal.Length Petal.Width\n## Sepal.Length    1.0000000  -0.1175698    0.8717538   0.8179411\n## Sepal.Width    -0.1175698   1.0000000   -0.4284401  -0.3661259\n## Petal.Length    0.8717538  -0.4284401    1.0000000   0.9628654\n## Petal.Width     0.8179411  -0.3661259    0.9628654   1.0000000\niris_cor_p <- cor.mtest(iris[1:4])\niris_cor_p## $p\n##              Sepal.Length  Sepal.Width Petal.Length  Petal.Width\n## Sepal.Length 0.000000e+00 1.518983e-01 1.038667e-47 2.325498e-37\n## Sepal.Width  1.518983e-01 0.000000e+00 4.513314e-08 4.073229e-06\n## Petal.Length 1.038667e-47 4.513314e-08 0.000000e+00 4.675004e-86\n## Petal.Width  2.325498e-37 4.073229e-06 4.675004e-86 0.000000e+00\n## \n## $lowCI\n##              Sepal.Length Sepal.Width Petal.Length Petal.Width\n## Sepal.Length    1.0000000  -0.2726932    0.8270363   0.7568971\n## Sepal.Width    -0.2726932   1.0000000   -0.5508771  -0.4972130\n## Petal.Length    0.8270363  -0.5508771    1.0000000   0.9490525\n## Petal.Width     0.7568971  -0.4972130    0.9490525   1.0000000\n## \n## $uppCI\n##              Sepal.Length Sepal.Width Petal.Length Petal.Width\n## Sepal.Length   1.00000000  0.04351158    0.9055080   0.8648361\n## Sepal.Width    0.04351158  1.00000000   -0.2879499  -0.2186966\n## Petal.Length   0.90550805 -0.28794993    1.0000000   0.9729853\n## Petal.Width    0.86483606 -0.21869663    0.9729853   1.0000000\ncorrplot(iris_cor, method = \"shade\",type = \"upper\",order = \"AOE\", \n         p.mat = iris_cor_p$p, insig = \"p-value\")"},{"path":"non-parametric-test.html","id":"non-parametric-test","chapter":"10 Non-parametric test","heading":"10 Non-parametric test","text":"Non-parametric test คือ การวิเคราะห์ทางสถิติที่เราไม่ทราบลักษณะการกระจายตัวของข้อมูลอย่างชัดเจน ข้อดีคือมีความยืดหยุ่นกว่า แต่มีความแม่นยำน้อยกว่า","code":""},{"path":"non-parametric-test.html","id":"proportion-test","chapter":"10 Non-parametric test","heading":"10.1 Proportion test","text":"คือ การทดสอบทางสถิติเพื่อทำการเปรียบเทียบอัตราส่วนของจำนวน โดยจะใช้กับข้อมูลประเภทจำนวนนับของตัวแปรจัดประเภท (Nominal variable) เช่น จำนวนคน จำนวนเซลล์ เป็นต้นข้อสังเกต การทดลองที่มีการทำ technical replicate แล้วหาค่าเฉลี่ยนั้น ตัวข้อมูลยังเป็น จำนวนนับ การจะหาความต่างค่าเฉลี่ยโดยใช้ t.test นั้น จำนวน sample ควรจะมากพอตาม Central limit theorem นอกเหนือจากนั้นควรใช้ proportional test หรือ ควรใช้ generalized linear model ประเภทอื่นมากกว่า","code":""},{"path":"non-parametric-test.html","id":"chi-square-test","chapter":"10 Non-parametric test","heading":"10.1.1 Chi-square test","text":"คือ การทดสอบความต่างของอัตราส่วนโดยใช้การประมาณการของ ค่าที่คาดหวัง (expected value) และ ค่าที่สังเกตได้จริง (observed value)\\[\n\\chi^{2} = \\sum_{=1}^{n}\\frac{(O-E)^{2}}{E}\n\\]","code":""},{"path":"non-parametric-test.html","id":"chi-square-goodness-of-fit","chapter":"10 Non-parametric test","heading":"10.1.1.1 Chi-square goodness of fit","text":"เป็นการเปรียบเทียบว่า observed value นั้นมาจากประชากรทางทฤษฎีหรือไม่ โดย expected value นั้นคำนวนจาก\\[\nE_{} = CDF_{}(Y_{u})-CDF_{}(Y_{l})\n\\]ยกตัวอย่างการทอดลูกเต๋า ซึ่งมีโอกาสการเกิดทุกหน้า = \\(1/6\\)\\(H_{0}\\) การกระจายตัวของการทอดลูกเต๋านี้เท่ากับการกระจายทางทฤษฎี\\(H_{0}\\) การกระจายตัวของการทอดลูกเต๋านี้เท่ากับการกระจายทางทฤษฎี\\(H_{}\\) การกระจายตัวของการทอดลูกเต๋านี้ไม่เท่ากับการกระจายทางทฤษฎี\\(H_{}\\) การกระจายตัวของการทอดลูกเต๋านี้ไม่เท่ากับการกระจายทางทฤษฎีจะเห็นว่าความแตกต่างระหว่าง observed และ expected นั้น อยู่ในพิสัยของของ \\(H_{0}\\)แต่ถ้าลูกเต๋านั้นเป็นลูกเต๋าถ่วงน้ำหนักเมื่อวิเคราะห์ chi-square ตามการกระจายตัวของลูกเต๋าทั่วไป จะแตกต่างอย่างมีนัยสำคัญแต่ถ้าวิเคราะห์เทียบกับการกระจายตัวเดียวกับลูกเต๋าถ่วงน้ำหนัก จะไม่แตกต่างกัน","code":"\nset.seed(123)\ndice <- sample(6, 1000, replace = TRUE) # โยนลูกเต๋า 1000 ครั้ง\nchisq_dice <- chisq.test(table(dice))\nchisq_dice## \n##  Chi-squared test for given probabilities\n## \n## data:  table(dice)\n## X-squared = 1.436, df = 5, p-value = 0.9203\ndata.frame(O = chisq_dice$observed, E.Freq = chisq_dice$expected)\nweight_dice <- sample(6,1000, replace = TRUE, prob = c(3,2,1,1,1,1)/9)\nchisq_weight_norm <- chisq.test(table(weight_dice))\nchisq_weight_norm## \n##  Chi-squared test for given probabilities\n## \n## data:  table(weight_dice)\n## X-squared = 248.55, df = 5, p-value < 2.2e-16\ndata.frame(O = chisq_weight_norm$observed, E.freq = chisq_weight_norm$expected)\nchisq_weight_weight <- chisq.test(table(weight_dice), p = c(3,2,1,1,1,1)/9)\nchisq_weight_weight## \n##  Chi-squared test for given probabilities\n## \n## data:  table(weight_dice)\n## X-squared = 2.9135, df = 5, p-value = 0.7133\ndata.frame(O = chisq_weight_weight$observed, E.freq = chisq_weight_weight$expected)"},{"path":"non-parametric-test.html","id":"chi-square-test-of-independence","chapter":"10 Non-parametric test","heading":"10.1.1.2 Chi-square test of independence","text":"เป็นการเปรียบเทียบข้อมูลจำนวนสองกลุ่มขึ้นไปว่า มีความสัมพันธ์ที่ทำให้การกระจายตัวของข้อมูลเปลี่ยนไปจากปกติหรือไม่\\(H_{0}\\): ข้อมูลทั้ง 2+ กลุ่มนั้นไม่มีความสัมพันธ์ต่อกัน\\(H_{}\\): ข้อมูลทั้ง 2+ กลุ่มนั้นมีความสัมพันธ์ต่อกันโดยการวิเคราะห์นั้นจะใช้กับข้อมูลความถี่แบบ \\(n \\times n\\) โดย expected event นั้นคิดจาก\\[\nE_{,j} = P(G_{,j}) \\times P(Con_{,j}) \\times \\text{total counts}\n\\] \\[\nE = \\frac{\\text{Row total} \\times \\text{Column total}}{\\text{Total sample size}}\n\\]อย่างเช่น expected event สำหรับช่อง \\(\\) คือ \\[\n\\frac{(+ B) \\times (+ C)}{(+ B + C + D)^{2}}(+B+C+D)\n\\]ยกตัวอย่างว่าอยากทราบว่าเพศมีผลต่ออัตราการตายในมะเร็งปอดหรือไม่p < 0.05 หมายความว่าเพศมีผลต่ออัตราการตายอย่างมีนัยสำคัญลองคำนวณเองตามสูตรขั้นต้น","code":"\nlung_ob##         status\n## sex      Alive Dead\n##   Female    37   53\n##   Male      26  112\nlung_chisq <- chisq.test(lung_ob, correct = FALSE)\nlung_chisq## \n##  Pearson's Chi-squared test\n## \n## data:  lung_ob\n## X-squared = 13.511, df = 1, p-value = 0.0002371\nlung_ex <- apply(expand.grid(rowSums(lung_ob), colSums(lung_ob)),1, prod) |> \n  matrix(nrow=2)/sum(lung_ob) # สร้าง expected table\n\nlung_ex##          [,1]     [,2]\n## [1,] 24.86842 65.13158\n## [2,] 38.13158 99.86842\nchi_value <- sum((lung_ob - lung_ex)^2/lung_ex)\nchi_value # chi-squared## [1] 13.51117\npchisq(chi_value, df = lung_chisq$parameter, lower.tail = FALSE) # p-value## [1] 0.000237147"},{"path":"non-parametric-test.html","id":"fisher","chapter":"10 Non-parametric test","heading":"10.1.2 Fisher’s exact test","text":"คือการทดสอบว่าข้อมูลนั้นมีความสัมพันธ์หรือไม่ โดยการเทียบกับความสัมพันธ์แบบสุ่ม การทดสอบนี้จะมีความแม่นยำกว่า chi-square เนื่องจากเป็นการคำนวณความน่าจะเป็นโดยตรง\\[\np = \\frac{{+B \\choose }{C+D \\choose C}}{{n \\choose +C}} = \\frac{{+B \\choose B}{C+D \\choose D}}{{n \\choose B+D}}\n\\]พิจารณาสูตร จุดประสงค์คือ การคำนวณความน่าจะเป็นของการหยิบสุ่มแบบไม่คืนให้ได้ตาม condition ที่ต้องการนั่นเองp < 0.05 หมายความว่าเพศมีผลต่ออัตราการตายอย่างมีนัยสำคัญ สังเกตว่า p จะมากกว่า chi-square เนื่องจากการทดสอบนี้มีความ conservative กว่าลองคำนวณเองตามสูตรขั้นต้นปล. การใช้ lung_ob[1] - 1 นั้นมีที่มาจากว่า เมื่อใช้ lower.tail = TRUE จะคำนวณโอกาสที่ ได้ \\(P[X > x]\\) ซึ่งเราต้องการ \\(P[X \\geq x]\\) จึงต้อง ลบ condition ที่ต้องการออกด้วย","code":"\nfisher.test(lung_ob, alternative = \"two.sided\")## \n##  Fisher's Exact Test for Count Data\n## \n## data:  lung_ob\n## p-value = 0.0004349\n## alternative hypothesis: true odds ratio is not equal to 1\n## 95 percent confidence interval:\n##  1.583762 5.727861\n## sample estimates:\n## odds ratio \n##   2.991585\nalive_dead <- colSums(lung_ob)\nalive_dead # total alive and dead## Alive  Dead \n##    63   165\nmale_female <- rowSums(lung_ob)\nmale_female # total male and female## Female   Male \n##     90    138\nfisher_p <- (choose(alive_dead[1], lung_ob[1]-1)*choose(alive_dead[2], lung_ob[3])/\n               (choose(sum(lung_ob), male_female[1])))\n\nunname(fisher_p)*2 # remove name## [1] 0.0004388966\n## or\n2*(phyper(lung_ob[1]-1,alive_dead[1], \n       alive_dead[2], male_female[1],lower.tail=FALSE))## [1] 0.0004635661"},{"path":"non-parametric-test.html","id":"rank-test","chapter":"10 Non-parametric test","heading":"10.2 Rank test","text":"เป็นการหาความต่างของลำดับ แทนที่จะหาความต่างของ mean/variance ในภาวะที่ไม่ทราบการกระจายตัวของข้อมูลที่ชัดเจน","code":""},{"path":"non-parametric-test.html","id":"test-for-normality","chapter":"10 Non-parametric test","heading":"10.2.1 Test for normality","text":"กลับมาที่ตัวอย่าง iris ดูการกระจายของข้อมูลพิจารณาแล้ว Petal.Width ไม่น่าจะใช่ normal distribution จะทำการทดสอบต่อโดย shapiro.test() ซึ่งเป็นการทดสอบการกระจายตัวของข้อมูลว่าหลุดออกจาก normal distribution หรือไม่จะเห็นว่า Petal.Width มี p < 0.05 พอสมควร (ไม่เป็น normal distribution) จึงสมควรใช้ non-parametric test","code":"\n  ggplot(long_df, aes(x = cm, fill = Metrics)) + geom_histogram() +\n  facet_grid(Metrics~Species, scales = \"free\") +\n  theme_bw()\nlong_df |> \n  group_by(Metrics, Species) |> \n  summarise(normality = round(shapiro.test(cm)$p.value, 4))"},{"path":"non-parametric-test.html","id":"wilcox-rs","chapter":"10 Non-parametric test","heading":"10.2.2 Wilcoxon’s rank sum test (Mann-Whitney U test)","text":"คือ การคำนวณว่ากลุ่มตัวอย่าง 2 กลุ่มนั้นมาจากประชากรกลุ่มเดียวกันหรือไม่ จากการพิจารณาผลรวมของลำดับข้อมูลทั้งสองกลุ่มลักษณะการใช้คล้าย independent t-test สำหรับ non-normal distribution\\[\nW_{j} = n_{1}n_{2} + \\frac{n_{j}(n_{j}+1)}{2} - R_{n}\n\\]\\[\nW = min(W_{1}, W_{2})\n\\]ลองคำนวณเอง หลักการคือจัดอันดับของข้อมูลโดยเรียงจาก น้อยไปมาก และให้อันดับเป็นตัวเลข (อันดับที่เท่ากัน ให้เป็นค่าเฉลี่ยของลำดับนั้น เช่น อันดับ 2, 3, 4 ที่มีค่าเท่ากัน ให้อันดับเป็น (2+3+4)/3 = 5 ทุกตัว)จัดอันดับของข้อมูลโดยเรียงจาก น้อยไปมาก และให้อันดับเป็นตัวเลข (อันดับที่เท่ากัน ให้เป็นค่าเฉลี่ยของลำดับนั้น เช่น อันดับ 2, 3, 4 ที่มีค่าเท่ากัน ให้อันดับเป็น (2+3+4)/3 = 5 ทุกตัว)คำนวณค่า \\(W\\) โดยแยกกลุ่ม 1 และ กลุ่ม 2 และเลือกค่า \\(W\\) ที่น้อยที่สุดคำนวณค่า \\(W\\) โดยแยกกลุ่ม 1 และ กลุ่ม 2 และเลือกค่า \\(W\\) ที่น้อยที่สุดปล. เมื่อจำนวนตัวอย่าง >50 ค่า \\(W\\) จะเข้าสู่ normal distribution ซึ่งสามารถเปลี่ยนเป็นค่า \\(Z\\) ได้ ส่งผลให้การคำนวณ p-value จะแม่นยำขึ้น\\[\nZ = \\frac{W-m_{w}}{s_{w}}\n\\]\\[\nm_{w} = \\frac{n_{1}n_{2}}{2} = \\text{mean W}\n\\]\\[\ns_{w} = \\sqrt{\\frac{n_{1}n_{2}(n_{1}+n_{2}+1)}{12}}\n\\]","code":"\niris_pw <- df |> \n  select(Petal.Width, Species) |> \n  filter(Species != \"virginica\" )\n\niris_wx <- wilcox.test(Petal.Width~Species, data = iris_pw)\n\niris_wx## \n##  Wilcoxon rank sum test with continuity correction\n## \n## data:  Petal.Width by Species\n## W = 0, p-value < 2.2e-16\n## alternative hypothesis: true location shift is not equal to 0\niris_wx$p.value## [1] 2.284669e-18\niris_pw_rank <- iris_pw |> \n  arrange(`Petal.Width`) |> \n  mutate(Rank = rank(`Petal.Width`, ties.method = \"average\")) # rank all values\n\nsetosa <- split(iris_pw_rank, iris_pw$Species)$setosa\nversicolor <- split(iris_pw_rank, iris_pw$Species)$versicolor\n\nall_combn <- nrow(setosa)*nrow(versicolor)\nall_combn## [1] 2500\nsetosa_rank_sum <- all_combn + (nrow(setosa)*(nrow(setosa)+1))/2 - sum(setosa$Rank)\nsetosa_rank_sum## [1] 2500\nversicolor_rank_sum <- all_combn + (nrow(versicolor)*(nrow(versicolor)+1))/2 - sum(versicolor$Rank)\nversicolor_rank_sum## [1] 0\nW <- min(setosa_rank_sum,versicolor_rank_sum)\nW## [1] 0\n## Normal approximation\nmW <- all_combn/2\nsdW <- sqrt(all_combn*(nrow(setosa)+nrow(versicolor)+1)/12)\nz = (W-mW)/sdW\npval <- 2*pnorm(-abs(z)) \npval # not exactly equal due to tie adjustment in wilcox.test()## [1] 6.856641e-18"},{"path":"non-parametric-test.html","id":"wilcox-sign","chapter":"10 Non-parametric test","heading":"10.2.3 Wilcoxon’s signed-rank test","text":"คือ การคำนวณว่ากลุ่มตัวอย่าง 2 กลุ่มนั้นมาจากประชากรกลุ่มเดียวกันหรือไม่ จากการคำนวณลำดับข้อมูลของทั้งสองกลุ่มลักษณะการใช้คล้าย paired t-test สำหรับ non-normal distribution\\[\nV = \\sum_{=1}^{N_{r}}[sgn(x_{2,} - x_{1,}) \\cdot R_{}]\n\\]\\[\nsgn(x) =\\begin{cases} -1 \\quad \\text{} \\, x < 1,  \\\\0 \\quad \\ \\ \\  \\text{} \\, x = 0,\\\\1 \\quad \\ \\ \\  \\text{} \\, x > 0\\end{cases}\n\\]\\[\nV = min(V_{-}, V_{+})\n\\]สมมติการวัด wound healing assay (วัดการเคลื่อนที่ของเซลล์) ก่อนและหลัง treat ยาลองคำนวณเอง หลักการคือคำนวณความต่างของก่อนและหลัง (หรือคู่เทียบ)คำนวณความต่างของก่อนและหลัง (หรือคู่เทียบ)จัดอันดับของข้อมูลโดยเรียงจาก น้อยไปมาก และให้อันดับเป็นตัวเลข (อันดับที่เท่ากัน ให้เป็นค่าเฉลี่ยของลำดับนั้น เช่น อันดับ 2, 3, 4 เท่ากัน ให้อันดับเป็น (2+3+4)/3 = 5 ทุกตัวแปร)จัดอันดับของข้อมูลโดยเรียงจาก น้อยไปมาก และให้อันดับเป็นตัวเลข (อันดับที่เท่ากัน ให้เป็นค่าเฉลี่ยของลำดับนั้น เช่น อันดับ 2, 3, 4 เท่ากัน ให้อันดับเป็น (2+3+4)/3 = 5 ทุกตัวแปร)คำนวณค่า \\(V\\) โดยแยกเครื่องหมาย + และ - และเลือกค่า \\(V\\) ที่น้อยที่สุดคำนวณค่า \\(V\\) โดยแยกเครื่องหมาย + และ - และเลือกค่า \\(V\\) ที่น้อยที่สุด","code":"\nset.seed(123)\n\ntreat <- data.frame(sample = 1:20,\n  Before = runif(20, min = 400, max = 500),\n           After = detectnorm::rnonnorm(20, mean = 400, sd = 30, skew = 10, kurt = 5)$dat)\n\nhead(treat, 10)\nwilcox.test(treat$Before, treat$After, paired = TRUE, exact = TRUE)## \n##  Wilcoxon signed rank exact test\n## \n## data:  treat$Before and treat$After\n## V = 169, p-value = 0.01531\n## alternative hypothesis: true location shift is not equal to 0\ntreat_rank <- treat |> mutate(Diff = Before-After) |> \n                mutate(Absdiff = abs(Diff)) |> \n                mutate(Rank = rank(Absdiff, ties.method = \"average\")) \ntreat_rank\nsign_rank <- treat_rank |> group_by(sign(Diff)) |> \n              summarize(rank_sum = sum(Rank))\n\nV <- min(sign_rank$rank_sum)\nV## [1] 41\npval <- psignrank(V, 20,20)*2\npval## [1] 0.01531219"},{"path":"non-parametric-test.html","id":"kruskal-wallis-test","chapter":"10 Non-parametric test","heading":"10.2.4 Kruskal-Wallis test","text":"คือ การเปรียบเทียบค่าเฉลี่ยของลำดับว่ามาจากประชากรเดียวกันหรือไม่ ลักษณะการใช้เช่นเดียวกับ ANOVA\\[\nH = (N-1)\\frac{\\sum^{g}_{=1}n_{}(\\bar{r_{}}-\\bar{r})^{2}}{\\sum^{g}_{=1}\\sum^{n_{}}_{j=1}(r_{ij}-\\bar{r})^{2}}\n\\]ลองคำนวณเอง หลักการการจัดอันดับเหมือน Wilcoxon’s rank sum test","code":"\niris_pw_all <- df |> \n               select(Petal.Width, Species) # 3 groups\n\niris_kw <- kruskal.test(Petal.Width ~ Species, data = iris_pw_all)\niris_kw$p.value## [1] 3.261796e-29\niris_pw_all_ranked <- iris_pw_all |> arrange(`Petal.Width`) |> \n                        mutate(Rank = rank(`Petal.Width`, ties.method = \"average\"))\niris_pw_all_ranked\naverage_rank <- mean(iris_pw_all_ranked$Rank) # also = (nrow(iris_pw_all_ranked)+1)/2\naverage_rank## [1] 75.5\nbetween_group_var <- iris_pw_all_ranked |>\n                  group_by(Species) |> \n                   summarise(rank_var = ((mean(Rank) - average_rank)^2)*n())\nbetween_group_var\nwithin_group_var <- iris_pw_all_ranked |> \n                    mutate(rank_var = (Rank-average_rank)^2)\nwithin_group_var\nH <- ((nrow(iris_pw_all_ranked)-1))*sum(between_group_var$rank_var)/sum(within_group_var$rank_var)\nH## [1] 131.1854\npval <- pchisq(H, 2, lower.tail = FALSE)\npval## [1] 3.261796e-29"},{"path":"non-parametric-test.html","id":"correlation-test-1","chapter":"10 Non-parametric test","heading":"10.3 Correlation test","text":"","code":""},{"path":"non-parametric-test.html","id":"spearmans-correlation","chapter":"10 Non-parametric test","heading":"10.3.1 Spearman’s correlation","text":"เป็นการทดสอบความสัมพันธ์ในทิศทางของตัวแปรสองตัวแปรว่าเป็นไปในทางเดียวกันหรือไม่ (monotonic relationship)\\[ \\rho_{xy} =\\frac{cov(x,y)}{s(x) s(y)} \\]\\[\n\\rho_{xy} = \\frac{\\sum^{n}_{=1}(x_{}-\\bar{x})(y_{}-\\bar{y})}{\\sqrt{\\sum^{n}_{=1}(x_{}-\\bar{x})^{2}}\\sqrt{\\sum^{n}_{=1}(y_{}-\\bar{y})^{2}}}\n\\]โดย \\(x, y\\) คือ ลำดับของข้อมูล (ไม่ใช่ตัวข้อมูลเอง) ส่งผลให้การทดสอบนี้ เป็นการทดสอบการเพิ่มขึ้นของลำดับ ไม่ใช่การเพิ่มขึ้นของข้อมูล ดังนั้น จึงไม่ใช่การทดสอบความสัมพันธ์เป็นเชิงเส้นเหมือน Pearson’s correlation แต่เป็นการทดสอบเพียงว่าข้อมูลไปในทิศทางเดียวันหรือไม่การทดสอบใน R ใช้ลักษณะ code เดียวกันกับ Pearson’s correlation แต่เปลี่ยน argument เป็น method = \"pearson\" และข้อควรระวังก็คิดเหมือนกัน","code":"\npoly_data <- data.frame(x = seq(-10, 10, length.out = 100)) |> \n  mutate(y = x^9+x+10+rnorm(100, mean = 0, sd =3))\n\nggplot(poly_data, aes(x=x,y=y)) + geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw()\ncor(poly_data$x, poly_data$y, method = \"pearson\") # not quite linear## [1] 0.6870804\ncor(poly_data$x, poly_data$y, method = \"spearman\") # monotonic## [1] 0.9993399"},{"path":"regression-model.html","id":"regression-model","chapter":"11 Regression model","heading":"11 Regression model","text":"Regression model คือการสร้างสมการถดถอยของความสัมพันธ์ระหว่าง 2+ ตัวแปร โดยประกอบไปด้วยตัวแปรต้น (independent variable, \\(x\\)) คือ ตัวแปรที่เป็นต้นเหตุตัวแปรต้น (independent variable, \\(x\\)) คือ ตัวแปรที่เป็นต้นเหตุตัวแปรตาม (dependent variable, \\(y\\)) คือ ตัวแปรที่เป็นปลายเหตุ ซึ่งเป็นผลมาจากการเปลี่ยนแปลงของตัวแปรต้นตัวแปรตาม (dependent variable, \\(y\\)) คือ ตัวแปรที่เป็นปลายเหตุ ซึ่งเป็นผลมาจากการเปลี่ยนแปลงของตัวแปรต้นความสัมพันธ์ของตัวแปรต้นและตัวแปรตามจะเขียนในรูปแบบ \\(f(x) \\sim x\\)","code":""},{"path":"regression-model.html","id":"linear-regression","chapter":"11 Regression model","heading":"11.1 Linear regression","text":"","code":""},{"path":"regression-model.html","id":"model-summary","chapter":"11 Regression model","heading":"11.1.1 Model summary","text":"คือ การสร้างความสัมพันธ์ของตัวแปรแบบเชิงเส้น ใช้กับข้อมูลแบบต่อเนื่อง (continuous data)\\[\nh_{\\theta}(x) = \\theta_{0} + \\theta_{1}x_{1} + \\theta_{2}x_{2} + \\ …  \\ + \\theta_{n}x_{n} + \\epsilon\n\\]ในการวัดความแม่นยำของ linear regression นั้นประกอบด้วยสามองค์ประกอบ\\[\n\\text{Total variation} = \\text{Explained variation} + \\text{Unexplained variation/Error}\n\\]\\[\n\\text{Total sum squares} \\ (TSS) = \\text{Sum squares regression} \\ (SSR) + \\text{Sum squares error} \\ (SSE)\n\\]\\[\n\\sum^{n}_{=1}(y_{}-\\bar{y}_{})^{2} = \\sum^{n}_{=1}(\\hat{y}_{}-\\bar{y}_{})^{2} + \\sum^{n}_{=1}(y_{}-\\hat{y}_{})^{2}\n\\]\\(TSS\\) = Total variation = ค่าความผันผวนระหว่างข้อมูลกับค่าเฉลี่ยของข้อมูล\\(TSS\\) = Total variation = ค่าความผันผวนระหว่างข้อมูลกับค่าเฉลี่ยของข้อมูล\\(SSR\\) = Explained variation = ค่าความผันผวนระหว่างค่าเฉลี่ยของข้อมูลกับเส้น regression\\(SSR\\) = Explained variation = ค่าความผันผวนระหว่างค่าเฉลี่ยของข้อมูลกับเส้น regression\\(SSE\\) = Error = ค่าความผันผวนระหว่างข้อมูลกับเส้น regression\\(SSE\\) = Error = ค่าความผันผวนระหว่างข้อมูลกับเส้น regression\\(R^{2}\\) คือ อัตราส่วนระหว่าง Explained variation กับ Total variation = \\(\\frac{SSR}{TSS} = 1-\\frac{SSE}{TSS}\\) ซึ่งจะบ่งบอกความสามารถของเส้นถดถอย ในการอธิบายข้อมูล (goodness fit)\\(F\\)-test คือการเปรียบเทียบความสามารถของเส้นถดถอย ว่าสามารถอธิบายข้อมูลได้ดีกว่า \\(H_{0}\\) อย่างมีนัยสำคัญหรือไม่ ภายใต้สมมติฐาน\\(H_{0}\\): \\(f(x) = \\theta_{0} + c\\) หรือ สามารถอธิบายข้อมูลได้โดยใช้แค่ค่าเฉลี่ย\\(H_{0}\\): \\(f(x) = \\theta_{0} + c\\) หรือ สามารถอธิบายข้อมูลได้โดยใช้แค่ค่าเฉลี่ย\\(H_{}\\): \\(f(x) = \\theta_{0} + x_{1}\\theta_{1} + … + \\epsilon\\)\\(H_{}\\): \\(f(x) = \\theta_{0} + x_{1}\\theta_{1} + … + \\epsilon\\)ซึ่งเป็นการเทียบอัตราส่วน explained กับ unexplained variation เช่นเดียวกับ ANOVA\\[F =\\frac{MSR}{MSE} = \\frac{TSS-SSE}{SSE}/\\frac{DF_{TSS}-DF_{SSE}}{DF_{SSE}}\\]\\(t\\)-test คือการเปรียบเทียบเส้น regression เมื่อมีตัวแปรนั้น ว่าอธิบายได้ดีกว่าเมื่อไม่มีตัวแปรนั้นหรือไม่\\(H_{0}\\): \\(\\theta = 0\\)\\(H_{0}\\): \\(\\theta = 0\\)\\(H_{}\\): \\(\\theta \\neq 0\\)\\(H_{}\\): \\(\\theta \\neq 0\\)จะเห็นว่าสมการนั้นเหมือน One-sample t-test แต่เขียนในรูปแบบ regression\\[\nt = \\frac{\\theta-\\theta_{0}}{SE(\\theta)}\n\\]\\[\nSE(\\theta) = \\sqrt{\\frac{1}{n-2} \\times {\\sum_{=1}^{n}\\frac{(y_{} - \\hat{y_{}})^2}{(x_{} - \\hat{x_{}})^2}}}\n\\]","code":"\ndata(\"Diabetes\", package = \"heplots\")\n\nggplot(Diabetes, aes(x = glufast, y = sspg)) + \n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  theme_bw()## \n## Call:\n## lm(formula = sspg ~ glufast, data = Diabetes)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -197.030  -59.050   -0.371   68.950  142.060 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  39.4534    13.3348   2.959  0.00362 ** \n## glufast       1.1866     0.0969  12.247  < 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 74.33 on 143 degrees of freedom\n## Multiple R-squared:  0.5119, Adjusted R-squared:  0.5085 \n## F-statistic:   150 on 1 and 143 DF,  p-value: < 2.2e-16\ndiabetes_fit <- lm(sspg ~ glufast, data = Diabetes) \nsummary(diabetes_fit)## \n## Call:\n## lm(formula = sspg ~ glufast, data = Diabetes)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -197.030  -59.050   -0.371   68.950  142.060 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  39.4534    13.3348   2.959  0.00362 ** \n## glufast       1.1866     0.0969  12.247  < 2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 74.33 on 143 degrees of freedom\n## Multiple R-squared:  0.5119, Adjusted R-squared:  0.5085 \n## F-statistic:   150 on 1 and 143 DF,  p-value: < 2.2e-16"},{"path":"regression-model.html","id":"prediction","chapter":"11 Regression model","heading":"11.1.2 Prediction","text":"ข้อดีของสมการถอดถอย คือ สามารถใช้ในการทำนายข้อมูลตัวแปรตามชุดใหม่ได้ จากผลลัพธ์ขั้นต้นในคอลัมน์ coef พบว่าทุกๆ glufast ที่เพิ่มขึ้น 1.186 หน่วย ส่งผลให้ sspg เพิ่มขึ้น 1 หน่วย ซึ่งเขียนเป็นสมการได้ว่า\\[\nf(x) = 39.4354 \\ + 1.1866\\times(\\text{glufast}) + \\epsilon\n\\]โดยสมการนี้จะอยู่ใน diabetes_fit","code":"\nnew_sspg <- data.frame(glufast = 1:400) \nnew_sspg <- new_sspg |> \n  mutate(predicted_sspg = predict(diabetes_fit, newdata = new_sspg))\n\nggplot(new_sspg, aes(x = glufast, y = predicted_sspg)) +\n  geom_point(size = 0.3) + theme_bw()"},{"path":"regression-model.html","id":"logistic-regression","chapter":"11 Regression model","heading":"11.2 Logistic regression","text":"คือ สมการถดถอยซึ่งมีคุณสมบัติในการจำแนกตัวแปรแบบสองตัวแปร (binary classification) ซึ่งเขียนอยู่ในรูปของ ค่าลอการิธึมของอัตราส่วนความเสี่ยง (log odds)\\[\nlog(\\frac{h(x)}{1-h(x)}) = \\theta_{0} + x_{1}\\theta_{1} + x_{2}\\theta_{2} + \\ ... \\ + x_{n}\\theta_{n} + \\epsilon = z\n\\]\\[\n\\frac{h(x)}{1-h(x)} = e^{z}\n\\]\\[\nh(x) = \\frac{1}{1+e^{z}}\n\\]\\[\nh(x) = \\frac{1}{1+e^{\\theta_{0} + x_{1}\\theta_{1} + x_{2}\\theta_{2} + \\ ... \\ + x_{n}\\theta_{n} + \\epsilon}}\n\\]ความพิเศษของสมการนี้คือ ขอบเขตของ \\(h(x)\\) จะอยู่ระหว่าง (0, 1) เสมอ ซึ่งส่งผลให้สามารถคำนวณกลับไปทำนายอัตราการเกิดเหตุการณ์จากอัตราส่วนความเสี่ยงได้ต่อไปเราจะทำนายว่า glufast เพื่อให้ตัวแปรเป็น binary เราจะรวม Overt_Diabetic และ Chemical_Diabetic เป็นกลุ่มเดียวกัน","code":"\nlog_df <- data.frame(x = -20:20) |> mutate(y = 1/(1+exp(0 + 0.75*x)))\nggplot(log_df, aes(x = x, y = y)) + geom_line() + theme_bw() +\n  labs(y = \"h(x)\")\nDiabetes_mixed <- Diabetes |> mutate(group = \n                                       case_match(group,\n                                                  \"Normal\" ~ 0,\n                                                  \"Chemical_Diabetic\" ~ 1,\n                                                  \"Overt_Diabetic\" ~ 1))\n\nggplot(Diabetes_mixed, aes(x = glufast, y = group)) + \n  geom_point() +\n  geom_smooth(method = \"glm\",  method.args = list(family = \"binomial\"), \n              se = FALSE) +\n  theme_bw()\nlogit_fit <- glm(group ~ glufast, family = \"binomial\", \n                 data = Diabetes_mixed) \nlogit_fit## \n## Call:  glm(formula = group ~ glufast, family = \"binomial\", data = Diabetes_mixed)\n## \n## Coefficients:\n## (Intercept)      glufast  \n##    -11.7611       0.1158  \n## \n## Degrees of Freedom: 144 Total (i.e. Null);  143 Residual\n## Null Deviance:       200.7 \n## Residual Deviance: 121.9     AIC: 125.9\nnew_group <- data.frame(glufast = 1:200) \nnew_group <- new_group |> \n  mutate(predicted_group = predict(logit_fit, \n                                   newdata = new_group, type = \"response\"))\n\nggplot(new_group, aes(x = glufast, y = predicted_group)) +\n  geom_point() + theme_bw()"},{"path":"regression-model.html","id":"poisson-quassipoisson-and-negative-binomial-regression","chapter":"11 Regression model","heading":"11.3 Poisson, quassipoisson, and negative binomial regression","text":"Poission regression คือ สมการถดถอยที่ใช้ในการทำนายความถี่ หรือค่าเฉลี่ยของการเกิดเหตุการณ์นั้นๆ มักใช้กับข้อมูลที่ไม่ต่อเนื่อง (discrete value) พิจารณาข้อมูลแบบ Poisson distribution\\[\nf(k) = P(X = k) = \\frac{\\lambda^{k}}{k!}e^{-\\lambda}\n\\]จะพบว่ามีตัวแปรที่สามารถทำนายได้เมื่อมีข้อมูลอีกชนิดหนึ่ง คือ ค่าเฉลี่ยการเกิดเหตุการณ์ \\((\\lambda)\\) และ จำนวนเหตุการณ์ที่เกิด \\((k)\\) จึงออกมาเป็นสมการถดถอยได้สองรูปแบบสำหรับ \\(\\lambda\\)\\[\n\\lambda = e^{\\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2}+…+\\theta_{n}x_{n}}\n\\]\\[\nln(\\lambda) = \\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2}+…+\\theta_{n}x_{n}\n\\]สำหรับ \\(k\\) เราจำเป็นต้องเปลี่ยน \\(\\lambda\\) ให้อยู่ในรูป \\(k/t\\) และย้ายไปเป็นตัวแปรควบคุมเวลา (offset) ซึ่งจะมี regression coefficient = 1 เสมอ\\[ \\lambda = \\frac{k}{t} = e^{\\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2}+…+\\theta_{n}x_{n}} \\]\\[ ln(k) - \\ln(t) = \\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2}+…+\\theta_{n}x_{n} \\]\\[\nln(k) =  \\theta_{0}+\\theta_{1}x_{1}+\\theta_{2}x_{2}+…+\\theta_{n}x_{n} + \\ln(t) \\rightarrow  \\text{offset}\n\\]ซึ่งสมการนี้เป็นสมการพื้นฐานของการนับจำนวนใดๆ ดังเช่นตัวอย่างนี้ คือความสัมพันธ์ระหว่างจำนวนครั้งที่เจ็บป่วยกับการเข้าพบแพทย์ในสองสัปดาห์ ในประเทศออสเตรเลียอย่างไรก็ตาม Poisson regression มีสมมติฐานที่สำคัญตาม Poisson distribution คือต้องเป็นจำนวนนับVariance = Meanซึ่งข้อมูลบางส่วนจะไม่เป็นไปตามสมมติฐานนี้ โดยจะนิยมใช้ Quassipoisson regression\\[\nV = \\phi\\times\\mu\n\\]\n\\[\n\\phi = \\frac{\\chi^{2}}{\\text{DF}} = \\frac{1}{n-k}{\\sum_{=1}^{n}\\frac{(Y_{}-\\hat{\\mu_{}})^{2}}{\\hat{\\mu_{}}}}\n\\]หรือ Negative binomial regression มากกว่า","code":"\ndata(\"DoctorVisits\", package = \"AER\")\n\nglm(visits ~  illness, family = \"poisson\", data = DoctorVisits) |> summary()## \n## Call:\n## glm(formula = visits ~ illness, family = \"poisson\", data = DoctorVisits)\n## \n## Coefficients:\n##             Estimate Std. Error z value Pr(>|z|)    \n## (Intercept) -1.83750    0.04300  -42.73   <2e-16 ***\n## illness      0.35155    0.01546   22.74   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for poisson family taken to be 1)\n## \n##     Null deviance: 5634.8  on 5189  degrees of freedom\n## Residual deviance: 5159.3  on 5188  degrees of freedom\n## AIC: 7494.9\n## \n## Number of Fisher Scoring iterations: 6\nggplot(DoctorVisits, aes (x = illness, y = visits)) +\n  geom_jitter() +\n  geom_smooth(method = \"glm\", method.args = list(family = \"poisson\"), se = FALSE) +\n  scale_x_continuous(breaks = 0:5) +\n  scale_y_continuous(breaks = 0:9) +\n  theme_bw()"},{"path":"survival-analysis.html","id":"survival-analysis","chapter":"12 Survival analysis","heading":"12 Survival analysis","text":"ในงานวิจัยที่กระทำกับผู้ป่วย หรือแม้กระทั้งเซลล์นั้น บางครั้งจะมีความจำเป็นที่ต้องทำการวิเคราะห์ข้อมูลเพื่อเปรียบเทียบสร้างแบบจำลองที่สามารถทำนายเวลาที่ใช้ก่อนที่จะเกิดเหตุการณ์ที่ท่านสนใจ (event) เช่น เวลาที่ผู้ป่วยจะเสียชีวิตจากโรคมะเร็งนับตั้งแต่วันวินิจฉัย เวลาของเซลล์ที่จะตายหลังจากใส่สารบางอย่างที่สนใจ เป็นต้นลักษณะพิเศษของการวิเคราะห์ survival analysis คือ มีการวิเคราะห์โดยใช้ปัจจัยที่เรียกว่า censoring ร่วม ซึ่งคือการที่ เหตุการณ์ที่คาดหวังว่าจะเกิดนั้นไม่มาถึงแม้ว่าจะครบตามเวลาที่ผู้วิจัยสังเกตการณ์แล้ว ซึ่งทำให้ไม่สามารถมั่นใจได้ว่าเหตุการณ์นั้นจะเกิดต่อไปหรือไม่ ณ เวลาหลังจากนี้การ censor โดยหลักมี 3 แบบ คือRight-censor (ดังรูป) คือ ไม่แน่ใจข้อมูลการเกิด event เวลาสุดท้ายที่พบ ซึ่งพบมมากที่สุดRight-censor (ดังรูป) คือ ไม่แน่ใจข้อมูลการเกิด event เวลาสุดท้ายที่พบ ซึ่งพบมมากที่สุดLeft-censor คือ ไม่แน่ใจข้อมูลช่วงเวลาเริ่มต้น เช่น diagnosis วันไหนLeft-censor คือ ไม่แน่ใจข้อมูลช่วงเวลาเริ่มต้น เช่น diagnosis วันไหนInterval-censor คือ เวลาช่วงใดช่วงหนึ่งหายไปInterval-censor คือ เวลาช่วงใดช่วงหนึ่งหายไป","code":""},{"path":"survival-analysis.html","id":"kaplein-meir-estimate","chapter":"12 Survival analysis","heading":"12.1 Kaplein-Meir estimate","text":"Kaplein-Meir estimate (KM) คือกราฟแสดงอัตราการเกิดของเหตุการณ์เมื่อเทียบกับเวลาที่ผ่านไป โดยหลักการคำนวณ survival คือ\\[ \\hat{S}(t) = \\prod_{: t_{} \\leq t}(1- \\frac{d_{}}{n_{}})\\]\\[\n\\text{Survival proability} = \\frac{n.risk - n.event}{n.risk}\n\\]อธิบายหลักการอย่างง่ายของ KM นั่นคือ ทุกเคสทียังไม่เกิดเหตุการณ์นั้น จะเป็น “เคสที่เสี่ยงต่อการเกิดเหตุการณ์ (risk)” ซึ่งจำนวนเคสแรกเริ่มที่เสี่ยง (number risk) จะเท่ากับจำนวนเคสทั้งหมด (sample size) โดยจะนับการเกิด event ตามปกติ เพียงแต่ถ้าเคสนั้นถูก censor นั้น n.risk จะลดลงด้วย ทำให้อัตราการเกิด event ยังไม่เปลี่ยนแปลง ดังตัวอย่างตามตารางเมื่อนำไปพล็อตกราฟแล้วจะได้ผลดังนี้สังเกตุว่าส่วนที่ censor (มีสัญลักษณ์ +) จะไม่มีการตกลงของกราฟ แต่เมื่อถึงเวลาที่มี event เกิดขึ้น การตกลงของกราฟจะสูงกว่าเมื่อไม่มี censor นำมาก่อน","code":""},{"path":"survival-analysis.html","id":"การสราง-km-ใน-r","chapter":"12 Survival analysis","heading":"12.1.1 การสร้าง KM ใน R","text":"ตัวอย่างข้อมูลของผู้ป่วยมะเร็งรังไข่ที่ได้รับการรักษาโดยการผ่าตัดอธิบายตัวแปร:age = อายุage = อายุfutime = ระยะเวลาติดตามตั้งแต่วินิจฉัยจนเสียชีวิต/มาพบแพทย์ครั้งสุดท้ายfutime = ระยะเวลาติดตามตั้งแต่วินิจฉัยจนเสียชีวิต/มาพบแพทย์ครั้งสุดท้ายfustat = 0 - censor, 1 - deadfustat = 0 - censor, 1 - deadresid.ds = มีชิ้นส่วนของมะเร็งหลงเหลือหลังจากการผ่าตัด (ผ่าตัดได้ไม่หมด)resid.ds = มีชิ้นส่วนของมะเร็งหลงเหลือหลังจากการผ่าตัด (ผ่าตัดได้ไม่หมด)rx = กลุ่มการรักษาrx = กลุ่มการรักษาecog.ps = ECOG performance status คะแนนน้อยแปลว่าผู้ป่วยมีสุขภาพโดยรวมดีecog.ps = ECOG performance status คะแนนน้อยแปลว่าผู้ป่วยมีสุขภาพโดยรวมดีเมื่อใช้ function Surv() จะทำการเปลี่ยน futime ให้รับรู้การ censor สังเกตว่าผู้ป่วยที่ ไม่เกิดเหตุการณ์จะมีสัญลักษณ์ + อยู่ข้างหลัง บ่งบอกว่าข้อมูลนั้นถูก censor นั่นหมายความว่า ผู้ป่วยจะเกิดเหตุการณ์หรือไม่ก็ได้หลังจากนี้ เพียงแต่ผู้วิจัยไม่สามารถทราบได้แล้วการพล็อต KM นั้นสามารถทำได้โดยใช้ package survminer โดยเริ่มจากการสร้างตาราง survival curve จากคำสั่ง survfit()หลังจากนั้นใช้คำสั่ง ggsurvplot() เพื่อทำการสร้างกราฟจะเห็นว่าผู้ป่วยกลุ่มนี้มี median survival อยู่ประมาณ 1.75 ปีจะพบว่า ถ้าผ่าตัดแล้วไม่เหลือร่องรอยของโรค จะมีอัตราการรอดชีวิตที่ดีกว่า แต่ยังไม่ถึงระดับมีนัยสำคัญ","code":"\nlibrary(dplyr) \nlibrary(survival)\nnames(ovarian)## [1] \"futime\"   \"fustat\"   \"age\"      \"resid.ds\" \"rx\"       \"ecog.ps\"\novarian |> mutate(age_group = cut(age, seq(0,100,10))) |> \n  group_by(age_group) |> count(fustat) |> filter(fustat==1) |> \n  glm(n~age_group, family = \"poisson\", data = _) |> summary()## \n## Call:\n## glm(formula = n ~ age_group, family = \"poisson\", data = filter(count(group_by(mutate(ovarian, \n##     age_group = cut(age, seq(0, 100, 10))), age_group), fustat), \n##     fustat == 1))\n## \n## Coefficients:\n##                   Estimate Std. Error z value Pr(>|z|)\n## (Intercept)      4.676e-11  1.000e+00   0.000    1.000\n## age_group(50,60] 1.609e+00  1.095e+00   1.469    0.142\n## age_group(60,70] 1.099e+00  1.155e+00   0.951    0.341\n## age_group(70,80] 1.099e+00  1.155e+00   0.951    0.341\n## \n## (Dispersion parameter for poisson family taken to be 1)\n## \n##     Null deviance:  2.9110e+00  on 3  degrees of freedom\n## Residual deviance: -4.4409e-16  on 0  degrees of freedom\n## AIC: 19.464\n## \n## Number of Fisher Scoring iterations: 3\nglm(fustat ~ age + resid.ds + offset(log(futime)), family = \"poisson\", data = ovarian) |> summary()## \n## Call:\n## glm(formula = fustat ~ age + resid.ds + offset(log(futime)), \n##     family = \"poisson\", data = ovarian)\n## \n## Coefficients:\n##              Estimate Std. Error z value Pr(>|z|)    \n## (Intercept) -14.17523    2.08156  -6.810 9.77e-12 ***\n## age           0.10234    0.03502   2.922  0.00347 ** \n## resid.ds      0.73279    0.71520   1.025  0.30556    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for poisson family taken to be 1)\n## \n##     Null deviance: 35.691  on 25  degrees of freedom\n## Residual deviance: 22.070  on 23  degrees of freedom\n## AIC: 52.07\n## \n## Number of Fisher Scoring iterations: 6\nggplot(ovarian, aes(x = age, y = fustat)) + geom_point() +\n  geom_smooth(method = \"glm\", method.args = list(family = \"poisson\"),\n              formula = y~x)\ncensored_df <- ovarian |>    \n  mutate(censored_futime = Surv(ovarian$futime, ovarian$fustat)) \n\nhead(select(censored_df, futime, fustat, censored_futime))\nlibrary(survminer)\n\novarian_surv <- survfit(\n  Surv(futime/365.25, fustat) ~ 1, data = ovarian # เปลี่ยนเป็นปี\n  )\n\novarian_surv |> tidy() |> head(10)\nggsurvplot(ovarian_surv, risk.table = TRUE, break.time.by = 0.25, \n           surv.median.line = \"hv\") \novarian_surv_resid <- survfit(\n  Surv(futime/365.25, fustat) ~ resid.ds, data = ovarian\n  )\n\nggsurvplot(ovarian_surv_resid, risk.table = TRUE, break.time.by = 0.25,\n           surv.median.line = \"hv\", pval = TRUE)"},{"path":"survival-analysis.html","id":"log-rank-test","chapter":"12 Survival analysis","heading":"12.2 Log-rank test","text":"Log-rank test คือ non-parametric test สำหรับ univariate analysis ที่เปรียบเทียบความแตกต่างของอัตราการเกิด event ว่าแตกต่างอย่างมีนัยสำคัญหรือไม่Observed คือ จำนวน event ที่เกิดขึ้นในแต่ละกลุ่มObserved คือ จำนวน event ที่เกิดขึ้นในแต่ละกลุ่มExpected คือ จำนวน event ที่คาดว่าจะเกิดขึ้นในแต่ละกลุ่มExpected คือ จำนวน event ที่คาดว่าจะเกิดขึ้นในแต่ละกลุ่ม(O-E)^2/E = Chi-square statistics ของค่า observed และ expected(O-E)^2/E = Chi-square statistics ของค่า observed และ expectedChisq = ผลสุดท้ายของ Chi-square statistics = sum(O-E)^2/EChisq = ผลสุดท้ายของ Chi-square statistics = sum(O-E)^2/Ep = p-value ของ Chi-square statisticsp = p-value ของ Chi-square statisticsค่า log-rank นี้ สามารถแสดงใน KM ได้โดยใช้ pval = TRUE ตามหัวข้อเบื้องต้น","code":"\novarian_surv_diff <- survdiff(\n  Surv(futime/365.25, fustat) ~ resid.ds, data = ovarian\n  )\n\novarian_surv_diff## Call:\n## survdiff(formula = Surv(futime/365.25, fustat) ~ resid.ds, data = ovarian)\n## \n##             N Observed Expected (O-E)^2/E (O-E)^2/V\n## resid.ds=1 11        3     6.26      1.70      3.62\n## resid.ds=2 15        9     5.74      1.85      3.62\n## \n##  Chisq= 3.6  on 1 degrees of freedom, p= 0.06"},{"path":"survival-analysis.html","id":"cox-proportional-hazard-model","chapter":"12 Survival analysis","heading":"12.3 Cox-proportional hazard model","text":"Cox-proportional hazard model (CPH) เป็น semi-parametric model ซึ่งวัด risk ของการเกิด event นั้นๆ โดยมี function คือ\\[\nh(t) = h_{0}(t) \\times exp(b_{1}X_{1} + b_{2}X_{2}+ ... + b_{s}X_{p})\n\\]\\[\nln(\\frac{h(t)}{h_{0}(t)}) = b_{1}X_{1} + b_{2}X_{2}+ ... + b_{s}X_{p}\n\\]ซึ่ง \\(h(t)/h_{0}(t)\\) นั้นคือ hazard ratio (HR) หรือ ความเสี่ยงของการเกิด event นั้นๆการวิเคราะห์ CPH นั้นมีข้อดีกว่า log-rank คือสามารถประมาณการเชิงปริมาณ (quantitative measurement) ผ่าน HR และสามารถวิเคราะห์สมการแบบ multivariate analysis ได้exp(coef) = HR = \\(h(t)/h_{0}(t)\\) ในที่นี้ท่านสามารถอภิปรายได้ว่า อายุที่เพิ่มขึ้น 1 ปีนั้น ส่งผลให้เกิดอัตราการเสียชีวิตในผู้ป่วยมะเร็งรังไข่เพิ่มขึ้น 1.13 เท่า (13%) และมีนัยสำคัญทางสถิติexp(coef) = HR = \\(h(t)/h_{0}(t)\\) ในที่นี้ท่านสามารถอภิปรายได้ว่า อายุที่เพิ่มขึ้น 1 ปีนั้น ส่งผลให้เกิดอัตราการเสียชีวิตในผู้ป่วยมะเร็งรังไข่เพิ่มขึ้น 1.13 เท่า (13%) และมีนัยสำคัญทางสถิติp ในตาราง คือ ค่าคำนวณ p-value จาก Wald’s test ของแต่ละตัวแปรว่ามีผลต่ออัตราการรอดชีวิตหรือไม่p ในตาราง คือ ค่าคำนวณ p-value จาก Wald’s test ของแต่ละตัวแปรว่ามีผลต่ออัตราการรอดชีวิตหรือไม่p ข้างล่าง คือ overall p จาก likelihood ratio test ว่าจากทั้งหมด มีตัวแปรใดตัวแปรหนึ่งส่งผลให้อัตรากการรอดชีวิตเปลี่ยนไปอย่างมีนัยสำคัญทางสถิติหรือไม่p ข้างล่าง คือ overall p จาก likelihood ratio test ว่าจากทั้งหมด มีตัวแปรใดตัวแปรหนึ่งส่งผลให้อัตรากการรอดชีวิตเปลี่ยนไปอย่างมีนัยสำคัญทางสถิติหรือไม่","code":"\novarian_cox <- coxph(Surv(futime/365.25, fustat) ~ \n                       resid.ds + age + factor(rx), data = ovarian) \n\novarian_cox## Call:\n## coxph(formula = Surv(futime/365.25, fustat) ~ resid.ds + age + \n##     factor(rx), data = ovarian)\n## \n##                coef exp(coef) se(coef)      z       p\n## resid.ds     0.6964    2.0065   0.7585  0.918 0.35858\n## age          0.1285    1.1372   0.0473  2.718 0.00657\n## factor(rx)2 -0.8489    0.4279   0.6392 -1.328 0.18416\n## \n## Likelihood ratio test=16.77  on 3 df, p=0.0007889\n## n= 26, number of events= 12"},{"path":"survival-analysis.html","id":"การตรวจสอบ-assumption-validity-ของ-cph","chapter":"12 Survival analysis","heading":"12.3.1 การตรวจสอบ assumption validity ของ CPH","text":"CPH นั้นมี assumption ดังนี้:ตัวแปรแต่ละกลุ่มมีอัตราการเกิด event ที่แตกต่างกันตัวแปรแต่ละกลุ่มมีอัตราการเกิด event ที่แตกต่างกันHR เท่ากันทุกช่วงเวลา เช่น ที่ 1, 2, 5 ปี อัตราส่วนการเสียชีวิตระหว่างตัวแปรเท่ากันหมดHR เท่ากันทุกช่วงเวลา เช่น ที่ 1, 2, 5 ปี อัตราส่วนการเสียชีวิตระหว่างตัวแปรเท่ากันหมดตัวแปรมีความสัมพันธ์แบบ linear continuous variableตัวแปรมีความสัมพันธ์แบบ linear continuous variableไม่จำเป็นต้องทราบลักษณะการกระจายตัวของข้อมูลก่อน (จึงเป็น semi-parametric model)ไม่จำเป็นต้องทราบลักษณะการกระจายตัวของข้อมูลก่อน (จึงเป็น semi-parametric model)สามารถตรวจสอบ HR ได้โดยใช้ proportionality assumption test จาก Schoenfeld residuals โดย cox.zph()โดย test นี้จะทำการเปรียบเทียบ residuals ระหว่าง risk-weight average กับ ตัวแปรนั้นๆ ว่ามีการเปลี่ยนแปลงไปในทิศทางใดทิศทางหนึ่งหรือไม่ ถ้ามี (p < 0.05) หมายความว่า เวลาที่ผ่านไปอาจจะส่งผลให้ HR นั้นมีความแตกต่างกัน ซึ่งจะต้องทำ time-varying CPH เพิ่มเติมโดยในข้อมูล ovarian นี้ ไม่มีตัวใดที่ p-value < 0.05 จึงถือได้ว่า อัตราส่วนนั้นคงที่ และทำให้ CPH นั้น validในส่วนของ linearity สามารถตวจสอบโดยใช้ function ggcoxfunctional()จะเห็นว่า age นั้นการเพิ่มขึ้นแบบ linearity โดยมี deviation เล็กน้อย","code":"\novarian_coxzph <- cox.zph(ovarian_cox) \nggcoxzph(ovarian_coxzph)\novarian_linear_age <- ggcoxfunctional(Surv(futime/365.25, fustat)~  age+                                 + I(log(age)) + I(sqrt(age)), data = ovarian) \novarian_linear_age"},{"path":"distribution.html","id":"distribution","chapter":"13 Distribution","heading":"13 Distribution","text":"","code":""},{"path":"distribution.html","id":"normal-distribution","chapter":"13 Distribution","heading":"13.1 Normal distribution","text":"คือ ลักษณะการกระจายตัวของข้อมูลที่เป็นรูประฆังคว่ำ ซึ่งพบมากสุดในธรรมชาติ\\[\nf(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^{2}}\n\\]\\(Z\\) distribution = standard normal distribution ของประชากร ที่มี \\(\\mu = 0\\), \\(\\sigma = 1\\)สามารถสร้าง \\(Z\\) score ได้จาก\\[\nZ = \\frac{x-\\mu}{\\sigma}\n\\]ค่าของ \\(Z\\)-score ที่พบบ่อย","code":""},{"path":"distribution.html","id":"t-distribution","chapter":"13 Distribution","heading":"13.2 \\(t\\) distribution","text":"Standard distribution ของกลุ่มตัวอย่างที่สุ่มจากประชากร ใช้ใน t-test\\[\nf(t) = \\frac{\\Gamma(\\frac{v+1}{2})}{\\sqrt{v\\pi}\\Gamma(\\frac{v}{2})}(1+\\frac{t^{2}}{v})^{-\\frac{v+1}{2}}\n\\]สามารถสร้าง \\(t\\)-score (\\(t\\) -value ) ได้จาก\\[\nt = \\frac{\\bar{x}-\\mu}{s/\\sqrt{n}}\n\\]หมายเหตุ \\(t\\)-score บางครั้งเป็นคำศัพท์เฉพาะทางEducation assessment \\(\\mu = 50\\), \\(\\sigma = 10\\)Education assessment \\(\\mu = 50\\), \\(\\sigma = 10\\)Bone density เทียบกับผู้ป่วยอายุ 30 ปี \\(\\mu = 0\\), \\(\\sigma = 1\\)Bone density เทียบกับผู้ป่วยอายุ 30 ปี \\(\\mu = 0\\), \\(\\sigma = 1\\)","code":"\nt_dist <- data.frame(x = x, \n                        `DF 1` = dt(x, df = 1),\n                        `DF 2` = dt(x, df = 2),\n                        `DF 4` = dt(x, df = 4),\n                        `DF 8` = dt(x, df = 8)) |> \n  pivot_longer(-x,names_to = \"Param\", values_to  = \"T.distribution\" ) \n\nggplot(t_dist, aes(x = x, y = T.distribution, col = Param)) + \n  geom_line(alpha = 0.8, linewidth = 0.5) +\n  xlim(-4,4) +\n  labs(title = \"t-distribution\", x = \"Values\", y = \"Rate\")"},{"path":"distribution.html","id":"uniform-distribution","chapter":"13 Distribution","heading":"13.3 Uniform distribution","text":"คือ การกระจายตัวของข้อมูลที่อัตราการเกิดเท่าๆ กัน เช่น ทอยลูกเต๋าไม่ถ่วงน้ำหนัก 1 ลูก ดึงไพ่จากสำรับ เป็นต้น\\[\nf(x) = \\begin{cases}\n\\frac{1}{b-} \\ \\text{} \\ \\leq x \\leq b \\\\\n0 \\ \\text{} \\ x<\\ \\text{} \\ x>b\n\\end{cases}\n\\]","code":"\nx <- seq(0,10,1)\n\nunif_dist <- data.frame(x = x, \n                     dice = dunif(x, min = 1 ,max = 6)) |> \n  pivot_longer(-x,names_to = \"Param\", values_to  = \"Uniform.distribution\" ) \n\nggplot(unif_dist, aes(x = x, y = Uniform.distribution)) + \n  geom_point() +\n  geom_segment(col = \"darkblue\", xend = x, yend = 0) +\n  scale_x_continuous(breaks = 0:10, limits = c(0,10)) +\n  labs(title = \"Dice rolls\", x = \"Face\", y = \"Rate\")"},{"path":"distribution.html","id":"binomial-distribution","chapter":"13 Distribution","heading":"13.4 Binomial distribution","text":"คือ การกระจายตัวของโอกาสสำเร็จในการทดลองที่มีผลลัพธ์สองรูปแบบ เช่น หัว/ก้อย ชนะ/แพ้\\[\nf(x,n,p) = P(X = x) = {n\\choose x}p^{x}(1-p)^{n-k}  \n\\]","code":"\n# 20 trials, prob of success = 10% to 90%\nbinom_dist <- map_dfc(c(0.1, 0.3, 0.5, 0.7, 0.9), ~dbinom(1:20, 20, .x)) |> \n  set_names(paste0(\"Prob = \", c(0.1, 0.3, 0.5, 0.7, 0.9) )) |> \n  mutate(numb_success = 1:20) |> \n  pivot_longer(!numb_success, names_to = \"Prob\", values_to = \"rate\") \n\nggplot(binom_dist, aes(x = numb_success, y = rate, col = Prob)) + \n  geom_point(size = 0.8) +\n  geom_line() +\n  scale_x_continuous(breaks = seq(0,21,1), limits = c(0,21)) +\n  labs(x = \"Number of success\", y = \"Rate\")"},{"path":"distribution.html","id":"negative-binomial-distribution","chapter":"13 Distribution","heading":"13.5 Negative binomial distribution","text":"คือ การกระจายของจำนวนครั้งที่ไม่สำเร็จก่อนที่จะได้จำนวนครั้งของการสำเร็จที่ต้องการ\\[\np(k) = {r-1+k \\choose r-1}p^{r-1}(1-p)^{k}p = {r-1+k \\choose k}p^{r}(1-p)^{k}\n\\]","code":"\nnbprob_dist <- map_dfc(c(0.1, 0.3, 0.5, 0.7, 0.9), \\(x) dnbinom(1:20, 20,x)) |> \n  set_names(paste0(\"Prob = \", c(0.1, 0.3,0.5,0.7,0.9) )) |> \n  mutate(numb_failure = 1:20) |> \n  pivot_longer(!numb_failure, names_to = \"Prob\", values_to = \"rate\") \n\nggplot(nbprob_dist, aes(x = numb_failure, y = rate, col = Prob)) + \n  geom_point(alpha = 0.9, size =2) +\n  geom_line() +\n  scale_x_continuous(breaks = seq(0,20,2)) +\n  theme_bw() +\n  labs(x = \"Number of failures\", y = \"Rate\")"},{"path":"distribution.html","id":"hypergeometric-distribution","chapter":"13 Distribution","heading":"13.6 Hypergeometric distribution","text":"คือ การกระจายตัวของโอกาสที่จะสุ่มได้เป้าหมายที่ต้องการจากการหยิบสุ่มแบบใส่คืน (Sampling replacement) ใช้ใน Fisher’s exact test\\[\nf(x,n,M,N) = p(X=x) = \\frac{{M \\choose x}{N-M \\choose n-x}}{N \\choose n}\n\\]","code":"\nhyper_dist <- map_dfc(c(10,20,30), ~dhyper(1:30, .x, 30, 30)) |>  \n  set_names(paste0(\"Black = \", c(10,20,30))) |> \n  mutate(numb_success = 1:30) |> \n  pivot_longer(!numb_success, names_to = \"Pop\", values_to = \"rate\") \n\nggplot(hyper_dist, aes(x = numb_success, y = rate, col = Pop)) + \n  geom_point(size = 0.8) +\n  geom_line() +\n  scale_x_continuous(breaks = seq(0,30,2), limits = c(0,30)) +\n  labs(title = \"Probablity of getting black balls from 30 picks\", \n       x = \"Number of black balls picked\", y = \"Rate\", col = \"Total black balls\\n in the bag\")"},{"path":"distribution.html","id":"poisson-dist","chapter":"13 Distribution","heading":"13.7 Poisson distribution","text":"คือ การกระจายตัวของโอกาสที่จะเกิดเหตุการณ์เท่ากับจำนวนครั้งที่ต้องการภายใต้ช่วงเวลาใดเวลาหนึ่ง\\[\nf(k) = P(X = k) = \\frac{\\lambda^{k}}{k!}e^{-\\lambda}\n\\]\\[\n\\lambda = \\frac{k}{t}\n\\]การกระจายตัวแบบ Poisson เป็นการกระจายตัวแบบพื้นฐานในการนับจำนวน gene ที่เกิดขึ้นจาก RNA sequencing profile","code":"\npois_dist <- map_dfc(c(1, 2, 4, 10), ~dpois(1:20, .x)) |>  \n  set_names(paste0(\"Mean = \", c(1, 2, 4, 10))) |> \n  mutate(numb_event = 1:20) |> \n  pivot_longer(!numb_event, names_to = \"Mean\", values_to = \"value\") |> \n  mutate(Mean = fct_relevel(Mean, paste0(\"Mean = \", c(1, 2, 4, 10))))\n\nggplot(pois_dist, aes(x = numb_event, y = value, col = Mean)) + \n  geom_point(size = 0.8) +\n  geom_line() + \n  scale_x_continuous(breaks = seq(0,20,2), limits = c(0,21)) +\n  labs(title = \"Probablity that certain number of events will occur\", \n       x = \"Number of events\", y = \"Rate\", col = \"Average number of events\")"},{"path":"session-info.html","id":"session-info","chapter":"14 Session info","heading":"14 Session info","text":"","code":"\nsessionInfo()## R version 4.3.1 (2023-06-16 ucrt)\n## Platform: x86_64-w64-mingw32/x64 (64-bit)\n## Running under: Windows 11 x64 (build 22621)\n## \n## Matrix products: default\n## \n## \n## locale:\n## [1] LC_COLLATE=English_United Kingdom.utf8  LC_CTYPE=English_United Kingdom.utf8   \n## [3] LC_MONETARY=English_United Kingdom.utf8 LC_NUMERIC=C                           \n## [5] LC_TIME=English_United Kingdom.utf8    \n## \n## time zone: Asia/Bangkok\n## tzcode source: internal\n## \n## attached base packages:\n## [1] stats     graphics  grDevices utils     datasets  methods   base     \n## \n## other attached packages:\n##  [1] survminer_0.4.9 ggpubr_0.6.0    cowplot_1.1.1   broom_1.0.5     survival_3.5-5  corrplot_0.92   granova_2.2    \n##  [8] car_3.1-2       carData_3.0-5   lubridate_1.9.2 forcats_1.0.0   stringr_1.5.0   dplyr_1.1.2     purrr_1.0.2    \n## [15] readr_2.1.4     tidyr_1.3.0     tibble_3.2.1    ggplot2_3.4.3   tidyverse_2.0.0\n## \n## loaded via a namespace (and not attached):\n##  [1] tidyselect_1.2.0  psych_2.3.6       farver_2.1.1      fastmap_1.1.1     digest_0.6.33     timechange_0.2.0 \n##  [7] lifecycle_1.0.3   magrittr_2.0.3    compiler_4.3.1    rlang_1.1.1       sass_0.4.7        tools_4.3.1      \n## [13] utf8_1.2.3        yaml_2.3.7        data.table_1.14.8 knitr_1.44        ggsignif_0.6.4    labeling_0.4.3   \n## [19] bit_4.0.5         mnormt_2.1.1      xml2_1.3.5        abind_1.4-5       nleqslv_3.3.4     withr_2.5.0      \n## [25] grid_4.3.1        fansi_1.0.4       xtable_1.8-4      colorspace_2.1-0  scales_1.2.1      cli_3.6.1        \n## [31] rmarkdown_2.25    crayon_1.5.2      generics_0.1.3    km.ci_0.5-6       rstudioapi_0.15.0 tzdb_0.4.0       \n## [37] commonmark_1.9.0  cachem_1.0.8      splines_4.3.1     parallel_4.3.1    survMisc_0.5.6    vctrs_0.6.3      \n## [43] Matrix_1.6-0      jsonlite_1.8.7    bookdown_0.35     hms_1.1.3         bit64_4.0.5       rstatix_0.7.2    \n## [49] jpeg_0.1-10       jquerylib_0.1.4   glue_1.6.2        ggtext_0.1.2      stringi_1.7.12    gtable_0.3.4     \n## [55] downlit_0.4.3     munsell_0.5.0     detectnorm_1.0.0  pillar_1.9.0      htmltools_0.5.5   truncnorm_1.0-9  \n## [61] KMsurv_0.1-5      R6_2.5.1          Rdpack_2.5        vroom_1.6.3       evaluate_0.21     lattice_0.21-8   \n## [67] highr_0.10        markdown_1.8      rbibutils_2.2.15  png_0.1-8         backports_1.4.1   gridtext_0.1.5   \n## [73] memoise_2.0.1     bslib_0.5.1       Rcpp_1.0.11       gridExtra_2.3     nlme_3.1-162      mgcv_1.8-42      \n## [79] xfun_0.40         zoo_1.8-12        fs_1.6.3          pkgconfig_2.0.3"}]
